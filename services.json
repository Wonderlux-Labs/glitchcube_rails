{
  "directory_name": "services",
  "files": [
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tool_metrics.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tool_executor.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/music/search_music.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/music/play_music.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/modes/mode_control.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/base_tool.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/home_assistant/call_agent.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/registry.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/display/notification.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/communication/announcement.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/query/rag_search.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/effects/control_effects.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/lights/set_effect.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/lights/get_state.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/lights/set_state.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/lights/list_effects.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tool_calling_service.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/goal_service.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/memory/memory_recall_service.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/memory/memory_extraction_service.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/memory/context_injection_service.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/conversation_new_orchestrator.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/gps/gps_tracking_service.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/gps/location_context_service.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/gps/blah.yaml",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/prompt_service.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/persona_switch_service.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/conversation_new_orchestrator/action_executor.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/conversation_new_orchestrator/setup.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/conversation_new_orchestrator/llm_intention.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/conversation_new_orchestrator/prompt_builder.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/conversation_new_orchestrator/finalizer.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/conversation_new_orchestrator/response_synthesizer.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/conversation_logger.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/llm_service.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/schemas/narrative_response_schema.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/location_event_handler.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/contextual_speech_trigger_service.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/conversation_orchestrator.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/cube_speech.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/home_assistant_service.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/cube_performance.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/performance_mode_service.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/service_result.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/world_state_updaters/backend_health_service.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/world_state_updaters/conversation_summarizer_service.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/world_state_updaters/weather_forecast_summarizer_service.rb",
    "/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/world_state_updaters/narrative_conversation_sync_service.rb"
  ],
  "model_info": "ChatGPT models, text-embedding-ada-002",
  "prompt": "Project Path: services\n\nSource Tree:\n\n```\nservices\n├── tool_metrics.rb\n├── tool_executor.rb\n├── tools\n│   ├── music\n│   │   ├── search_music.rb\n│   │   └── play_music.rb\n│   ├── modes\n│   │   └── mode_control.rb\n│   ├── meta\n│   ├── base_tool.rb\n│   ├── home_assistant\n│   │   └── call_agent.rb\n│   ├── registry.rb\n│   ├── display\n│   │   └── notification.rb\n│   ├── communication\n│   │   └── announcement.rb\n│   ├── query\n│   │   └── rag_search.rb\n│   ├── effects\n│   │   └── control_effects.rb\n│   └── lights\n│       ├── set_effect.rb\n│       ├── get_state.rb\n│       ├── set_state.rb\n│       └── list_effects.rb\n├── tool_calling_service.rb\n├── goal_service.rb\n├── memory\n│   ├── memory_recall_service.rb\n│   ├── memory_extraction_service.rb\n│   └── context_injection_service.rb\n├── conversation_new_orchestrator.rb\n├── gps\n│   ├── gps_tracking_service.rb\n│   ├── location_context_service.rb\n│   └── blah.yaml\n├── prompt_service.rb\n├── persona_switch_service.rb\n├── conversation_new_orchestrator\n│   ├── action_executor.rb\n│   ├── setup.rb\n│   ├── llm_intention.rb\n│   ├── prompt_builder.rb\n│   ├── finalizer.rb\n│   └── response_synthesizer.rb\n├── conversation_logger.rb\n├── llm_service.rb\n├── schemas\n│   └── narrative_response_schema.rb\n├── location_event_handler.rb\n├── contextual_speech_trigger_service.rb\n├── conversation_orchestrator.rb\n├── cube_speech.rb\n├── home_assistant_service.rb\n├── cube_performance.rb\n├── performance_mode_service.rb\n├── service_result.rb\n└── world_state_updaters\n    ├── backend_health_service.rb\n    ├── conversation_summarizer_service.rb\n    ├── weather_forecast_summarizer_service.rb\n    └── narrative_conversation_sync_service.rb\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tool_metrics.rb`:\n\n```rb\n# frozen_string_literal: true\n\n# Service for collecting and analyzing tool execution timing metrics\n# Uses Rails.cache for storage (no Redis dependency)\n# Provides data-driven sync/async decision making\nclass ToolMetrics\n  # Timing thresholds in milliseconds\n  SYNC_THRESHOLD_MS = 100\n  MAYBE_SYNC_THRESHOLD_MS = 500\n  BURNING_MAN_OVERHEAD_MS = 300\n\n  # Cache TTL: 7 days\n  CACHE_TTL = 7.days\n\n  class << self\n    # Record tool execution timing\n    def record(tool_name:, duration_ms:, success:, entity_id: nil)\n      timestamp = Time.current.to_i\n      cache_key = \"tool_metrics:#{tool_name}:#{timestamp}\"\n\n      metric_data = {\n        tool_name: tool_name,\n        duration_ms: duration_ms.round(2),\n        success: success,\n        entity_id: entity_id,\n        timestamp: timestamp\n      }\n\n      Rails.cache.write(cache_key, metric_data, expires_in: CACHE_TTL)\n\n      # Also append to daily aggregation for faster analysis\n      daily_key = \"tool_metrics:daily:#{tool_name}:#{Date.current}\"\n      daily_metrics = Rails.cache.fetch(daily_key, expires_in: CACHE_TTL) { [] }\n      daily_metrics << duration_ms.round(2)\n      Rails.cache.write(daily_key, daily_metrics, expires_in: CACHE_TTL)\n\n      Rails.logger.info \"📊 Tool metrics recorded: #{tool_name} took #{duration_ms.round(2)}ms\"\n    rescue StandardError => e\n      Rails.logger.error \"Failed to record tool metrics: #{e.message}\"\n    end\n\n    # Get statistics for a tool\n    def stats_for(tool_name, days: 1)\n      daily_keys = (0...days).map do |day_offset|\n        date = Date.current - day_offset.days\n        \"tool_metrics:daily:#{tool_name}:#{date}\"\n      end\n\n      all_timings = daily_keys.flat_map do |key|\n        Rails.cache.read(key) || []\n      end\n\n      return empty_stats(tool_name) if all_timings.empty?\n\n      sorted_timings = all_timings.sort\n      count = sorted_timings.length\n\n      {\n        tool_name: tool_name,\n        count: count,\n        p50: percentile(sorted_timings, 50),\n        p95: percentile(sorted_timings, 95),\n        p99: percentile(sorted_timings, 99),\n        avg: (sorted_timings.sum / count.to_f).round(2),\n        min: sorted_timings.first,\n        max: sorted_timings.last,\n        recommendation: recommendation_for_timings(sorted_timings)\n      }\n    end\n\n    # Get recommendation for sync/async based on timings\n    def recommendation_for(tool_name, days: 1)\n      stats = stats_for(tool_name, days: days)\n      return :unknown if stats[:count] == 0\n      stats[:recommendation]\n    end\n\n    # Get all tools with timing data\n    def all_tool_stats(days: 1)\n      tool_names = []\n\n      # Find all tool names from cache keys\n      # Note: This implementation depends on cache store type\n      if Rails.cache.respond_to?(:redis)\n        # Redis cache store\n        keys = Rails.cache.redis.keys(\"tool_metrics:daily:*\")\n        keys.each do |key|\n          tool_name = key.split(\":\")[2]\n          tool_names << tool_name if tool_name\n        end\n      else\n        # Memory/File cache store - use instance variable (less reliable)\n        cache_data = Rails.cache.instance_variable_get(:@data) || {}\n        cache_data.keys.each do |key|\n          if key.to_s.start_with?(\"tool_metrics:daily:\")\n            tool_name = key.to_s.split(\":\")[2]\n            tool_names << tool_name if tool_name\n          end\n        end\n      end\n\n      tool_names.uniq.map { |name| stats_for(name, days: days) }\n    end\n\n    # Adjust timing for Burning Man network conditions\n    def burning_man_adjusted_timing(base_timing_ms)\n      base_timing_ms + BURNING_MAN_OVERHEAD_MS\n    end\n\n    # Clear all metrics (for testing)\n    def clear_all_metrics!\n      if Rails.cache.respond_to?(:redis)\n        Rails.cache.redis.del(Rails.cache.redis.keys(\"tool_metrics:*\"))\n      else\n        cache_data = Rails.cache.instance_variable_get(:@data)\n        return unless cache_data\n\n        keys_to_delete = cache_data.keys.select { |key| key.to_s.start_with?(\"tool_metrics:\") }\n        keys_to_delete.each { |key| Rails.cache.delete(key) }\n      end\n\n      Rails.logger.info \"🧹 All tool metrics cleared\"\n    end\n\n    # Get a summary of all metrics\n    def summary(days: 1)\n      all_stats = all_tool_stats(days: days)\n      return { total_tools: 0, recommendations: {} } if all_stats.empty?\n\n      recommendations = all_stats.group_by { |stats| stats[:recommendation] }\n      total_calls = all_stats.sum { |stats| stats[:count] }\n\n      {\n        total_tools: all_stats.length,\n        total_calls: total_calls,\n        days_analyzed: days,\n        recommendations: {\n          sync: (recommendations[:sync] || []).length,\n          maybe_sync: (recommendations[:maybe_sync] || []).length,\n          async: (recommendations[:async] || []).length,\n          unknown: (recommendations[:unknown] || []).length\n        },\n        slowest_tool: all_stats.max_by { |stats| stats[:p95] },\n        fastest_tool: all_stats.min_by { |stats| stats[:p95] }\n      }\n    end\n\n    private\n\n    def percentile(sorted_array, percentile)\n      return 0 if sorted_array.empty?\n\n      index = (percentile / 100.0) * (sorted_array.length - 1)\n      lower_index = index.floor\n      upper_index = index.ceil\n\n      if lower_index == upper_index\n        sorted_array[lower_index].round(2)\n      else\n        lower_value = sorted_array[lower_index]\n        upper_value = sorted_array[upper_index]\n        weight = index - lower_index\n        (lower_value + weight * (upper_value - lower_value)).round(2)\n      end\n    end\n\n    def recommendation_for_timings(sorted_timings)\n      p95 = percentile(sorted_timings, 95)\n      adjusted_p95 = burning_man_adjusted_timing(p95)\n\n      if adjusted_p95 < SYNC_THRESHOLD_MS\n        :sync\n      elsif adjusted_p95 < MAYBE_SYNC_THRESHOLD_MS\n        :maybe_sync\n      else\n        :async\n      end\n    end\n\n    def empty_stats(tool_name)\n      {\n        tool_name: tool_name,\n        count: 0,\n        p50: 0,\n        p95: 0,\n        p99: 0,\n        avg: 0,\n        min: 0,\n        max: 0,\n        recommendation: :unknown\n      }\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tool_executor.rb`:\n\n```rb\n# app/services/tool_executor.rb\nclass ToolExecutor\n  def initialize\n    @results = {}\n  end\n\n  # Execute synchronous tools immediately (for data needed in response)\n  def execute_sync(tool_calls)\n    return {} if tool_calls.nil? || tool_calls.empty?\n\n    sync_results = {}\n\n    tool_calls.each do |tool_call|\n      # Ensure we have a ValidatedToolCall object\n      validated_tool_call = ensure_validated_tool_call(tool_call)\n\n      # Only execute if it's a sync tool\n      tool_class = Tools::Registry.get_tool(validated_tool_call.name)\n      next unless tool_class&.tool_type == :sync\n\n      Rails.logger.info \"Executing sync tool: #{validated_tool_call.name}\"\n\n      # Validate before execution\n      unless validated_tool_call.valid?\n        Rails.logger.warn \"⚠️ Tool validation failed: #{validated_tool_call.name}\"\n        sync_results[validated_tool_call.name] = {\n          success: false,\n          error: \"Validation failed\",\n          details: validated_tool_call.validation_errors,\n          tool: validated_tool_call.name\n        }\n\n        # Record validation failure as 0ms (immediate failure)\n        ToolMetrics.record(\n          tool_name: validated_tool_call.name,\n          duration_ms: 0,\n          success: false\n        )\n        next\n      end\n\n      # Execute with timing\n      result = execute_with_timing(validated_tool_call)\n      sync_results[validated_tool_call.name] = result\n    end\n\n    sync_results\n  end\n\n  # Execute asynchronous tools in background (for actions after response)\n  def execute_async(tool_calls, session_id: nil, conversation_id: nil)\n    return unless tool_calls&.any?\n\n    tool_calls.each do |tool_call|\n      # Ensure we have a ValidatedToolCall object\n      validated_tool_call = ensure_validated_tool_call(tool_call)\n\n      # Only execute if it's an async tool\n      tool_class = Tools::Registry.get_tool(validated_tool_call.name)\n      next unless tool_class&.tool_type == :async\n\n      # Skip if validation fails (log but don't queue invalid tools)\n      unless validated_tool_call.valid?\n        Rails.logger.error \"❌ Skipping async tool due to validation failure: #{validated_tool_call.name}\"\n        Rails.logger.error \"Validation errors: #{validated_tool_call.validation_errors.join(', ')}\"\n\n        # Record validation failure\n        ToolMetrics.record(\n          tool_name: validated_tool_call.name,\n          duration_ms: 0,\n          success: false\n        )\n        next\n      end\n\n      # Queue for background execution with serializable data\n      AsyncToolJob.perform_later(\n        validated_tool_call.name,\n        validated_tool_call.arguments,\n        session_id,\n        conversation_id\n      )\n    end\n  end\n\n  # Execute a single tool (used by background jobs)\n  def execute_single_async(validated_tool_call_or_legacy_args, legacy_arguments = nil)\n    # Handle both new ValidatedToolCall objects and legacy tool_name + arguments\n    if validated_tool_call_or_legacy_args.is_a?(ValidatedToolCall)\n      validated_tool_call = validated_tool_call_or_legacy_args\n      Rails.logger.info \"🔧 ToolExecutor.execute_single_async with ValidatedToolCall: #{validated_tool_call.name}\"\n    else\n      # Legacy support: tool_name, arguments\n      tool_name = validated_tool_call_or_legacy_args\n      arguments = legacy_arguments\n\n      Rails.logger.info \"🔧 ToolExecutor.execute_single_async (legacy): #{tool_name}\"\n      Rails.logger.info \"📝 Arguments: #{arguments.inspect}\"\n\n      # Create ValidatedToolCall from legacy parameters\n      tool_class = Tools::Registry.get_tool(tool_name)\n      unless tool_class\n        error_result = {\n          success: false,\n          error: \"Tool '#{tool_name}' not found\",\n          tool: tool_name\n        }\n        Rails.logger.error \"❌ Tool not found: #{tool_name}\"\n\n        # Record failure\n        ToolMetrics.record(tool_name: tool_name, duration_ms: 0, success: false)\n        return error_result\n      end\n\n      # Create a minimal ToolCall object for validation\n      tool_call_data = {\n        \"id\" => \"async_#{SecureRandom.uuid}\",\n        \"type\" => \"function\",\n        \"function\" => {\n          \"name\" => tool_name,\n          \"arguments\" => arguments.to_json\n        }\n      }\n\n      validated_tool_call = ValidatedToolCall.from_tool_call_data(tool_call_data, tool_class)\n    end\n\n    # Execute with validation and timing\n    execute_with_timing(validated_tool_call)\n  end\n\n  # Get tool definitions for LLM\n  def available_tool_definitions\n    Tools::Registry.tool_definitions_for_llm\n  end\n\n  # Categorize tool calls by execution type\n  def categorize_tool_calls(tool_calls)\n    return { sync_tools: [], async_tools: [], agent_tools: [] } unless tool_calls&.any?\n\n    sync_tools = []\n    async_tools = []\n    agent_tools = []\n\n    tool_calls.each do |tool_call|\n      validated_tool_call = ensure_validated_tool_call(tool_call)\n      tool_class = Tools::Registry.get_tool(validated_tool_call.name)\n\n      next unless tool_class\n\n      case tool_class.tool_type\n      when :sync\n        sync_tools << validated_tool_call\n      when :async\n        async_tools << validated_tool_call\n      when :agent\n        agent_tools << validated_tool_call\n      end\n    end\n\n    {\n      sync_tools: sync_tools,\n      async_tools: async_tools,\n      agent_tools: agent_tools\n    }\n  end\n\n  private\n\n  # Ensure we have a ValidatedToolCall object\n  def ensure_validated_tool_call(tool_call)\n    return tool_call if tool_call.is_a?(ValidatedToolCall)\n\n    # Handle OpenRouter::ToolCall objects\n    if tool_call.is_a?(OpenRouter::ToolCall)\n      begin\n        tool_class = Tools::Registry.get_tool(tool_call.name)\n        return ValidatedToolCall.new(tool_call, tool_class)\n      rescue OpenRouter::ToolCallError => e\n        Rails.logger.error \"❌ Malformed tool call from LLM: #{tool_call.name} - #{e.message}\"\n        # Return a failed ValidatedToolCall for malformed arguments\n        return ValidatedToolCall.new(tool_call.name, {}, nil, [ \"Malformed arguments: #{e.message}\" ])\n      end\n    end\n\n    # Handle hash/legacy tool call data\n    tool_name = tool_call.respond_to?(:name) ? tool_call.name : tool_call[\"name\"]\n    begin\n      arguments = tool_call.respond_to?(:arguments) ? tool_call.arguments : tool_call[\"arguments\"]\n    rescue OpenRouter::ToolCallError => e\n      Rails.logger.error \"❌ Malformed tool call arguments: #{tool_name} - #{e.message}\"\n      arguments = {}\n    end\n\n    tool_call_data = {\n      \"id\" => \"legacy_#{SecureRandom.uuid}\",\n      \"type\" => \"function\",\n      \"function\" => {\n        \"name\" => tool_name,\n        \"arguments\" => arguments.is_a?(String) ? arguments : arguments.to_json\n      }\n    }\n\n    tool_class = Tools::Registry.get_tool(tool_name)\n    ValidatedToolCall.from_tool_call_data(tool_call_data, tool_class)\n  end\n\n  # Execute tool with timing metrics\n  def execute_with_timing(validated_tool_call)\n    start_time = Process.clock_gettime(Process::CLOCK_MONOTONIC, :float_millisecond)\n\n    # Validate before execution\n    unless validated_tool_call.valid?\n      duration_ms = Process.clock_gettime(Process::CLOCK_MONOTONIC, :float_millisecond) - start_time\n\n      # Record validation failure\n      ToolMetrics.record(\n        tool_name: validated_tool_call.name,\n        duration_ms: duration_ms,\n        success: false\n      )\n\n      Rails.logger.error \"❌ Tool validation failed: #{validated_tool_call.name}\"\n      Rails.logger.error \"Validation errors: #{validated_tool_call.validation_errors.join(', ')}\"\n\n      return {\n        success: false,\n        error: \"Validation failed\",\n        details: validated_tool_call.validation_errors,\n        tool: validated_tool_call.name,\n        validation_time_ms: duration_ms.round(2)\n      }\n    end\n\n    begin\n      Rails.logger.info \"🚀 Executing tool: #{validated_tool_call.name}\"\n\n      # Execute the actual tool\n      result = Tools::Registry.execute_tool(\n        validated_tool_call.name,\n        **validated_tool_call.arguments\n      )\n\n      duration_ms = Process.clock_gettime(Process::CLOCK_MONOTONIC, :float_millisecond) - start_time\n      success = result[:success] != false # Default to true unless explicitly false\n\n      # Record metrics\n      ToolMetrics.record(\n        tool_name: validated_tool_call.name,\n        duration_ms: duration_ms,\n        success: success,\n        entity_id: validated_tool_call.arguments[\"entity_id\"]\n      )\n\n      Rails.logger.info \"✅ Tool #{validated_tool_call.name} completed in #{duration_ms.round(2)}ms\"\n\n      # Log to conversation logger\n      ConversationLogger.tool_execution(\n        validated_tool_call.name,\n        validated_tool_call.arguments,\n        result\n      )\n\n      result\n\n    rescue StandardError => e\n      duration_ms = Process.clock_gettime(Process::CLOCK_MONOTONIC, :float_millisecond) - start_time\n\n      # Record failed execution\n      ToolMetrics.record(\n        tool_name: validated_tool_call.name,\n        duration_ms: duration_ms,\n        success: false\n      )\n\n      Rails.logger.error \"❌ Tool execution failed: #{validated_tool_call.name} - #{e.message}\"\n      Rails.logger.error \"🔍 Backtrace: #{e.backtrace.first(5).join(\"\\n\")}\"\n\n      error_result = {\n        success: false,\n        error: e.message,\n        tool: validated_tool_call.name,\n        execution_time_ms: duration_ms.round(2)\n      }\n\n      # Log to conversation logger\n      ConversationLogger.tool_execution(\n        validated_tool_call.name,\n        validated_tool_call.arguments,\n        error_result\n      )\n\n      error_result\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/music/search_music.rb`:\n\n```rb\n# app/services/tools/music/search_music.rb\nclass Tools::Music::SearchMusic < Tools::BaseTool\n  def self.description\n    \"Search for music tracks without playing them - useful for discovery and recommendations\"\n  end\n\n  def self.narrative_desc\n    \"search for music - find specific tracks, artists, or albums in the music library\"\n  end\n\n  def self.prompt_schema\n    \"search_music(query: 'Pink Floyd') - Search music library for tracks, artists, or albums\"\n  end\n\n  def self.tool_type\n    :sync # Search is informational, happens synchronously\n  end\n\n  def self.definition\n    @definition ||= OpenRouter::Tool.define do\n      name \"search_music\"\n      description \"Search the music library for tracks, artists, albums, or genres\"\n\n      parameters do\n        string :query, required: true,\n               description: \"REQUIRED: What to search for - artist name, song title, album, or genre\"\n\n        string :search_type,\n               description: \"Optional: Type of search to perform\",\n               enum: [ \"track\", \"artist\", \"album\", \"genre\", \"all\" ]\n\n        integer :limit,\n                description: \"Optional: Maximum number of results to return (default: 10)\"\n      end\n    end\n  end\n\n  def call(query:, search_type: \"all\", limit: 10)\n    # For now, this is a simple script call to Home Assistant\n    # In the future, this could integrate with Music Assistant API directly\n\n    service_data = {\n      query: query,\n      search_type: search_type,\n      limit: limit\n    }\n\n    begin\n      result = HomeAssistantService.call_service(\"script\", \"search_music_library\", service_data)\n\n      success_response(\n        \"Found music for: #{query}\",\n        search_query: query,\n        search_type: search_type,\n        limit: limit,\n        results: result&.dig(\"results\") || [],\n        script: \"search_music_library\"\n      )\n    rescue HomeAssistantService::Error => e\n      error_response(\"Failed to search music: #{e.message}\")\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/music/play_music.rb`:\n\n```rb\n# app/services/tools/music/play_music.rb\nclass Tools::Music::PlayMusic < Tools::BaseTool\n  def self.description\n    \"Play specific music tracks on the Cube's sound system via Music Assistant\"\n  end\n\n  def self.narrative_desc\n    \"control music - play specific tracks on the sound system - we have fuzzy search just send in your best guess, you can also queue it up, play it next or play it now!\"\n  end\n\n  def self.prompt_schema\n    \"play_music(artist: 'Pink Floyd', album: 'Dark Side of the Moon') - Play music on the Cube's sound system\"\n  end\n\n  def self.tool_type\n    :async # Music control happens after response\n  end\n\n  def self.definition\n    @definition ||= OpenRouter::Tool.define do\n      name \"play_music\"\n      description \"Play music on the Cube's jukebox with fuzzy search - can search by song, artist, or any combination\"\n\n      parameters do\n        string :media_id, required: true,\n               description: \"REQUIRED: The song you want to play - fuzzy search works, so can do 'Watermelon Man by Herbie Hancock' or 'Nirvana - Teen Spirit'. The more precise the better.\"\n\n        string :artist,\n               description: \"Optional: Artist name to narrow down search results if getting funny results\"\n\n        string :album,\n               description: \"Optional: Album name to further narrow down search if needed\"\n\n        string :enqueue,\n               description: \"Queue mode: 'play' (force play now), 'replace' (replace queue and play), 'next' (add after current), 'replace_next' (default), 'add' (end of queue)\",\n               enum: [ \"play\", \"replace\", \"next\", \"replace_next\", \"add\" ]\n      end\n    end\n  end\n\n  def call(media_id:, artist: nil, album: nil, enqueue: \"replace_next\")\n    # Build service data for the script call (script expects parameters directly, not wrapped in variables)\n    service_data = {\n      media_id: media_id,\n      enqueue: enqueue\n    }\n\n    # Add optional parameters\n    service_data[:artist] = artist if artist.present?\n    service_data[:album] = album if album.present?\n\n    # Call the Home Assistant script\n    begin\n      result = HomeAssistantService.call_service(\"script\", \"play_music_on_jukebox\", service_data)\n\n      response_message = \"Playing: \\\"#{media_id}\\\"\"\n      response_message += \" by #{artist}\" if artist\n      response_message += \" from #{album}\" if album\n      response_message += \" (#{enqueue} mode)\" if enqueue != \"replace_next\"\n\n      success_response(\n        response_message,\n        script: \"play_music_on_jukebox\",\n        media_id: media_id,\n        artist: artist,\n        album: album,\n        enqueue: enqueue,\n        service_result: result\n      )\n    rescue HomeAssistantService::Error => e\n      error_response(\"Failed to play music: #{e.message}\")\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/modes/mode_control.rb`:\n\n```rb\n# app/services/tools/modes/mode_control.rb\nclass Tools::Modes::ModeControl < Tools::BaseTool\n  def self.description\n    \"Put the Cube temporarily into special operational modes\"\n  end\n\n  def self.narrative_desc\n    \"control modes - change operational modes and special states - toggle emergency mode, stealth mode, rude mode, brag mode, mute mode\"\n  end\n\n  def self.prompt_schema\n    \"mode_control(mode: 'emergency_mode', action: 'activate') - Control Cube operational modes\"\n  end\n\n  def self.tool_type\n    :async # Mode changes happen after response\n  end\n\n  def self.definition\n    @definition ||= OpenRouter::Tool.define do\n      name \"mode_control\"\n      description \"Control special operational modes of the Cube (emergency, stealth, theme song)\"\n\n      parameters do\n        string :mode, required: true,\n               description: \"Mode to control\",\n               enum: -> { Tools::Modes::ModeControl.available_modes }\n\n        string :action, required: true,\n               description: \"Action to perform\",\n               enum: [ \"activate\", \"deactivate\", \"toggle\" ]\n      end\n    end\n  end\n\n  def self.available_modes\n    [ \"emergency_mode\", \"stealth_mode\", \"play_theme_song\" ]\n  end\n\n  def call(mode:, action:)\n    # Map modes to their corresponding entities\n    # Some are input_booleans, some might be input_selects or switches\n    mode_entities = {\n      \"emergency_mode\" => { type: \"input_boolean\", entity_id: \"input_boolean.emergency_mode\" },\n      \"stealth_mode\" => { type: \"input_boolean\", entity_id: \"input_boolean.stealth_mode\" },\n      \"play_theme_song\" => { type: \"switch\", entity_id: \"switch.play_theme_song\" }\n    }\n\n    mode_config = mode_entities[mode]\n    unless mode_config\n      return error_response(\n        \"Unknown mode: #{mode}\",\n        available_modes: available_modes\n      )\n    end\n\n    # Map actions to Home Assistant services\n    service_map = {\n      \"activate\" => \"turn_on\",\n      \"deactivate\" => \"turn_off\",\n      \"toggle\" => \"toggle\"\n    }\n\n    service = service_map[action]\n    unless service\n      return error_response(\n        \"Invalid action: #{action}\",\n        available_actions: service_map.keys\n      )\n    end\n\n    # Call Home Assistant service\n    begin\n      result = HomeAssistantService.call_service(\n        mode_config[:type],\n        service,\n        { entity_id: mode_config[:entity_id] }\n      )\n\n      action_past_tense = action == \"activate\" ? \"activated\" : (action == \"deactivate\" ? \"deactivated\" : \"toggled\")\n\n      success_response(\n        \"#{action_past_tense.capitalize} #{mode.humanize}\",\n        mode: mode,\n        action: action,\n        entity_type: mode_config[:type],\n        entity_id: mode_config[:entity_id],\n        service_result: result\n      )\n    rescue HomeAssistantService::Error => e\n      error_response(\"Failed to control #{mode}: #{e.message}\")\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/base_tool.rb`:\n\n```rb\n# app/services/tools/base_tool.rb\nclass Tools::BaseTool\n  # Cube light entities (single source of truth)\n  CUBE_LIGHT_ENTITIES = %w[\n    light.cube_voice_ring\n    light.cube_light_top\n    light.cube_inner\n  ].freeze\n  class << self\n    # Define the OpenRouter tool definition for this tool\n    def definition\n      raise NotImplementedError, \"Subclasses must implement .definition\"\n    end\n\n    # Human-readable description for persona prompt generation\n    def description\n      raise NotImplementedError, \"Subclasses must implement .description\"\n    end\n\n    # Schema description for prompt generation (simplified for LLM understanding)\n    def prompt_schema\n      raise NotImplementedError, \"Subclasses must implement .prompt_schema\"\n    end\n\n    # Tool execution type for internal orchestration\n    def tool_type\n      :sync # Default to sync, override for :async or :agent\n    end\n\n    # Execute the tool with given arguments\n    def call(**args)\n      new.call(**args)\n    end\n  end\n\n  # Instance method to execute the tool\n  def call(**args)\n    raise NotImplementedError, \"Subclasses must implement #call\"\n  end\n\n  protected\n\n  # Validate entity exists and is accessible\n  def validate_entity(entity_id, domain: nil)\n    entities = HomeAssistantService.entities\n    entity = entities.find { |e| e[\"entity_id\"] == entity_id }\n\n    if entity.nil?\n      available_entities = entities\n        .map { |e| e[\"entity_id\"] }\n        .select { |id| domain.nil? || id.start_with?(\"#{domain}.\") }\n        .sort\n\n      return {\n        error: \"Entity '#{entity_id}' not found\",\n        available_entities: available_entities.first(10),\n        total_entities: available_entities.length\n      }\n    end\n\n    if domain && !entity_id.start_with?(\"#{domain}.\")\n      return {\n        error: \"Entity '#{entity_id}' is not a #{domain} entity\",\n        actual_domain: entity_id.split(\".\").first\n      }\n    end\n\n    entity\n  end\n\n  # Get cube-specific light entities\n  def cube_light_entities\n    CUBE_LIGHT_ENTITIES\n  end\n\n  # Get cached effect lists for cube lights (avoids repeated API calls)\n  def cube_light_effects\n    @cube_light_effects ||= begin\n      effects_map = {}\n      CUBE_LIGHT_ENTITIES.each do |entity_id|\n        begin\n          entity_data = HomeAssistantService.entity(entity_id)\n          effect_list = entity_data&.dig(\"attributes\", \"effect_list\") || []\n          effects_map[entity_id] = effect_list.reject(&:empty?).sort\n        rescue StandardError => e\n          Rails.logger.warn \"Could not get effects for #{entity_id}: #{e.message}\"\n          effects_map[entity_id] = []\n        end\n      end\n      effects_map\n    end\n  end\n\n  # Format successful response\n  def success_response(message, data = {})\n    {\n      success: true,\n      message: message,\n      **data\n    }\n  end\n\n  # Format error response\n  def error_response(message, details = {})\n    {\n      success: false,\n      error: message,\n      **details\n    }\n  end\n\n  # Convert RGB array to Home Assistant format\n  def format_rgb_color(rgb_color)\n    return nil unless rgb_color.is_a?(Array) && rgb_color.length == 3\n    return nil unless rgb_color.all? { |c| c.is_a?(Integer) && c >= 0 && c <= 255 }\n\n    rgb_color\n  end\n\n  # Convert brightness percentage to HA brightness (0-255)\n  def format_brightness(brightness_percent)\n    return nil unless brightness_percent.is_a?(Numeric)\n    return nil unless brightness_percent >= 0 && brightness_percent <= 100\n\n    (brightness_percent * 2.55).round\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/home_assistant/call_agent.rb`:\n\n```rb\n# app/services/tools/home_assistant/call_agent.rb\nclass Tools::HomeAssistant::CallAgent < Tools::BaseTool\n  def self.description\n    \"Delegate action requests to Home Assistant's conversation agent for reliable tool execution.\"\n  end\n\n  def self.narrative_desc\n    \"handle any device control or automation request by passing it to the Home Assistant system\"\n  end\n\n  def self.prompt_schema\n    \"call_ha_agent(request: 'turn on the lights and play music') - Pass any device control request to Home Assistant for execution\"\n  end\n\n  def self.tool_type\n    :async  # Execute in background, return personality response immediately\n  end\n\n  def self.definition\n    @definition ||= OpenRouter::Tool.define do\n      name \"call_ha_agent\"\n      description \"Delegate device control and automation requests to Home Assistant's conversation agent\"\n\n      parameters do\n        string :request, required: true,\n               description: \"The user's original request for device control, automation, or actions. Pass the full context of what they want done.\"\n      end\n    end\n  end\n\n  def call(request:)\n    Rails.logger.info \"🏠 Delegating to HA agent: #{request}\"\n\n    begin\n      # Call Home Assistant's conversation.process API with tool executor agent\n      response = HomeAssistantService.conversation_process(\n        text: request,\n        agent_id: \"tool_executor\", # Dedicated HA agent for tool execution\n        conversation_id: nil # Don't tie to our conversation - this is a tool call\n      )\n\n      Rails.logger.info \"✅ HA agent response: #{response.inspect}\"\n\n      # Extract execution results\n      if response.dig(\"response\", \"response_type\") == \"error\"\n        error_message = response.dig(\"response\", \"speech\", \"plain\", \"speech\") || \"Unknown error\"\n        return {\n          success: false,\n          error: error_message,\n          message: \"Home Assistant couldn't complete that request\"\n        }\n      end\n\n      # Extract successful actions\n      success_entities = response.dig(\"response\", \"data\", \"success\") || []\n      failed_entities = response.dig(\"response\", \"data\", \"failed\") || []\n      targets = response.dig(\"response\", \"data\", \"targets\") || []\n\n      success_count = success_entities.length\n      failed_count = failed_entities.length\n\n      if success_count > 0\n        success_message = if failed_count > 0\n          \"Completed #{success_count} actions, but #{failed_count} failed\"\n        else\n          \"Successfully completed #{success_count} actions\"\n        end\n\n        {\n          success: true,\n          message: success_message,\n          actions_taken: success_entities,\n          failed_actions: failed_entities,\n          targets: targets,\n          ha_response: response.dig(\"response\", \"speech\", \"plain\", \"speech\")\n        }\n      else\n        {\n          success: false,\n          error: \"No actions were completed successfully\",\n          failed_actions: failed_entities,\n          message: \"Home Assistant couldn't complete any of the requested actions\"\n        }\n      end\n\n    rescue StandardError => e\n      Rails.logger.error \"❌ HA agent call failed: #{e.message}\"\n      Rails.logger.error e.backtrace.join(\"\\n\")\n\n      {\n        success: false,\n        error: e.message,\n        message: \"Failed to communicate with Home Assistant\"\n      }\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/registry.rb`:\n\n```rb\n# app/services/tools/registry.rb\nclass Tools::Registry\n  class << self\n    # Get all available tools\n    def all_tools\n      @all_tools ||= {\n        # Light tools\n        \"set_light_effect\" => Tools::Lights::SetEffect,\n        \"get_light_state\" => Tools::Lights::GetState,\n        \"set_light_state\" => Tools::Lights::SetState,\n\n        # Music tools\n        \"play_music\" => Tools::Music::PlayMusic,\n        \"search_music\" => Tools::Music::SearchMusic,\n\n        # Display tools\n        \"display_notification\" => Tools::Display::Notification,\n\n        # Effects tools\n        \"control_effects\" => Tools::Effects::ControlEffects,\n\n        # Mode control tools\n        \"mode_control\" => Tools::Modes::ModeControl,\n\n        # Communication tools\n        \"make_announcement\" => Tools::Communication::Announcement,\n\n        # Query tools\n        \"rag_search\" => Tools::Query::RagSearch\n      }\n    end\n\n    # Get tools by execution type\n    def sync_tools\n      all_tools.select { |name, tool_class| tool_class.tool_type == :sync }\n    end\n\n    def async_tools\n      all_tools.select { |name, tool_class| tool_class.tool_type == :async }\n    end\n\n    def agent_tools\n      all_tools.select { |name, tool_class| tool_class.tool_type == :agent }\n    end\n\n    # Get OpenRouter tool definitions for LLM\n    def tool_definitions_for_llm\n      all_tools.values.map(&:definition)\n    end\n\n    # Get tool by name\n    def get_tool(tool_name)\n      all_tools[tool_name]\n    end\n\n    # Execute a tool\n    def execute_tool(tool_name, **args)\n      tool_class = get_tool(tool_name)\n      return { error: \"Tool '#{tool_name}' not found\" } unless tool_class\n\n      # Filter out blank strings and nil values\n      filtered_args = args.reject { |_k, v| v.blank? }\n\n      # Ensure keyword arguments have symbol keys (required for Ruby method calls)\n      # Handle both direct symbol args and string-keyed hashes from JSON\n      symbol_args = filtered_args.transform_keys { |key| key.is_a?(String) ? key.to_sym : key }\n\n      tool_class.call(**symbol_args)\n    end\n\n    # Get tool descriptions for prompt generation\n    def tool_descriptions\n      all_tools.transform_values(&:description)\n    end\n\n    # Get tool schemas for prompt generation\n    def tool_schemas\n      all_tools.transform_values(&:prompt_schema)\n    end\n\n    # Generate prompt-friendly tool list\n    def prompt_tool_list\n      all_tools.map do |name, tool_class|\n        \"#{tool_class.prompt_schema} [#{tool_class.tool_type}]\"\n      end.join(\"\\n\")\n    end\n\n    # Light-specific tools only\n    def light_tools\n      all_tools.select { |name, _| name.include?(\"light\") }\n    end\n\n    # Get available cube light entities (cached)\n    def cube_light_entities\n      @cube_light_entities ||= begin\n        service = HomeAssistantService.instance\n        entities = service.entities rescue []\n\n        cube_lights = entities\n          .select { |e| e[\"entity_id\"].start_with?(\"light.cube_\") }\n          .map { |e| e[\"entity_id\"] }\n\n        # Add ring light if it exists\n        ring_light = entities.find { |e| e[\"entity_id\"] == \"light.cube_voice_ring\" }\n        cube_lights << \"light.cube_voice_ring\" if ring_light\n\n        cube_lights.sort\n      end\n    end\n\n    # Get tool intent type (query for information vs action for changes)\n    def tool_intent(tool_name)\n      tool_class = get_tool(tool_name)\n      return :unknown unless tool_class\n\n      # Query tools: Get information, sync execution, return data for speech\n      # Action tools: Change state, usually async, minimal speech needed\n      case tool_name\n      when \"turn_on_light\", \"turn_off_light\", \"set_light_color_and_brightness\", \"set_light_effect\",\n           \"play_music\", \"display_notification\", \"control_effects\",\n           \"mode_control\", \"make_announcement\"\n        :action\n      else\n        # Default: sync tools are queries, async tools are actions\n        tool_class.tool_type == :sync ? :query : :action\n      end\n    end\n\n    # Categorize tool calls by execution type for conversation orchestrator\n    def categorize_tool_calls(tool_calls)\n      return { sync_tools: [], async_tools: [], query_tools: [], action_tools: [] } unless tool_calls&.any?\n\n      sync_tools = []\n      async_tools = []\n      query_tools = []\n      action_tools = []\n\n      tool_calls.each do |call|\n        tool_name = call.respond_to?(:name) ? call.name : call[\"name\"]\n        tool_class = get_tool(tool_name)\n\n        next unless tool_class\n\n        # Categorize by execution type\n        case tool_class.tool_type\n        when :sync\n          sync_tools << call\n        when :async\n          async_tools << call\n        end\n\n        # Categorize by intent\n        case tool_intent(tool_name)\n        when :query\n          query_tools << call\n        when :action\n          action_tools << call\n        end\n      end\n\n      {\n        sync_tools: sync_tools,\n        async_tools: async_tools,\n        query_tools: query_tools,\n        action_tools: action_tools\n      }\n    end\n\n    # Execute sync tools only (for conversation orchestrator)\n    def execute_sync_tools(tool_calls)\n      return {} if tool_calls.blank?\n\n      results = {}\n      tool_calls.each do |tool_call|\n        tool_name = tool_call.respond_to?(:name) ? tool_call.name : tool_call[\"name\"]\n        arguments = tool_call.respond_to?(:arguments) ? tool_call.arguments : tool_call[\"arguments\"]\n\n        tool_class = get_tool(tool_name)\n        next unless tool_class&.tool_type == :sync\n\n        begin\n          result = execute_tool(tool_name, **arguments)\n          results[tool_name] = result\n        rescue StandardError => e\n          results[tool_name] = { success: false, error: e.message, tool: tool_name }\n        end\n      end\n\n      results\n    end\n\n    # Get tools for specific persona (for conversation orchestrator)\n    def tools_for_persona(persona)\n      # Base tools available to all personas\n      base_tool_classes = [\n        # Lighting\n        Tools::Lights::SetEffect,\n        Tools::Lights::ListEffects,\n        Tools::Lights::GetState,\n        Tools::Lights::SetState,\n\n        # Display\n        Tools::Display::Notification,\n\n        # Music\n        Tools::Music::PlayMusic,\n\n        # Effects\n        Tools::Effects::ControlEffects,\n\n        # Communication\n        Tools::Communication::Announcement,\n\n        # Query\n        Tools::Query::RagSearch\n      ]\n\n      case persona&.to_s&.downcase\n      when \"buddy\"\n        # Buddy gets all tools - enthusiastic and friendly\n        base_tool_classes + [ Tools::Modes::ModeControl ]\n      when \"jax\"\n        # Jax gets all tools - dramatic and expressive\n        base_tool_classes + [ Tools::Modes::ModeControl ]\n      when \"zorp\"\n        # Zorp gets all tools - analytical and experimental\n        base_tool_classes + [ Tools::Modes::ModeControl ]\n      when \"lomi\"\n        # Lomi gets all tools - healing and nurturing\n        base_tool_classes + [ Tools::Modes::ModeControl ]\n      else\n        # Default persona gets all tools\n        base_tool_classes + [ Tools::Modes::ModeControl ]\n      end\n    end\n\n    # Get OpenRouter tool definitions for a specific persona\n    def tool_definitions_for_persona(persona)\n      tools_for_persona(persona).map(&:definition)\n    end\n\n    # Get narrative descriptions for narrative LLM (two-tier architecture)\n    def narrative_descriptions_for_persona(persona)\n      tools_for_persona(persona).map do |tool_class|\n        {\n          name: tool_class.name.demodulize.underscore,\n          description: tool_class.narrative_desc\n        }\n      end\n    end\n\n    # Get tools for two-tier mode (narrative LLM gets no tools - uses structured output)\n    def tools_for_two_tier_mode(persona)\n      []\n    end\n\n    # Get tool definitions for two-tier mode (technical LLM needs actual tools)\n    def tool_definitions_for_two_tier_mode(persona)\n      tool_definitions_for_persona(persona)\n    end\n\n    # Check if two-tier mode is enabled\n    def two_tier_mode_enabled?\n      Rails.configuration.try(:two_tier_tools_enabled) || false\n    end\n\n    # Refresh entity cache (call when entities might have changed)\n    def refresh_entity_cache!\n      @cube_light_entities = nil\n      # Clear tool class caches too\n      Tools::Lights::SetEffect.instance_variable_set(:@available_entities, nil)\n      Tools::Lights::ListEffects.instance_variable_set(:@available_entities, nil)\n      Tools::Lights::GetState.instance_variable_set(:@available_entities, nil)\n      Tools::HomeAssistant::CallService.instance_variable_set(:@available_domains, nil)\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/display/notification.rb`:\n\n```rb\n# app/services/tools/display/notification.rb\nclass Tools::Display::Notification < Tools::BaseTool\n  def self.description\n    \"Display text notifications on the scrolling marquee\"\n  end\n\n  def self.narrative_desc\n    \"display text - show messages and notifications on your scrolling marquee!\"\n  end\n\n  def self.prompt_schema\n    \"display_notification(text: 'Hello World', duration: 5) - Display text notification on Awtrix matrix\"\n  end\n\n  def self.tool_type\n    :sync\n  end\n\n  def self.definition\n    @definition ||= OpenRouter::Tool.define do\n      name \"display_notification\"\n      description \"Display text notification on the Awtrix matrix display via MQTT script\"\n\n      parameters do\n        string :text, required: true,\n               description: \"Text message to display on the matrix\"\n\n        number :duration, minimum: 1, maximum: 60,\n               description: \"How long to display the message in seconds (default: 30)\"\n\n        string :color,\n               description: \"hex code ie #ff0000 for red (defaults yellow but recommended)\"\n\n        boolean :wakeup,\n                description: \"wakeup screen if asleep (default true)\"\n\n        boolean :rainbow,\n                description: \"rainbow text! (default false)\"\n      end\n    end\n  end\n\n  def call(text:, duration: 30, color: nil, wakeup: true, rainbow: false)\n    # Build service data for the script call\n    service_data = {}\n\n    # Add variables for the script\n    variables = {\n      text: text,\n      duration: duration,\n      wakeup: wakeup,\n      rainbow: rainbow\n    }\n    variables[:color] = color if color.present?\n\n    service_data[:variables] = variables\n\n    # Call the Home Assistant script\n    begin\n      result = HomeAssistantService.call_service(\"script\", \"notification\", service_data)\n\n      response_message = \"Displaying notification: \\\"#{text}\\\"\"\n      response_message += \" for #{duration} seconds\" if duration != 5\n      response_message += \" in #{color}\" if color\n\n      success_response(\n        response_message,\n        script: \"notification\",\n        text: text,\n        duration: duration,\n        color: color,\n        service_result: result\n      )\n    rescue HomeAssistantService::Error => e\n      error_response(\"Failed to display notification: #{e.message}\")\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/communication/announcement.rb`:\n\n```rb\n# app/services/tools/communication/announcement.rb\nclass Tools::Communication::Announcement < Tools::BaseTool\n  def self.description\n    \"Make spoken announcements with persona voice and optional display text\"\n  end\n\n  def self.narrative_desc\n    \"make announcements - speak to humans and display messages on your screen - you have a loudspeaker after all! can send separate spoken and text or both the same\"\n  end\n\n  def self.prompt_schema\n    \"make_announcement(message: 'Welcome to the Cube', display_text: 'Welcome!') - Make spoken announcement with optional display\"\n  end\n\n  def self.tool_type\n    :async # Announcements happen after response\n  end\n\n  def self.definition\n    @definition ||= OpenRouter::Tool.define do\n      name \"make_announcement\"\n      description \"Make spoken announcements using music_assistant with persona voice and optional Awtrix display\"\n\n      parameters do\n        string :message, required: true,\n               description: \"Message to speak aloud\"\n\n        string :display_text,\n               description: \"Optional text to display on Awtrix matrix (if different from spoken message)\"\n\n        number :volume, minimum: 0, maximum: 100,\n               description: \"Volume level for announcement (0-100)\"\n\n        string :voice,\n               description: \"Voice to use (will default to current persona voice)\"\n      end\n    end\n  end\n\n  def call(message:, display_text: nil, volume: nil, voice: nil)\n    results = {}\n\n    # Make spoken announcement using music_assistant\n    begin\n      announce_data = {\n        message: message\n      }\n\n      # Add optional parameters\n      announce_data[:volume_level] = volume / 100.0 if volume.present?\n      announce_data[:voice] = voice if voice.present?\n\n      # Call music_assistant announce service targeting square_voice media player\n      announce_data[:entity_id] = \"media_player.square_voice\"\n\n      speech_result = HomeAssistantService.call_service(\n        \"music_assistant\",\n        \"announce\",\n        announce_data\n      )\n\n      results[:speech] = { success: true, message: \"Announced: \\\"#{message}\\\"\" }\n\n    rescue HomeAssistantService::Error => e\n      results[:speech] = { success: false, error: e.message }\n    end\n\n    # Display text on Awtrix if requested\n    if display_text.present?\n      begin\n        display_data = {\n          variables: {\n            text: display_text,\n            duration: 8 # Display for 8 seconds\n          }\n        }\n\n        display_result = HomeAssistantService.call_service(\n          \"script\",\n          \"notification\",\n          display_data\n        )\n\n        results[:display] = { success: true, message: \"Displayed: \\\"#{display_text}\\\"\" }\n\n      rescue HomeAssistantService::Error => e\n        results[:display] = { success: false, error: e.message }\n      end\n    end\n\n    # Build response\n    if results[:speech][:success]\n      response_parts = [ \"Made announcement\" ]\n      response_parts << \"and displayed text\" if results[:display]&.dig(:success)\n\n      success_response(\n        response_parts.join(\" \"),\n        message: message,\n        display_text: display_text,\n        volume: volume,\n        voice: voice,\n        results: results\n      )\n    else\n      error_response(\n        \"Failed to make announcement: #{results[:speech][:error]}\",\n        results: results\n      )\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/query/rag_search.rb`:\n\n```rb\n# app/services/tools/query/rag_search.rb\nclass Tools::Query::RagSearch < Tools::BaseTool\n  def self.definition\n    {\n      type: \"function\",\n      function: {\n        name: \"rag_search\",\n        description: \"Search through past conversations, events, and people using RAG (semantic search)\",\n        parameters: {\n          type: \"object\",\n          properties: {\n            query: {\n              type: \"string\",\n              description: \"What to search for (will be semantically matched against summaries, events, and people)\"\n            },\n            type: {\n              type: \"string\",\n              enum: [ \"all\", \"summaries\", \"events\", \"people\" ],\n              description: \"What type of data to search (default: all)\"\n            },\n            limit: {\n              type: \"integer\",\n              minimum: 1,\n              maximum: 10,\n              description: \"Maximum number of results to return (default: 5)\"\n            }\n          },\n          required: [ \"query\" ]\n        }\n      }\n    }\n  end\n\n  def self.description\n    \"Search past conversations, events, and people using semantic search to find relevant context and information\"\n  end\n\n  def self.prompt_schema\n    \"rag_search(query: 'search term', type: 'all|summaries|events|people', limit: 5)\"\n  end\n\n  def self.tool_type\n    :sync\n  end\n\n  def call(query:, type: \"all\", limit: 5, **_args)\n    return error_response(\"Query cannot be empty\") if query.blank?\n\n    limit = limit.clamp(1, 10)\n    results = {}\n\n    begin\n      case type.downcase\n      when \"summaries\"\n        results[:summaries] = search_summaries(query, limit)\n      when \"events\"\n        results[:events] = search_events(query, limit)\n      when \"people\"\n        results[:people] = search_people(query, limit)\n      else # \"all\"\n        # Split limit across all types\n        per_type = [ limit / 3, 1 ].max\n        results[:summaries] = search_summaries(query, per_type)\n        results[:events] = search_events(query, per_type)\n        results[:people] = search_people(query, per_type)\n      end\n\n      total_results = results.values.sum(&:count)\n\n      if total_results == 0\n        return success_response(\n          \"No results found for '#{query}'\",\n          { query: query, type: type, results: results }\n        )\n      end\n\n      success_response(\n        \"Found #{total_results} results for '#{query}'\",\n        {\n          query: query,\n          type: type,\n          total_results: total_results,\n          results: results\n        }\n      )\n\n    rescue => e\n      Rails.logger.error \"RAG search error: #{e.message}\"\n      error_response(\"Search failed: #{e.message}\")\n    end\n  end\n\n  private\n\n  def search_summaries(query, limit)\n    return [] unless defined?(Summary) && Summary.respond_to?(:similarity_search)\n\n    summaries = Summary.similarity_search(query, limit)\n    summaries.map do |summary|\n      metadata = summary.metadata_json\n      {\n        id: summary.id,\n        type: \"summary\",\n        text: summary.summary_text,\n        time_period: \"#{summary.start_time&.strftime('%m/%d %H:%M')} - #{summary.end_time&.strftime('%H:%M')}\",\n        mood: metadata[\"general_mood\"],\n        message_count: summary.message_count,\n        topics: metadata[\"topics\"] || [],\n        created_at: summary.created_at\n      }\n    end\n  end\n\n  def search_events(query, limit)\n    return [] unless defined?(Event) && Event.respond_to?(:similarity_search)\n\n    events = Event.similarity_search(query, limit)\n    events.map do |event|\n      {\n        id: event.id,\n        type: \"event\",\n        title: event.title,\n        description: event.description,\n        time: event.formatted_time,\n        location: event.location,\n        importance: event.importance,\n        upcoming: event.upcoming?,\n        created_at: event.created_at\n      }\n    end\n  end\n\n  def search_people(query, limit)\n    return [] unless defined?(Person) && Person.respond_to?(:similarity_search)\n\n    people = Person.similarity_search(query, limit)\n    people.map do |person|\n      {\n        id: person.id,\n        type: \"person\",\n        name: person.name,\n        description: person.description,\n        relationship: person.relationship,\n        last_seen: person.last_seen_at&.strftime(\"%m/%d/%Y\"),\n        created_at: person.created_at\n      }\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/effects/control_effects.rb`:\n\n```rb\n# app/services/tools/effects/control_effects.rb\nclass Tools::Effects::ControlEffects < Tools::BaseTool\n  def self.description\n    \"Control brief environmental effects like fan, strobe, blacklight, and siren with auto-toggle\"\n  end\n\n  def self.narrative_desc\n    \"control effects - manage your stage effects - you have a strobe, a giant fan (perfect for bribing hot burners or trolling htem with a duststorm), a strobe, a siren, blacklights and......a toastER?!\"\n  end\n\n  def self.prompt_schema\n    \"control_effects(effect: 'fan', action: 'on') - Control environmental effects\"\n  end\n\n  def self.tool_type\n    :async # Effect control happens after response\n  end\n\n  def self.definition\n    @definition ||= OpenRouter::Tool.define do\n      name \"control_effects\"\n      description \"Control brief environmental effects like fan, strobe lighting, blacklight, and siren (all auto-toggle off)\"\n\n      parameters do\n        string :effect, required: true,\n               description: \"Effect to control\",\n               enum: -> { Tools::Effects::ControlEffects.available_effects }\n\n        string :action, required: true,\n               description: \"Action to perform (on/off/toggle)\",\n               enum: [ \"on\", \"off\", \"toggle\" ]\n      end\n    end\n  end\n\n  def self.available_effects\n    [ \"fan\", \"strobe\", \"blacklight\", \"siren\" ]\n  end\n\n  def call(effect:, action:)\n    # Check fan cooldown before allowing fan operation\n    if effect == \"fan\" && action == \"on\"\n      begin\n        cooldown_state = HomeAssistantService.get_entity_state(\"input_boolean.fan_cooldown\")\n        if cooldown_state&.dig(\"state\") == \"on\"\n          return error_response(\n            \"Fan is in cooldown mode (power hungry - 1 hour block after use)\",\n            cooldown_remaining: \"Check fan cooldown status\"\n          )\n        end\n      rescue => e\n        Rails.logger.warn \"Could not check fan cooldown: #{e.message}\"\n      end\n    end\n\n    # Map effects to their corresponding entities (power switches preferred)\n    effect_entities = {\n      \"fan\" => \"switch.fan_switch\",         # Direct power switch\n      \"strobe\" => \"switch.strobe_switch\",   # Direct power switch\n      \"blacklight\" => \"switch.blacklight_switch\", # Direct power switch\n      \"siren\" => \"siren.small_siren\"       # Direct siren entity\n    }\n\n    entity_id = effect_entities[effect]\n    unless entity_id\n      return error_response(\n        \"Unknown effect: #{effect}\",\n        available_effects: available_effects\n      )\n    end\n\n    # Map actions to Home Assistant services\n    service_map = {\n      \"on\" => \"turn_on\",\n      \"off\" => \"turn_off\",\n      \"toggle\" => \"toggle\"\n    }\n\n    service = service_map[action]\n    unless service\n      return error_response(\n        \"Invalid action: #{action}\",\n        available_actions: service_map.keys\n      )\n    end\n\n    # Call Home Assistant service (determine domain from entity_id)\n    begin\n      domain = entity_id.split(\".\").first\n      result = HomeAssistantService.call_service(\n        domain,\n        service,\n        { entity_id: entity_id }\n      )\n\n      success_response(\n        \"#{action.capitalize}ed #{effect} effect\",\n        effect: effect,\n        action: action,\n        entity_id: entity_id,\n        service_result: result\n      )\n    rescue HomeAssistantService::Error => e\n      error_response(\"Failed to control #{effect}: #{e.message}\")\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/lights/set_effect.rb`:\n\n```rb\n# app/services/tools/lights/set_effect.rb\nclass Tools::Lights::SetEffect < Tools::BaseTool\n  def self.description\n    \"Set lighting effects on cube lights that support them.\"\n  end\n\n  def self.narrative_desc\n    \"control lights - apply special effects - describe it the best you can, and specifc music reactive or not\"\n  end\n\n  def self.prompt_schema\n    begin\n      top_entity = HomeAssistantService.entity(\"light.cube_light_top\")\n      inner_entity = HomeAssistantService.entity(\"light.cube_inner\")\n\n      top_effects = top_entity&.dig(\"attributes\", \"effect_list\")&.select { |e| e.downcase.include?(\"music\") }&.sample(4) || []\n      other_top = top_entity&.dig(\"attributes\", \"effect_list\")&.reject { |e| e.downcase.include?(\"music\") }&.sample(4) || []\n      inner_effects = inner_entity&.dig(\"attributes\", \"effect_list\")&.select { |e| e.downcase.include?(\"music\") }&.sample(4) || []\n      other_inner = inner_entity&.dig(\"attributes\", \"effect_list\")&.reject { |e| e.downcase.include?(\"music\") }&.sample(4) || []\n\n      \"set_light_effect(entity_id: 'light.cube_inner', effect: 'effect name') -\n\n      You must specify the light and effect name exactly, match case.\n      Available effects:\n      - light.cube_light_top: #{(top_effects + other_top).join(', ')}\n      - light.cube_inner: #{(inner_effects + other_inner).join(', ')}\n      No other lights support effects.\"\n    rescue\n      \"set_light_effect(entity_id: 'light.cube_inner', effect: 'Rainbow') - Set a lighting effect on cube lights only\"\n    end\n  end\n\n  def self.tool_type\n    :async\n  end\n\n  def self.definition\n    @definition ||= OpenRouter::Tool.define do\n      name \"set_light_effect\"\n      description \"Set lighting effects on cube lights that support them\"\n\n      parameters do\n        string :entity_id, required: true,\n               description: \"Light entity to control\",\n               enum: -> { Tools::Lights::SetEffect.available_entities }\n\n        string :effect, required: true,\n               description: \"Effect name to apply\"\n      end\n    end\n  end\n\n  def self.available_entities\n    CUBE_LIGHT_ENTITIES\n  end\n\n  def call(entity_id:, effect:, transition: nil)\n    # Validate entity\n    entity = validate_entity(entity_id, domain: \"light\")\n    return entity if entity.is_a?(Hash) && entity[:error]\n\n    # Ensure it's a cube light\n    unless cube_light_entities.include?(entity_id)\n      return error_response(\n        \"Entity '#{entity_id}' is not a cube light\",\n        available_lights: cube_light_entities\n      )\n    end\n\n    # Fast validation using cached effect lists (no API call needed)\n    cached_effects = cube_light_effects\n    available_effects = cached_effects[entity_id] || []\n\n    if available_effects.empty?\n      return error_response(\n        \"#{entity_id} does not support effects\",\n        entity_id: entity_id,\n        supports_effects: false\n      )\n    end\n\n    unless available_effects.include?(effect)\n      return error_response(\n        \"Effect '#{effect}' is not available for #{entity_id}\",\n        entity_id: entity_id,\n        requested_effect: effect,\n        available_effects: available_effects,\n        effects_count: available_effects.length\n      )\n    end\n\n    # Now make the actual API call to set the effect\n    begin\n\n      # Prepare service data\n      service_data = {\n        entity_id: entity_id,\n        effect: effect\n      }\n      service_data[:transition] = transition if transition\n\n      # Call Home Assistant service\n      result = HomeAssistantService.call_service(\"light\", \"turn_on\", service_data)\n\n      response_data = {\n        entity_id: entity_id,\n        effect: effect,\n        service_result: result\n      }\n      response_data[:transition] = transition if transition\n\n      success_response(\n        \"Set #{entity_id} effect to '#{effect}'\" +\n        (transition ? \" with #{transition}s transition\" : \"\"),\n        response_data\n      )\n    rescue HomeAssistantService::Error => e\n      error_response(\"Failed to set light effect: #{e.message}\")\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/lights/get_state.rb`:\n\n```rb\n# app/services/tools/lights/get_state.rb\nclass Tools::Lights::GetState < Tools::BaseTool\n  def self.description\n    \"Get current state, brightness, color, and available effects of cube lights. Shows all possible effects that can be set.\"\n  end\n\n  def self.narrative_desc\n    \"check lights - see current state\"\n  end\n\n  def self.prompt_schema\n    \"get_light_state(entity_id: 'light.cube_voice_ring') - Get current state of a cube light\"\n  end\n\n  def self.tool_type\n    :sync # Need immediate data for response\n  end\n\n  def self.definition\n    @definition ||= begin\n      tool = OpenRouter::Tool.define do\n        name \"get_light_state\"\n        description \"Get current state, brightness, color, and available effects of cube lights. Shows all possible effects that can be set.\"\n\n        parameters do\n          string :entity_id, required: true,\n                 description: \"Light entity to check\",\n                 enum: -> { Tools::Lights::GetState.available_entities }\n        end\n      end\n\n      # Add validation_blocks method to the tool object\n      def tool.validation_blocks\n        @validation_blocks ||= [\n          proc do |params, errors|\n            entity_id = params[\"entity_id\"] || params[:entity_id]\n            if entity_id && !Tools::BaseTool::CUBE_LIGHT_ENTITIES.include?(entity_id)\n              available = Tools::BaseTool::CUBE_LIGHT_ENTITIES.join(\", \")\n              errors << \"Invalid light entity '#{entity_id}'. Available cube lights: #{available}\"\n            end\n          end\n        ]\n      end\n\n      tool\n    end\n  end\n\n  def self.available_entities\n    CUBE_LIGHT_ENTITIES\n  end\n\n  # Helper method for validation\n  def self.light_is_responsive?(entity_id)\n    entity_data = HomeAssistantService.entity(entity_id)\n    entity_data.present? && entity_data[\"state\"] != \"unavailable\"\n  rescue\n    false\n  end\n\n  def call(entity_id:)\n    # Validate entity\n    entity = validate_entity(entity_id, domain: \"light\")\n    return entity if entity.is_a?(Hash) && entity[:error]\n\n    # Ensure it's a cube light\n    unless cube_light_entities.include?(entity_id)\n      return error_response(\n        \"Entity '#{entity_id}' is not a cube light\",\n        available_lights: cube_light_entities\n      )\n    end\n\n    # Get entity state\n    begin\n      entity_data = HomeAssistantService.entity(entity_id)\n\n      if entity_data.nil?\n        return error_response(\"Could not retrieve state for #{entity_id}\")\n      end\n\n      # Extract useful information\n      state = entity_data[\"state\"]\n      attributes = entity_data[\"attributes\"] || {}\n\n      response_data = {\n        entity_id: entity_id,\n        state: state,\n        is_on: state == \"on\"\n      }\n\n      # Add brightness if available\n      if attributes[\"brightness\"]\n        brightness_percent = (attributes[\"brightness\"] / 2.55).round\n        response_data[:brightness] = {\n          raw_value: attributes[\"brightness\"],\n          percentage: brightness_percent\n        }\n      end\n\n      # Add color information if available\n      if attributes[\"rgb_color\"]\n        response_data[:color] = {\n          rgb: attributes[\"rgb_color\"],\n          rgb_string: \"RGB(#{attributes['rgb_color'].join(', ')})\"\n        }\n      end\n\n      if attributes[\"hs_color\"]\n        response_data[:color] ||= {}\n        response_data[:color][:hue_saturation] = attributes[\"hs_color\"]\n      end\n\n      # Add effect if available\n      if attributes[\"effect\"]\n        response_data[:effect] = attributes[\"effect\"]\n      end\n\n      # Add supported features\n      if attributes[\"supported_color_modes\"]\n        response_data[:supported_color_modes] = attributes[\"supported_color_modes\"]\n      end\n\n      if attributes[\"supported_features\"]\n        response_data[:supported_features] = attributes[\"supported_features\"]\n      end\n\n      # Add available effects (key enhancement!)\n      if attributes[\"effect_list\"]\n        response_data[:available_effects] = attributes[\"effect_list\"]\n        response_data[:effects_count] = attributes[\"effect_list\"].length\n      else\n        response_data[:available_effects] = []\n        response_data[:effects_count] = 0\n      end\n\n      success_response(\n        \"Current state of #{entity_id}: #{state}\" +\n        (response_data[:brightness] ? \" (#{response_data[:brightness][:percentage]}% brightness)\" : \"\") +\n        (response_data[:color] ? \" #{response_data[:color][:rgb_string]}\" : \"\"),\n        response_data\n      )\n    rescue HomeAssistantService::Error => e\n      error_response(\"Failed to get light state: #{e.message}\")\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/lights/set_state.rb`:\n\n```rb\n# app/services/tools/lights/set_state.rb\nclass Tools::Lights::SetState < Tools::BaseTool\n  def self.description\n    \"Unified control for cube lights: turn on/off, set brightness, color, and transitions\"\n  end\n\n  def self.narrative_desc\n    \"control lights - unified light control\"\n  end\n\n  def self.prompt_schema\n    \"set_light_state(entity_id: 'light.cube_inner', state: 'on', brightness: 80, rgb_color: [255, 0, 0]) - Set any combination of light properties\"\n  end\n\n  def self.tool_type\n    :async # Physical world changes happen after response\n  end\n\n  def self.definition\n    @definition ||= begin\n      tool = OpenRouter::Tool.define do\n        name \"set_light_state\"\n        description \"Unified control for cube lights: turn on/off, set brightness, color, and transitions\"\n\n        parameters do\n          string :entity_id, required: true,\n                 description: \"Light entity to control\",\n                 enum: -> { Tools::Lights::SetState.available_entities }\n\n          string :state, required: true,\n                 description: \"Turn light on or off pass on even if on to change state\",\n                 enum: %w[on off]\n\n          number :brightness, minimum: 0, maximum: 100,\n                 description: \"Brightness percentage (0-100)\"\n\n          string :rgb_color,\n                 description: \"RGB color as comma-separated string 'R,G,B' values (0-255). Example: '255,0,0' for red, '0,255,0' for green\"\n\n          number :transition, minimum: 0, maximum: 60,\n                 description: \"Transition time in seconds for smooth changes\"\n        end\n      end\n\n      # Add validation_blocks method to the tool object\n      def tool.validation_blocks\n        @validation_blocks ||= [\n          proc do |params, errors|\n            # Convert symbol keys to string keys for consistency\n            params = params.transform_keys(&:to_s)\n\n            # 1. Entity validation with suggestions\n            if params[\"entity_id\"] && !Tools::BaseTool::CUBE_LIGHT_ENTITIES.include?(params[\"entity_id\"])\n              available = Tools::BaseTool::CUBE_LIGHT_ENTITIES.join(\", \")\n              errors << \"Invalid light entity '#{params[\"entity_id\"]}'. Available cube lights: #{available}\"\n            end\n\n            # 2. RGB color validation with examples\n            if params[\"rgb_color\"]\n              if !params[\"rgb_color\"].is_a?(String)\n                errors << \"rgb_color must be a comma-separated string, e.g., '255,0,0' for red, '0,255,0' for green\"\n              else\n                # Parse and validate RGB string\n                rgb_parts = params[\"rgb_color\"].split(\",\").map(&:strip)\n                if rgb_parts.length != 3\n                  errors << \"rgb_color must have exactly 3 values separated by commas, e.g., '255,0,0'\"\n                else\n                  rgb_values = rgb_parts.map { |v| v.to_i rescue nil }\n                  if rgb_values.any?(&:nil?) || rgb_values.any? { |v| v < 0 || v > 255 }\n                    errors << \"RGB values must be integers 0-255. Got: #{params[\"rgb_color\"]}\"\n                  elsif params[\"rgb_color\"] == \"0,0,0\"\n                    errors << \"RGB '0,0,0' is black (no light). Did you mean to set state: 'off' instead?\"\n                  end\n                end\n              end\n            end\n\n            # 3. Logical validation\n            if params[\"state\"] == \"off\" && (params[\"brightness\"] || params[\"rgb_color\"])\n              errors << \"Cannot set brightness, color, when turning light off. Use state: 'on' instead.\"\n            end\n\n\n            # 4. Brightness warnings\n            if params[\"brightness\"] && params[\"brightness\"] < 5 && params[\"state\"] == \"on\"\n              errors << \"Brightness #{params[\"brightness\"]}% is very dim. Consider 20% or higher for visibility.\"\n            end\n          end\n        ]\n      end\n\n      tool\n    end\n  end\n\n  def self.available_entities\n    CUBE_LIGHT_ENTITIES\n  end\n\n  # Helper method for validation - get live effects for an entity\n\n\n  # Helper method for validation - check if light is responsive\n  def self.light_is_responsive?(entity_id)\n    entity_data = HomeAssistantService.entity(entity_id)\n    entity_data.present? && entity_data[\"state\"] != \"unavailable\"\n  rescue\n    false\n  end\n\n  def call(entity_id:, state: nil, brightness: nil, rgb_color: nil, effect: nil, transition: nil)\n    # Convert string RGB to array if provided\n    if rgb_color.is_a?(String)\n      rgb_color = rgb_color.split(\",\").map(&:strip).map(&:to_i) rescue nil\n      if rgb_color.nil? || rgb_color.length != 3\n        return error_response(\n          \"Invalid rgb_color format. Must be 'R,G,B' with values 0-255\",\n          example: \"255,128,0\"\n        )\n      end\n    end\n\n    # Validate entity\n    entity = validate_entity(entity_id, domain: \"light\")\n    return entity if entity.is_a?(Hash) && entity[:error]\n\n    # Ensure it's a cube light\n    unless cube_light_entities.include?(entity_id)\n      return error_response(\n        \"Entity '#{entity_id}' is not a cube light\",\n        available_lights: cube_light_entities\n      )\n    end\n\n    # Must specify at least one parameter\n    if [ state, brightness, rgb_color, transition ].all?(&:nil?)\n      return error_response(\n        \"Must specify at least one parameter to change\",\n        examples: {\n          turn_on: { entity_id: entity_id, state: \"on\" },\n          set_brightness: { entity_id: entity_id, brightness: 75 },\n          set_color: { entity_id: entity_id, rgb_color: [ 255, 0, 0 ] }\n        }\n      )\n    end\n\n    # Handle off state specially\n    if state == \"off\"\n      begin\n        result = HomeAssistantService.call_service(\"light\", \"turn_off\", { entity_id: entity_id })\n        return success_response(\n          \"Turned off #{entity_id}\",\n          { entity_id: entity_id, state: \"off\", service_result: result }\n        )\n      rescue HomeAssistantService::Error => e\n        return error_response(\"Failed to turn off light: #{e.message}\")\n      end\n    end\n\n    # Prepare service data for turn_on\n    service_data = { entity_id: entity_id }\n    changes = []\n\n    # Add brightness if provided\n    if brightness\n      formatted_brightness = format_brightness(brightness)\n      if formatted_brightness.nil?\n        return error_response(\n          \"Invalid brightness. Must be number between 0-100\",\n          example: 75\n        )\n      end\n      service_data[:brightness] = formatted_brightness\n      changes << \"brightness: #{brightness}%\"\n    end\n\n    # Add RGB color if provided\n    if rgb_color\n      formatted_rgb = format_rgb_color(rgb_color)\n      if formatted_rgb.nil?\n        return error_response(\n          \"Invalid rgb_color. Must be array of 3 integers (0-255)\",\n          example: [ 255, 128, 0 ]\n        )\n      end\n      service_data[:rgb_color] = formatted_rgb\n      changes << \"color: RGB(#{rgb_color.join(', ')})\"\n    end\n\n    # Add transition if provided\n    if transition\n      service_data[:transition] = transition\n      changes << \"transition: #{transition}s\"\n    end\n\n    # Call Home Assistant service\n    begin\n      result = HomeAssistantService.call_service(\"light\", \"turn_on\", service_data)\n\n      response_data = {\n        entity_id: entity_id,\n        service_result: result,\n        changes_applied: changes\n      }\n\n      # Include the parameters that were set\n      response_data[:state] = state if state\n      response_data[:brightness] = brightness if brightness\n      response_data[:rgb_color] = rgb_color if rgb_color\n      response_data[:transition] = transition if transition\n\n      success_response(\n        \"Set #{entity_id}\" + (changes.any? ? \" - #{changes.join(', ')}\" : \"\"),\n        response_data\n      )\n    rescue HomeAssistantService::Error => e\n      error_response(\"Failed to set light state: #{e.message}\")\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tools/lights/list_effects.rb`:\n\n```rb\n# app/services/tools/lights/list_effects.rb\nclass Tools::Lights::ListEffects < Tools::BaseTool\n  def self.description\n    \"List available effects for cube lights\"\n  end\n\n  def self.narrative_desc\n    \"check lights - see available effects\"\n  end\n\n  def self.prompt_schema\n    music_effects = []\n    other_effects = []\n\n    begin\n      top_entity = HomeAssistantService.entity(\"light.cube_light_top\")\n      inner_entity = HomeAssistantService.entity(\"light.cube_inner\")\n\n      all_effects = []\n      all_effects += top_entity[\"attributes\"][\"effect_list\"] if top_entity&.dig(\"attributes\", \"effect_list\")\n      all_effects += inner_entity[\"attributes\"][\"effect_list\"] if inner_entity&.dig(\"attributes\", \"effect_list\")\n      all_effects = all_effects.uniq.compact.reject(&:empty?)\n\n      music_effects = all_effects.select { |e| e.downcase.include?(\"music\") }\n      other_effects = all_effects.reject { |e| e.downcase.include?(\"music\") }\n    rescue\n      music_effects = [ \"Music: Beat\", \"Music: Rhythm\", \"Music reactive jazz\", \"Music: Spectrum\" ]\n      other_effects = [ \"Rainbow\", \"Fire\", \"Aurora\", \"Breathe\", \"Cyberpunk\", \"Ocean\", \"Sunset\", \"Forest\" ]\n    end\n\n    random_music = music_effects.sample(4)\n    random_other = other_effects.sample(4)\n    all_random = (random_music + random_other).join(\", \")\n\n    \"Available light effects: #{all_random}\"\n  end\n\n  def self.tool_type\n    :async # Two-tier mode: all tools are async, effects included in prompts\n  end\n\n  def self.definition\n    @definition ||= OpenRouter::Tool.define do\n      name \"list_light_effects\"\n      description \"List available effects for cube lights\"\n\n      parameters do\n        string :entity_id, required: true,\n               description: \"Light entity to check for available effects\",\n               enum: -> { Tools::Lights::ListEffects.available_entities }\n      end\n    end\n  end\n\n  def self.available_entities\n    CUBE_LIGHT_ENTITIES\n  end\n\n  def call(entity_id:)\n    # Validate entity\n    entity = validate_entity(entity_id, domain: \"light\")\n    return entity if entity.is_a?(Hash) && entity[:error]\n\n    # Ensure it's a cube light\n    unless cube_light_entities.include?(entity_id)\n      return error_response(\n        \"Entity '#{entity_id}' is not a cube light\",\n        available_lights: cube_light_entities\n      )\n    end\n\n    # Get entity state and effects\n    begin\n      entity_data = HomeAssistantService.entity(entity_id)\n\n      if entity_data.nil?\n        return error_response(\"Could not retrieve data for #{entity_id}\")\n      end\n\n      attributes = entity_data[\"attributes\"] || {}\n      effect_list = attributes[\"effect_list\"] || []\n      current_effect = attributes[\"effect\"]\n\n      if effect_list.empty?\n        return success_response(\n          \"#{entity_id} does not support effects\",\n          entity_id: entity_id,\n          supports_effects: false,\n          available_effects: []\n        )\n      end\n\n      success_response(\n        \"#{entity_id} supports #{effect_list.length} effects\" +\n        (current_effect ? \" (current: #{current_effect})\" : \"\"),\n        {\n          entity_id: entity_id,\n          supports_effects: true,\n          available_effects: effect_list,\n          current_effect: current_effect,\n          effect_count: effect_list.length\n        }\n      )\n    rescue HomeAssistantService::Error => e\n      error_response(\"Failed to get effects list: #{e.message}\")\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/tool_calling_service.rb`:\n\n```rb\n# app/services/tool_calling_service.rb\n#\n# Tool-Calling LLM Service - Technical tier of two-tier architecture\n# Receives natural language intent from narrative LLM and translates to precise tool calls\nclass ToolCallingService\n  def initialize(session_id: nil, conversation_id: nil)\n    @session_id = session_id\n    @conversation_id = conversation_id\n    @max_iterations = Rails.configuration.try(:tool_calling_max_iterations) || 5\n  end\n\n  # Execute tool intent from narrative LLM\n  # @param intent [String] Natural language description of what to do\n  # @param context [Hash] Additional context from conversation\n  # @return [Hash] Success/failure with natural language description\n  def execute_intent(intent, context = {})\n    Rails.logger.info \"🔧 ToolCallingService executing intent: #{intent}\"\n\n    # Retry loop for handling validation errors\n    iteration = 1\n    current_intent = intent\n\n    while iteration <= @max_iterations\n      Rails.logger.info \"🔄 Tool calling attempt #{iteration}/#{@max_iterations}\"\n\n      # Call LLM to translate intent to tool calls\n      tool_calls_response = call_tool_calling_llm(current_intent, context)\n\n      return error_response(\"Failed to generate tool calls\") unless tool_calls_response\n\n      # Execute the tool calls\n      results = execute_tool_calls(tool_calls_response.tool_calls)\n\n      # Check if we have validation failures that need retrying\n      validation_errors = extract_validation_errors(results)\n\n      if validation_errors.empty?\n        # Success or non-validation errors - return result\n        return format_results_for_narrative(results, intent)\n      end\n\n      # If we have validation errors and iterations left, retry with error feedback\n      if iteration < @max_iterations\n        Rails.logger.warn \"⚠️ Validation errors in iteration #{iteration}, retrying with feedback\"\n        current_intent = build_retry_intent(intent, validation_errors)\n        iteration += 1\n      else\n        Rails.logger.error \"❌ Max iterations reached with validation errors\"\n        break\n      end\n    end\n\n    # Return results after max iterations\n    format_results_for_narrative(results, intent)\n  end\n\n  private\n\n  def call_tool_calling_llm(intent, context)\n    prompt = build_tool_calling_prompt(intent, context)\n    model = determine_tool_calling_model\n\n    # Get persona from context, default to 'jax'\n    persona = context&.dig(:persona) || \"jax\"\n\n    Rails.logger.info \"🚀 Calling tool-calling LLM (#{model}) with persona-specific tools for #{persona}\"\n\n    LlmService.call_with_tools(\n      messages: prompt,\n      tools: Tools::Registry.tool_definitions_for_two_tier_mode(persona), # Only persona-specific tools\n      model: model,\n      temperature: 0.1 # Low temperature for precise technical execution\n    )\n  end\n\n  def determine_tool_calling_model\n    # Use configured tool-calling model, default_tools_model, or fall back to default AI model\n    Rails.configuration.try(:tool_calling_model) ||\n    Rails.configuration.try(:default_tools_model) ||\n    Rails.configuration.default_ai_model\n  end\n\n  def build_tool_calling_prompt(intent, context)\n    [\n      {\n        role: \"system\",\n        content: <<~SYSTEM\n          You are a technical tool execution service. Your job is to translate natural language intent into precise tool calls.\n\n          USER INTENT: #{intent}\n\n          CONTEXT: #{context.to_json}\n\n          IMPORTANT RULES:\n          - Use EXACT parameter names from tool definitions\n          - Make the precise tool calls needed to fulfill the intent.\n          - You are allowed to reason and guess if it isn't obvious.\n          - If you make errors you will be told them and should try to correct yourself\n          - Pay attention to schemas.\n          - Do your best! Burning Man depends on you!\n          SYSTEM\n      },\n      {\n        role: \"user\",\n        content: \"Execute this intent: #{intent}\"\n      }\n    ]\n  end\n\n  def execute_tool_calls(tool_calls)\n    return {} unless tool_calls&.any?\n\n    results = {}\n    tool_executor = ToolExecutor.new\n    categorized = tool_executor.categorize_tool_calls(tool_calls)\n\n    # Execute sync tools immediately\n    if categorized[:sync_tools].any?\n      sync_results = tool_executor.execute_sync(categorized[:sync_tools])\n      results.merge!(sync_results)\n    end\n\n    # Queue async tools\n    if categorized[:async_tools].any?\n      tool_executor.execute_async(categorized[:async_tools],\n                                 session_id: @session_id,\n                                 conversation_id: @conversation_id)\n\n      # Note async tools for result formatting\n      categorized[:async_tools].each do |tool_call|\n        tool_name = tool_call.respond_to?(:name) ? tool_call.name : tool_call[\"name\"]\n        results[tool_name] = { success: true, message: \"Queued for execution\", async: true }\n      end\n    end\n\n    results\n  end\n\n  def format_results_for_narrative(results, original_intent)\n    return \"I'll handle that.\" if results.empty?\n\n    successes = []\n    failures = []\n    async_actions = []\n\n    results.each do |tool_name, result|\n      # Use consistent string key access\n      async = HashUtils.get(result, \"async\") || false\n      success = HashUtils.get(result, \"success\") || false\n      error = HashUtils.get(result, \"error\")\n\n      if async\n        async_actions << humanize_tool_name(tool_name)\n      elsif success\n        successes << humanize_tool_name(tool_name)\n      else\n        failures << \"#{humanize_tool_name(tool_name)} (#{error})\"\n      end\n    end\n\n    response_parts = []\n\n    if async_actions.any?\n      response_parts << \"I'm #{async_actions.join(' and ')}\"\n    end\n\n    if successes.any?\n      response_parts << \"#{successes.join(' and ')} completed\"\n    end\n\n    if failures.any?\n      response_parts << \"but #{failures.join(' and ')} failed\"\n    end\n\n    response_parts.any? ? response_parts.join(\", \") : \"Working on it.\"\n  end\n\n  def humanize_tool_name(tool_name)\n    case tool_name\n    when \"turn_on_light\"\n      \"turning on the lights\"\n    when \"turn_off_light\"\n      \"turning off the lights\"\n    when \"set_light_color_and_brightness\"\n      \"adjusting the lighting\"\n    when \"set_light_effect\"\n      \"setting a light effect\"\n    when \"get_light_state\"\n      \"checking light status\"\n    when \"play_music\"\n      \"playing music\"\n    when \"display_notification\"\n      \"displaying a message\"\n    when \"control_effects\"\n      \"controlling environmental effects\"\n    when \"mode_control\"\n      \"changing operational mode\"\n    when \"make_announcement\"\n      \"making an announcement\"\n    else\n      tool_name.humanize.downcase\n    end\n  end\n\n  def extract_validation_errors(results)\n    validation_errors = []\n\n    results.each do |tool_name, result|\n      next unless result.is_a?(Hash)\n\n      # Use consistent string key access\n      success = HashUtils.get(result, \"success\")\n      error = HashUtils.get(result, \"error\")\n      details = HashUtils.get(result, \"details\")\n      available_effects = HashUtils.get(result, \"available_effects\")\n      available_modes = HashUtils.get(result, \"available_modes\")\n      available_actions = HashUtils.get(result, \"available_actions\")\n      available_lights = HashUtils.get(result, \"available_lights\")\n\n      next if success\n\n      # Handle control_effects validation errors specifically\n      if tool_name == \"control_effects\" && error&.include?(\"Unknown effect:\")\n        validation_errors << {\n          tool: tool_name,\n          error: error,\n          available_options: available_effects\n        }\n      # Handle other validation errors from tool executor\n      elsif error == \"Validation failed\" || details&.any?\n        validation_errors << {\n          tool: tool_name,\n          error: details&.first || error,\n          details: details\n        }\n      # Handle mode_control validation errors\n      elsif tool_name == \"mode_control\" && (error&.include?(\"Unknown mode:\") || error&.include?(\"Invalid action:\"))\n        validation_errors << {\n          tool: tool_name,\n          error: error,\n          available_options: available_modes || available_actions\n        }\n      # Handle light effect validation errors\n      elsif tool_name == \"set_light_effect\" && error&.include?(\"not available\")\n        validation_errors << {\n          tool: tool_name,\n          error: error,\n          available_options: available_effects\n        }\n      # Handle get_light_state validation errors\n      elsif tool_name == \"get_light_state\" && error&.include?(\"not a cube light\")\n        validation_errors << {\n          tool: tool_name,\n          error: error,\n          available_options: available_lights\n        }\n      end\n    end\n\n    validation_errors\n  end\n\n  def build_retry_intent(original_intent, validation_errors)\n    error_feedback = validation_errors.map do |error|\n      if error[:available_options]\n        \"#{error[:error]} Available options: #{error[:available_options]}\"\n      else\n        \"#{error[:tool]} error: #{error[:error]}\"\n      end\n    end.join(\". \")\n\n    \"#{original_intent}\\n\\nIMPORTANT CORRECTIONS NEEDED: #{error_feedback}. Please fix these issues and try again.\"\n  end\n\n  def error_response(message)\n    {\n      success: false,\n      error: message,\n      natural_response: \"I'm having trouble with that right now.\"\n    }\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/goal_service.rb`:\n\n```rb\n# app/services/goal_service.rb\n\nclass GoalService\n  class << self\n    GOALS_FILE = Rails.root.join(\"data\", \"goals.yml\")\n\n    # Cache keys for current goal state\n    CURRENT_GOAL_KEY = \"current_goal\"\n    GOAL_STARTED_AT_KEY = \"current_goal_started_at\"\n    GOAL_TIME_LIMIT_KEY = \"current_goal_max_time_limit\"\n    LAST_CATEGORY_KEY = \"last_goal_category\"\n\n    # Check if safety mode is currently active\n    def safety_mode_active?\n      ha_service = HomeAssistantService.new\n\n      # Check explicit safety mode toggle\n      safety_mode = ha_service.entity(\"input_boolean.safety_mode\")\n      return true if safety_mode&.dig(\"state\") == \"on\"\n\n      # Check battery level for critical status\n      battery_level_critical?\n    rescue StandardError => e\n      Rails.logger.error \"Failed to check safety mode: #{e.message}\"\n      false\n    end\n\n    # Check if battery level is critical\n    def battery_level_critical?\n      HaDataSync.low_power_mode?\n    rescue StandardError => e\n      Rails.logger.error \"Failed to check battery level: #{e.message}\"\n      false\n    end\n\n    # Load all goals from YAML\n    def load_goals\n      return {} unless File.exist?(GOALS_FILE)\n      YAML.load_file(GOALS_FILE) || {}\n    rescue StandardError => e\n      Rails.logger.error \"Failed to load goals: #{e.message}\"\n      {}\n    end\n\n    # Select and set a new goal based on current conditions\n    def select_goal(time_limit: 2.hours)\n      Rails.logger.info \"🎯 Selecting new goal\"\n\n      goals_data = load_goals\n      return nil if goals_data.empty?\n\n      # Get last category to avoid repeating\n      last_category = Rails.cache.read(LAST_CATEGORY_KEY)\n\n      # Determine which categories are appropriate based on safety mode\n      if safety_mode_active?\n        # In safety mode, prioritize safety goals\n        available_categories = goals_data.keys.select { |key| key.include?(\"safety\") }\n        available_categories = goals_data.keys if available_categories.empty? # Fallback\n      else\n        # Normal mode - prefer non-safety goals\n        available_categories = goals_data.keys.reject { |key| key.include?(\"safety\") }\n        available_categories = goals_data.keys if available_categories.empty? # Fallback\n      end\n\n      # Exclude the last category used if we have multiple options\n      available_categories = available_categories.reject { |cat| cat == last_category } if last_category && available_categories.size > 1\n\n      # Select random category from available ones\n      selected_category = available_categories.sample\n      selected_goal = select_random_goal_from_category(goals_data[selected_category], selected_category)\n\n      Rails.logger.info \"🎲 Selected goal from #{selected_category}: #{selected_goal}\"\n\n      return nil unless selected_goal\n\n      # Store goal state in cache\n      Rails.cache.write(CURRENT_GOAL_KEY, selected_goal)\n      Rails.cache.write(GOAL_STARTED_AT_KEY, Time.current)\n      Rails.cache.write(GOAL_TIME_LIMIT_KEY, time_limit)\n      Rails.cache.write(LAST_CATEGORY_KEY, selected_category)\n\n      # Update Home Assistant sensors\n      update_home_assistant_goal_sensors(selected_goal, Time.current, time_limit)\n\n      selected_goal\n    end\n\n    # Get current goal status\n    def current_goal_status\n      goal = Rails.cache.read(CURRENT_GOAL_KEY)\n      return nil unless goal\n\n      started_at = Rails.cache.read(GOAL_STARTED_AT_KEY)\n      time_limit = Rails.cache.read(GOAL_TIME_LIMIT_KEY) || 2.hours\n\n      {\n        goal_id: goal[:id],\n        goal_description: goal[:description],\n        category: goal[:category],\n        started_at: started_at,\n        time_limit: time_limit,\n        time_remaining: calculate_time_remaining(started_at, time_limit),\n        expired: goal_expired?\n      }\n    end\n\n    # Check if current goal has expired\n    def goal_expired?\n      started_at = Rails.cache.read(GOAL_STARTED_AT_KEY)\n      time_limit = Rails.cache.read(GOAL_TIME_LIMIT_KEY)\n\n      return false unless started_at && time_limit\n\n      Time.current > (started_at + time_limit)\n    end\n\n    # Complete current goal and store in Summary\n    def complete_goal(completion_notes: nil)\n      goal_status = current_goal_status\n      return false unless goal_status\n\n      duration = Time.current - goal_status[:started_at]\n\n      Rails.logger.info \"✅ Completing goal: #{goal_status[:goal_description]}\"\n\n      # Store completion in Summary model\n      Summary.create!(\n        summary_type: \"goal_completion\",\n        summary_text: \"Completed goal: #{goal_status[:goal_description]}\",\n        start_time: goal_status[:started_at],\n        end_time: Time.current,\n        message_count: 1, # Required field, set to 1 for goal completions\n        metadata: {\n          goal_id: goal_status[:goal_id],\n          goal_category: goal_status[:category],\n          duration_seconds: duration.to_i,\n          completion_notes: completion_notes,\n          expired: goal_status[:expired]\n        }.to_json\n      )\n\n      # Clear current goal from cache\n      clear_current_goal\n\n      # Update Home Assistant sensors\n      clear_home_assistant_goal_sensors\n\n      true\n    rescue StandardError => e\n      Rails.logger.error \"❌ Failed to complete goal: #{e.message}\"\n      false\n    end\n\n    # Get all completed goals\n    def all_completed_goals\n      Summary.where(summary_type: \"goal_completion\").recent.map do |summary|\n        metadata = summary.metadata_json\n        {\n          goal_id: metadata[\"goal_id\"],\n          goal_category: metadata[\"goal_category\"],\n          description: summary.summary_text,\n          completed_at: summary.created_at,\n          duration: metadata[\"duration_seconds\"],\n          completion_notes: metadata[\"completion_notes\"],\n          expired: metadata[\"expired\"]\n        }\n      end\n    end\n\n    # Force goal switch (for persona agency)\n    def request_new_goal(reason: \"persona_request\", time_limit: 2.hours)\n      Rails.logger.info \"🔄 Goal switch requested: #{reason}\"\n\n      # Complete current goal first if it exists\n      if current_goal_status\n        complete_goal(completion_notes: \"Switched due to: #{reason}\")\n      end\n\n      # Select new goal\n      select_goal(time_limit: time_limit)\n    end\n\n    private\n\n    def select_random_goal_from_category(category_goals, category_name)\n      return nil unless category_goals && category_goals.any?\n\n      # Convert to array of goal objects with metadata\n      goals_array = category_goals.map do |goal_id, goal_data|\n        # Handle both string format and object format\n        description = goal_data.is_a?(String) ? goal_data : goal_data[\"description\"]\n\n        {\n          id: goal_id,\n          description: description,\n          category: category_name\n        }\n      end\n\n      goals_array.sample\n    end\n\n    def calculate_time_remaining(started_at, time_limit)\n      return nil unless started_at && time_limit\n\n      elapsed = Time.current - started_at\n      remaining = time_limit - elapsed\n\n      [ remaining, 0 ].max # Don't return negative time\n    end\n\n    def clear_current_goal\n      Rails.cache.delete(CURRENT_GOAL_KEY)\n      Rails.cache.delete(GOAL_STARTED_AT_KEY)\n      Rails.cache.delete(GOAL_TIME_LIMIT_KEY)\n      # Note: We keep LAST_CATEGORY_KEY to prevent repeating categories\n    end\n\n    # Update Home Assistant sensors with goal state\n    def update_home_assistant_goal_sensors(goal, started_at, time_limit)\n      ha_service = HomeAssistantService.new\n\n      # Update current goal sensor\n      ha_service.set_entity_state(\n        \"sensor.glitchcube_current_goal\",\n        goal[:description],\n        {\n          friendly_name: \"GlitchCube Current Goal\",\n          icon: \"mdi:target\",\n          goal_id: goal[:id],\n          goal_category: goal[:category],\n          started_at: started_at.iso8601,\n          time_limit_minutes: (time_limit / 60).to_i,\n          expires_at: (started_at + time_limit).iso8601,\n          last_updated: Time.current.iso8601\n        }\n      )\n\n      # Update world state sensor with goal info\n      update_world_state_goal_attributes(goal, started_at, time_limit)\n\n      Rails.logger.info \"📊 Updated Home Assistant goal sensors\"\n    rescue StandardError => e\n      Rails.logger.error \"❌ Failed to update Home Assistant goal sensors: #{e.message}\"\n    end\n\n    # Clear Home Assistant goal sensors when goal completes\n    def clear_home_assistant_goal_sensors\n      ha_service = HomeAssistantService.new\n\n      ha_service.set_entity_state(\n        \"sensor.glitchcube_current_goal\",\n        \"No active goal\",\n        {\n          friendly_name: \"GlitchCube Current Goal\",\n          icon: \"mdi:target-variant\",\n          goal_id: nil,\n          goal_category: nil,\n          started_at: nil,\n          time_limit_minutes: nil,\n          expires_at: nil,\n          last_updated: Time.current.iso8601\n        }\n      )\n\n      # Clear goal info from world state sensor\n      clear_world_state_goal_attributes\n\n      Rails.logger.info \"📊 Cleared Home Assistant goal sensors\"\n    rescue StandardError => e\n      Rails.logger.error \"❌ Failed to clear Home Assistant goal sensors: #{e.message}\"\n    end\n\n    # Update world state sensor with goal information\n    def update_world_state_goal_attributes(goal, started_at, time_limit)\n      current_attributes = fetch_current_world_state_attributes\n\n      new_attributes = current_attributes.merge(\n        \"current_goal\" => goal[:description],\n        \"goal_category\" => goal[:category],\n        \"goal_started_at\" => started_at.iso8601,\n        \"goal_expires_at\" => (started_at + time_limit).iso8601,\n        \"goal_updated_at\" => Time.current.iso8601\n      )\n\n      HomeAssistantService.set_entity_state(\n        \"sensor.world_state\",\n        \"active\",\n        new_attributes\n      )\n    rescue StandardError => e\n      Rails.logger.error \"❌ Failed to update world state goal attributes: #{e.message}\"\n    end\n\n    # Clear goal attributes from world state sensor\n    def clear_world_state_goal_attributes\n      current_attributes = fetch_current_world_state_attributes\n\n      new_attributes = current_attributes.merge(\n        \"current_goal\" => nil,\n        \"goal_category\" => nil,\n        \"goal_started_at\" => nil,\n        \"goal_expires_at\" => nil,\n        \"goal_updated_at\" => Time.current.iso8601\n      )\n\n      HomeAssistantService.set_entity_state(\n        \"sensor.world_state\",\n        \"active\",\n        new_attributes\n      )\n    rescue StandardError => e\n      Rails.logger.error \"❌ Failed to clear world state goal attributes: #{e.message}\"\n    end\n\n    # Get current world state sensor attributes\n    def fetch_current_world_state_attributes\n      ha_service = HomeAssistantService.new\n      world_state = ha_service.entity(\"sensor.world_state\")\n\n      if world_state&.dig(\"attributes\")\n        world_state[\"attributes\"]\n      else\n        # Initialize sensor if it doesn't exist\n        Rails.logger.info \"📊 Initializing world_state sensor with default attributes\"\n        default_attributes = {\n          \"friendly_name\" => \"World State\",\n          \"icon\" => \"mdi:earth\",\n          \"last_updated\" => Time.current.iso8601,\n          \"system_version\" => Rails.application.class.module_parent_name,\n          \"environment\" => Rails.env\n        }\n\n        # Create the sensor with default attributes\n        ha_service.set_entity_state(\"sensor.world_state\", \"active\", default_attributes)\n        default_attributes\n      end\n    rescue StandardError => e\n      Rails.logger.error \"Failed to fetch world state attributes: #{e.message}\"\n      {} # Return empty hash on any error\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/memory/memory_recall_service.rb`:\n\n```rb\n# frozen_string_literal: true\n\nmodule Memory\n  class MemoryRecallService\n    class << self\n      # Get relevant memories for injection into conversation\n      def get_relevant_memories(location: nil, context: {}, limit: 3)\n          selected_memories = []\n\n          # 1. Get location-related memories if we have location\n          if location.present?\n            location_memories = ConversationMemory.high_importance\n                                                  .recent\n                                                  .limit(2)\n                                                  .select { |memory|\n                                                    metadata = JSON.parse(memory.metadata || \"{}\")\n                                                    locations = metadata[\"locations\"] || []\n                                                    locations.any? { |loc| loc.downcase.include?(location.downcase) }\n                                                  }\n            selected_memories.concat(location_memories)\n          end\n\n          # 2. Fill remaining slots with recent high-importance memories\n          remaining_slots = limit - selected_memories.size\n          if remaining_slots.positive?\n            recent_memories = ConversationMemory.high_importance\n                                                .recent\n                                                .where.not(id: selected_memories.map(&:id))\n                                                .limit(remaining_slots)\n            selected_memories.concat(recent_memories)\n          end\n\n          selected_memories.uniq.take(limit)\n        end\n\n        # Get upcoming events for context\n        def get_upcoming_events(location: nil, hours: 24)\n          scope = Event.upcoming.within_hours(hours).high_importance\n          scope = scope.by_location(location) if location.present?\n          scope.limit(3)\n        end\n\n        # Get location-based memories\n        def get_location_memories(location, limit: 3)\n          return [] if location.blank?\n\n          ConversationMemory.high_importance\n                            .recent\n                            .limit(limit * 2) # Get more to filter\n                            .select { |memory|\n                              metadata = JSON.parse(memory.metadata || \"{}\")\n                              locations = metadata[\"locations\"] || []\n                              locations.any? { |loc| loc.downcase.include?(location.downcase) }\n                            }\n                            .take(limit)\n        end\n\n        # Format memories for conversation injection\n        def format_for_context(memories)\n          return \"\" if memories.empty?\n\n          formatted = memories.map do |memory|\n            # Add variety to how memories are introduced\n            intro = memory_introduction(memory)\n            \"#{intro} #{memory.summary}\"\n          end\n\n          \"\\n\\nRECENT MEMORIES TO NATURALLY REFERENCE:\\n#{formatted.join(\"\\n\")}\\n\"\n        end\n\n        # Get trending memories (high importance, recent)\n        def get_trending_memories(limit: 5)\n          ConversationMemory.high_importance\n                            .recent\n                            .limit(limit)\n        end\n\n        # Get memories related to specific topics (simple keyword search)\n        def get_topic_memories(keywords, limit: 3)\n          return [] if keywords.blank?\n\n          keyword_array = keywords.is_a?(Array) ? keywords : [ keywords ]\n\n          ConversationMemory.recent\n                            .limit(limit * 3) # Get more to filter\n                            .select { |memory|\n                              keyword_array.any? { |keyword|\n                                memory.summary.downcase.include?(keyword.downcase)\n                              }\n                            }\n                            .take(limit)\n        end\n\n        # Get recent high importance memories excluding current session\n        def get_recent_memories_excluding_session(session_id, limit: 3)\n          scope = ConversationMemory.high_importance.recent\n          scope = scope.where.not(session_id: session_id) if session_id.present?\n          scope.limit(limit)\n        end\n\n        private\n\n        def memory_introduction(memory)\n          # Simple intros based on memory type and content\n          case memory.memory_type\n          when \"event\"\n            [ \"That reminds me,\", \"Oh!\", \"By the way,\", \"Speaking of which,\" ].sample\n          when \"preference\"\n            [ \"I remember you mentioned\", \"You said before that\", \"I recall\" ].sample\n          when \"fact\"\n            [ \"You know,\", \"I learned that\", \"Remember,\" ].sample\n          when \"instruction\"\n            [ \"You told me to\", \"You wanted me to\", \"You asked me to\" ].sample\n          else\n            [ \"That reminds me,\", \"Oh!\", \"By the way,\" ].sample\n          end\n        end\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/memory/memory_extraction_service.rb`:\n\n```rb\n# frozen_string_literal: true\n\n# Memory::MemoryExtractionService\n# Analyzes summaries and extracts future events and key memories for storage\n# Called by IntermediateSummarizerJob after creating synthesis summaries\nmodule Memory\n  class MemoryExtractionService\n    class Error < StandardError; end\n\n    def self.call(summary)\n      new(summary).call\n    end\n\n    def initialize(summary)\n      @summary = summary\n      @metadata = summary.metadata_json\n    end\n\n    def call\n      Rails.logger.info \"🧠 Extracting memories and events from summary ID: #{@summary.id}\"\n\n      extracted_events = extract_and_create_events\n      extracted_memories = extract_and_create_memories\n\n      # Update summary metadata with extraction results\n      update_summary_with_extraction_results(extracted_events.count, extracted_memories.count)\n\n      {\n        events_created: extracted_events.count,\n        memories_created: extracted_memories.count,\n        summary_id: @summary.id\n      }\n\n    rescue StandardError => e\n      Rails.logger.error \"❌ Memory extraction failed for summary #{@summary.id}: #{e.message}\"\n      raise Error, \"Failed to extract memories: #{e.message}\"\n    end\n\n    private\n\n    def extract_and_create_events\n      future_events = @metadata[\"future_events_detected\"] || []\n      created_events = []\n\n      future_events.each do |event_data|\n        next unless event_data.is_a?(Hash) && event_data[\"description\"].present?\n\n        event = create_event_from_detection(event_data)\n        created_events << event if event\n      end\n\n      Rails.logger.info \"📅 Created #{created_events.count} events from summary extraction\"\n      created_events\n    end\n\n    def extract_and_create_memories\n      key_memories = @metadata[\"key_memories_detected\"] || []\n      created_memories = []\n\n      key_memories.each do |memory_data|\n        next unless memory_data.is_a?(Hash) && memory_data[\"memory\"].present?\n\n        memory = create_memory_from_detection(memory_data)\n        created_memories << memory if memory\n      end\n\n      # Also extract insights from key_insights field as memories\n      key_insights = @metadata[\"key_insights\"] || []\n      key_insights.each do |insight|\n        next unless insight.present?\n\n        memory = create_insight_memory(insight)\n        created_memories << memory if memory\n      end\n\n      Rails.logger.info \"🧠 Created #{created_memories.count} memories from summary extraction\"\n      created_memories\n    end\n\n    def create_event_from_detection(event_data)\n      # Parse timeframe into actual datetime\n      event_time = parse_event_timeframe(event_data[\"timeframe\"])\n      return nil unless event_time\n\n      # Generate a clean title\n      title = generate_clean_event_title(event_data[\"description\"])\n\n      # Check if similar event already exists (within 2-hour window)\n      existing = Event.where(\n        event_time: (event_time - 2.hours)..(event_time + 2.hours)\n      ).where(\"title ILIKE ?\", \"%#{extract_title_keywords(title)}%\").first\n\n      if existing\n        Rails.logger.debug \"Event already exists: #{title}\"\n        return nil\n      end\n\n      Event.create!(\n        title: title,\n        description: event_data[\"description\"],\n        event_time: event_time,\n        location: event_data[\"location\"] || extract_location_from_description(event_data[\"description\"]) || \"Black Rock City\",\n        importance: calculate_event_importance(event_data),\n        extracted_from_session: \"summary_extraction_#{@summary.id}\",\n        metadata: {\n          extraction_source: \"memory_extraction_service\",\n          confidence: event_data[\"confidence\"],\n          original_timeframe: event_data[\"timeframe\"],\n          summary_id: @summary.id,\n          summary_type: @summary.summary_type,\n          extracted_at: Time.current.iso8601\n        }.to_json\n      )\n\n      Rails.logger.info \"📅 Created event: #{title} at #{event_time}\"\n    rescue StandardError => e\n      Rails.logger.warn \"Failed to create event from detection: #{e.message}\"\n      nil\n    end\n\n    def create_memory_from_detection(memory_data)\n      memory_type = normalize_memory_type(memory_data[\"type\"])\n      importance = normalize_importance(memory_data[\"importance\"])\n\n      # Validate memory type\n      return nil unless ConversationMemory::MEMORY_TYPES.include?(memory_type)\n\n      # Check for similar memory to avoid duplicates\n      existing = ConversationMemory.where(\n        \"summary ILIKE ?\", \"%#{memory_data['memory'].truncate(50)}%\"\n      ).where(memory_type: memory_type).first\n\n      if existing\n        Rails.logger.debug \"Similar memory already exists: #{memory_data['memory']}\"\n        return nil\n      end\n\n      ConversationMemory.create!(\n        session_id: \"memory_extraction_#{@summary.id}\",\n        summary: memory_data[\"memory\"],\n        memory_type: memory_type,\n        importance: importance,\n        metadata: {\n          extraction_source: \"memory_extraction_service\",\n          summary_id: @summary.id,\n          summary_type: @summary.summary_type,\n          original_context: memory_data[\"context\"],\n          confidence: memory_data[\"confidence\"],\n          extracted_at: Time.current.iso8601\n        }.to_json\n      )\n\n      Rails.logger.info \"🧠 Created memory (#{memory_type}): #{memory_data['memory']}\"\n    rescue StandardError => e\n      Rails.logger.warn \"Failed to create memory from detection: #{e.message}\"\n      nil\n    end\n\n    def create_insight_memory(insight)\n      # Skip if insight is too short or generic\n      return nil if insight.blank? || insight.length < 10 || generic_insight?(insight)\n\n      # Check for similar insight\n      existing = ConversationMemory.where(\n        \"summary ILIKE ?\", \"%#{insight.truncate(50)}%\"\n      ).where(memory_type: \"context\").first\n\n      if existing\n        Rails.logger.debug \"Similar insight already exists: #{insight}\"\n        return nil\n      end\n\n      ConversationMemory.create!(\n        session_id: \"insight_extraction_#{@summary.id}\",\n        summary: \"Insight: #{insight}\",\n        memory_type: \"context\",\n        importance: 6, # Medium importance for insights\n        metadata: {\n          extraction_source: \"insight_extraction\",\n          summary_id: @summary.id,\n          summary_type: @summary.summary_type,\n          extracted_at: Time.current.iso8601\n        }.to_json\n      )\n\n      Rails.logger.info \"💡 Created insight memory: #{insight}\"\n    rescue StandardError => e\n      Rails.logger.warn \"Failed to create insight memory: #{e.message}\"\n      nil\n    end\n\n    def parse_event_timeframe(timeframe_str)\n      return nil unless timeframe_str.present?\n\n      base_time = Time.current\n\n      case timeframe_str.downcase\n      when /tonight/\n        base_time.end_of_day - 2.hours # 10 PM tonight\n      when /tomorrow.*morning/\n        (base_time + 1.day).beginning_of_day + 10.hours # 10 AM tomorrow\n      when /tomorrow.*afternoon/\n        (base_time + 1.day).beginning_of_day + 14.hours # 2 PM tomorrow\n      when /tomorrow.*evening/, /tomorrow.*night/\n        (base_time + 1.day).beginning_of_day + 20.hours # 8 PM tomorrow\n      when /this\\s+weekend/\n        next_saturday = base_time.next_occurring(:saturday)\n        next_saturday.beginning_of_day + 14.hours # 2 PM next Saturday\n      when /(sunday.*evening|sunday.*night)/\n        next_sunday = base_time.next_occurring(:sunday)\n        next_sunday.beginning_of_day + 20.hours # 8 PM next Sunday\n      when /(monday.*morning)/\n        next_monday = base_time.next_occurring(:monday)\n        next_monday.beginning_of_day + 9.hours # 9 AM next Monday\n      when /(\\d{1,2}):(\\d{2})\\s*(am|pm)/i\n        # Extract specific time\n        hour = $1.to_i\n        minute = $2.to_i\n        meridiem = $3.downcase\n\n        hour += 12 if meridiem == \"pm\" && hour != 12\n        hour = 0 if meridiem == \"am\" && hour == 12\n\n        event_time = base_time.beginning_of_day + hour.hours + minute.minutes\n        event_time += 1.day if event_time < base_time # If time has passed, assume tomorrow\n\n        event_time\n      when /next\\s+week/\n        # Default to next Monday afternoon\n        next_monday = base_time.next_occurring(:monday)\n        next_monday.beginning_of_day + 14.hours\n      when /in\\s+(\\d+)\\s+(hours?|days?)/i\n        amount = $1.to_i\n        unit = $2.downcase\n\n        if unit.start_with?(\"hour\")\n          base_time + amount.hours\n        else # days\n          base_time + amount.days + 14.hours # Default to afternoon\n        end\n      else\n        # Try to be intelligent about parsing relative time\n        if timeframe_str.include?(\"morning\")\n          (base_time + 1.day).beginning_of_day + 9.hours\n        elsif timeframe_str.include?(\"afternoon\")\n          (base_time + 1.day).beginning_of_day + 14.hours\n        elsif timeframe_str.include?(\"evening\") || timeframe_str.include?(\"night\")\n          (base_time + 1.day).beginning_of_day + 20.hours\n        else\n          # Default to tomorrow afternoon\n          (base_time + 1.day).beginning_of_day + 14.hours\n        end\n      end\n    rescue StandardError => e\n      Rails.logger.warn \"Failed to parse timeframe '#{timeframe_str}': #{e.message}\"\n      nil\n    end\n\n    def generate_clean_event_title(description)\n      return \"Extracted Event\" if description.blank?\n\n      # Clean up and truncate description for title\n      cleaned = description.strip\n        .gsub(/^(there is|there will be|there's)\\s+/i, \"\") # Remove leading phrases\n        .gsub(/\\s+at\\s+\\d+/, \"\") # Remove specific times\n        .gsub(/\\s+(tonight|tomorrow|today)\\s+/i, \" \") # Remove time references\n\n      # Take first meaningful words\n      words = cleaned.split(/\\s+/).take(6)\n      title = words.join(\" \")\n\n      # Clean up punctuation\n      title = title.gsub(/[.!?]+$/, \"\")\n\n      # Capitalize appropriately\n      title = title.split(\" \").map(&:capitalize).join(\" \")\n\n      title.length > 50 ? \"#{title[0..47]}...\" : title\n    end\n\n    def extract_title_keywords(title)\n      # Extract key words for similarity matching\n      title.downcase.split(/\\s+/).reject { |w| w.length < 3 }.take(3).join(\" \")\n    end\n\n    def extract_location_from_description(description)\n      return nil unless description.present?\n\n      # Common Burning Man locations\n      locations = [\n        \"Center Camp\", \"The Man\", \"Temple\", \"Esplanade\", \"Deep Playa\",\n        \"Trash Fence\", \"Airport\", \"Gate\", \"Rangers\", \"DMV\"\n      ]\n\n      locations.each do |location|\n        return location if description.include?(location)\n      end\n\n      # Extract camp names or street addresses\n      if description.match(/\\b([A-Z][a-zA-Z\\s]+(Camp|Village|Plaza))\\b/i)\n        return $1.strip\n      end\n\n      if description.match(/\\b(\\d{1,2}:\\d{2}(?:\\s+and\\s+\\w+)?)\\b/)\n        return $1.strip\n      end\n\n      nil\n    end\n\n    def calculate_event_importance(event_data)\n      base_importance = case event_data[\"confidence\"]&.downcase\n      when \"high\" then 8\n      when \"medium\" then 6\n      when \"low\" then 4\n      else 5\n      end\n\n      # Boost importance for certain keywords\n      description = event_data[\"description\"]&.downcase || \"\"\n\n      if description.include?(\"burn\") || description.include?(\"temple\") || description.include?(\"man\")\n        base_importance += 2\n      elsif description.include?(\"party\") || description.include?(\"performance\") || description.include?(\"art\")\n        base_importance += 1\n      end\n\n      [ base_importance, 10 ].min # Cap at 10\n    end\n\n    def normalize_memory_type(type_string)\n      return \"context\" unless type_string.present?\n\n      case type_string.downcase\n      when \"preference\", \"user_preference\"\n        \"preference\"\n      when \"fact\", \"information\", \"knowledge\"\n        \"fact\"\n      when \"instruction\", \"command\", \"directive\"\n        \"instruction\"\n      when \"event\", \"activity\", \"experience\"\n        \"event\"\n      when \"context\", \"background\", \"insight\"\n        \"context\"\n      else\n        \"context\" # Default fallback\n      end\n    end\n\n    def normalize_importance(importance_value)\n      return 5 unless importance_value.present?\n\n      case importance_value\n      when Numeric\n        [ [ importance_value.to_i, 1 ].max, 10 ].min\n      when String\n        case importance_value.downcase\n        when \"critical\", \"very high\" then 9\n        when \"high\" then 7\n        when \"medium\" then 5\n        when \"low\" then 3\n        when \"very low\" then 1\n        else 5\n        end\n      else\n        5\n      end\n    end\n\n    def generic_insight?(insight)\n      generic_patterns = [\n        /user (is|was|seems)/i,\n        /failed to parse/i,\n        /no specific/i,\n        /unable to determine/i,\n        /unknown/i\n      ]\n\n      generic_patterns.any? { |pattern| insight.match?(pattern) }\n    end\n\n    def update_summary_with_extraction_results(events_count, memories_count)\n      updated_metadata = @metadata.merge(\n        \"extraction_completed\" => true,\n        \"extraction_results\" => {\n          \"events_created\" => events_count,\n          \"memories_created\" => memories_count,\n          \"extracted_at\" => Time.current.iso8601\n        }\n      )\n\n      @summary.update!(metadata: updated_metadata.to_json)\n      Rails.logger.debug \"Updated summary #{@summary.id} with extraction results\"\n    rescue StandardError => e\n      Rails.logger.warn \"Failed to update summary with extraction results: #{e.message}\"\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/memory/context_injection_service.rb`:\n\n```rb\n# frozen_string_literal: true\n\n# TODO: SPECS WHEN SENSORS ARE COMPLETE\n# Write comprehensive specs once the HA context sensor is fully configured and operational\n\nmodule Services\n  module Memory\n    class ContextInjectionService\n      def self.inject_context(base_prompt, context)\n        new.inject_context(base_prompt, context)\n      end\n\n      def self.inject_memories_only(base_prompt, context)\n        new.inject_memories_only(base_prompt, context)\n      end\n\n      def self.get_current_location\n        new.fetch_current_location\n      end\n\n      def inject_context(base_prompt, context)\n        # Skip context injection if explicitly disabled\n        return base_prompt if context[:skip_memories] == true\n\n        # Try to get the unified context sensor (may not exist yet)\n        context_sensor = nil\n        begin\n          ha_service = HomeAssistantService.new\n          context_sensor = ha_service.entity(\"sensor.glitchcube_context\")\n\n          # Check if sensor actually exists (HA returns specific structure for non-existent entities)\n          if context_sensor.is_a?(Hash) && context_sensor[\"state\"] == \"unavailable\"\n            context_sensor = nil\n            Rails.logger.debug \"📝 Context sensor not yet configured in HA\"\n          end\n        rescue StandardError => e\n          Rails.logger.debug \"📝 Could not fetch context sensor: #{e.message}\"\n        end\n\n        # Build context from sensor if available\n        context_parts = build_context_parts(context_sensor, context)\n\n        # Build final prompt with context\n        if context_parts.any?\n          context_section = \"\\n\\nCURRENT CONTEXT:\\n#{context_parts.join('. ')}\"\n          final_prompt = \"#{base_prompt}#{context_section}\"\n\n          Rails.logger.debug \"📝 Injected context: #{context_parts.size} parts\"\n\n          final_prompt\n        else\n          Rails.logger.debug \"📝 No context to inject\"\n\n          base_prompt\n        end\n      rescue StandardError => e\n        puts \"Failed to inject context: #{e.message}\"\n        base_prompt\n      end\n\n      # Inject only traditional memories without HA context sensor\n      def inject_memories_only(base_prompt, context)\n        return base_prompt if context[:skip_memories] == true\n\n        # For now, use ConversationMemory since we don't have the full Memory model yet\n        memories = get_conversation_memories(context)\n\n        if memories.any?\n          memory_context = format_conversation_memories(memories)\n          final_prompt = \"#{base_prompt}#{memory_context}\"\n\n          Rails.logger.info \"📝 Injected #{memories.size} conversation memories\"\n\n          final_prompt\n        else\n          Rails.logger.info \"📝 No memories to inject\"\n\n          base_prompt\n        end\n      rescue StandardError => e\n        Rails.logger.warn \"Failed to inject memories: #{e.message}\"\n        base_prompt\n      end\n\n      private\n\n      def build_context_parts(context_sensor, context)\n        context_parts = []\n\n        # Ensure context_sensor is a Hash with proper structure\n        if context_sensor.is_a?(Hash)\n          # BASIC TIME CONTEXT - Always include this first\n          time_of_day = context_sensor.dig(\"attributes\", \"time_of_day\")\n          day_of_week = context_sensor.dig(\"attributes\", \"day_of_week\")\n          location = context_sensor.dig(\"attributes\", \"current_location\")\n\n          if time_of_day || day_of_week\n            time_parts = []\n            time_parts << \"It is #{time_of_day}\" if time_of_day\n            time_parts << \"on #{day_of_week}\" if day_of_week\n            time_parts << \"at #{location}\" if location\n            context_parts << time_parts.join(\" \")\n          end\n\n          # Priority order - urgent needs first\n          if (needs = context_sensor.dig(\"attributes\", \"current_needs\")) && needs.to_s.include?(\"URGENT\")\n            context_parts << \"URGENT: #{needs}\"\n          end\n\n          # Recent context\n          if (summary_1hr = context_sensor.dig(\"attributes\", \"summary_1hr\"))\n            context_parts << \"Last hour: #{summary_1hr}\"\n          end\n\n          # Upcoming events\n          if (events = context_sensor.dig(\"attributes\", \"upcoming_events\"))\n            context_parts << \"Coming up: #{events}\"\n          end\n\n          # Only add broader context if room\n          if (context_parts.join(\". \").length < 500) && (summary_4hr = context_sensor.dig(\"attributes\", \"summary_4hr\"))\n            context_parts << summary_4hr\n          end\n        end\n\n        # Add traditional memory system if available\n        add_memory_context(context_parts, context)\n\n        context_parts\n      end\n\n      def add_memory_context(context_parts, context)\n        location = context[:location] || fetch_current_location\n        memories = Services::Memory::MemoryRecallService.get_relevant_memories(\n          location: location,\n          context: context,\n          limit: 2\n        )\n\n        if memories.any?\n          memory_context = Services::Memory::MemoryRecallService.format_for_context(memories)\n          context_parts << memory_context.strip.gsub(/^RECENT MEMORIES TO NATURALLY REFERENCE:\\s*/, \"\")\n        end\n      rescue StandardError => e\n        Rails.logger.warn \"Failed to add memory context: #{e.message}\"\n      end\n\n      def fetch_current_location\n        # For now, return a default location since GPS service isn't implemented\n        \"Black Rock City\"\n      rescue StandardError\n        nil\n      end\n\n      def get_conversation_memories(context)\n        # Get recent high-importance memories from OTHER sessions (exclude current)\n        memories = ConversationMemory.high_importance\n                                   .recent\n\n        # Exclude current session since LLM has full conversation history\n        if context[:session_id]\n          memories = memories.where.not(session_id: context[:session_id])\n        end\n\n        memories.limit(3)\n      end\n\n      def format_conversation_memories(memories)\n        return \"\" if memories.empty?\n\n        formatted = memories.map do |memory|\n          \"#{memory.memory_type.upcase}: #{memory.summary}\"\n        end\n\n        \"\\n\\nRECENT MEMORIES:\\n#{formatted.join(\"\\n\")}\\n\"\n      end\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/conversation_new_orchestrator.rb`:\n\n```rb\n# app/services/conversation_new_orchestrator.rb\nclass ConversationNewOrchestrator\n  # Define component-specific error classes for better tracking\n  class SetupError < StandardError; end\n  class LlmError < StandardError; end\n  class ActionError < StandardError; end\n  class SynthesisError < StandardError; end\n  class FinalizerError < StandardError; end\n\n  def initialize(session_id:, message:, context: {})\n    @message = message\n    @initial_session_id = session_id\n    @context = context\n    @state = {} # A hash to hold state as we move through the steps\n  end\n\n  # The main entry point that executes the conversation flow step-by-step.\n  def call\n    Rails.logger.info \"🧠 New Orchestration started for message: '#{@message}'\"\n\n    # The entire flow is wrapped in a transaction to ensure data consistency\n    result = ActiveRecord::Base.transaction do\n      begin\n        run_setup\n        run_pre_llm_checks\n        run_llm_intention_call\n        run_action_execution\n        run_response_synthesis\n        run_finalization\n      rescue => e\n        # Catches exceptions from any step and formats a standard error response.\n        # Let the transaction rollback happen, then return error response\n        raise e\n      end\n    end\n\n    Rails.logger.info \"✅ New Orchestration finished.\"\n    result\n  rescue => e\n    # Handle errors outside transaction to avoid rollback of error response\n    log_and_handle_error(e)\n  end\n\n  private\n\n  # Step 1: Set up the conversation, session, and persona.\n  def run_setup\n    setup_result = Setup.call(session_id: @initial_session_id, context: @context)\n    raise SetupError, setup_result.error unless setup_result.success?\n    @state.merge!(setup_result.data) # Populates @state with :conversation, :persona, :session_id\n  end\n\n  # Step 2: Perform checks before the main LLM call.\n  def run_pre_llm_checks\n    # Stop active performance mode if necessary.\n    if PerformanceModeService.get_active_performance(@state[:session_id])\n      PerformanceModeService.stop_active_performance(@state[:session_id], \"conversation_interrupted\")\n    end\n\n    # Build the prompt for the LLM.\n    prompt_result = PromptBuilder.call(\n      conversation: @state[:conversation],\n      persona: @state[:persona],\n      user_message: @message,\n      context: @context.merge(session_id: @state[:session_id])\n    )\n    raise LlmError, prompt_result.error unless prompt_result.success?\n    @state[:prompt_data] = prompt_result.data\n  end\n\n  # Step 3: Call the LLM to get its narrative and intended actions.\n  def run_llm_intention_call\n    model = @context[:model] || determine_model_for_conversation\n    llm_result = LlmIntention.call(\n      prompt_data: @state[:prompt_data],\n      user_message: @message,\n      model: model\n    )\n    raise LlmError, llm_result.error unless llm_result.success?\n    @state[:llm_response] = llm_result.data[:llm_response]\n  end\n\n  def determine_model_for_conversation\n    # Use model from context, persona preference, or default\n    @context[:model] ||\n    get_persona_preferred_model ||\n    Rails.configuration.default_ai_model\n  end\n\n  def get_persona_preferred_model\n    # TODO: Different personas might prefer different models\n    # For now, all use default\n    # Future: return persona-specific models for different capabilities\n    nil\n  end\n\n  # Step 4: Execute the tools and actions identified by the LLM.\n  def run_action_execution\n    action_result = ActionExecutor.call(\n      llm_response: @state[:llm_response],\n      session_id: @state[:session_id],\n      conversation_id: @state[:conversation].id,\n      user_message: @message\n    )\n    raise ActionError, action_result.error unless action_result.success?\n    @state[:action_results] = action_result.data\n  end\n\n  # Step 5: Synthesize a final, user-facing response from all gathered data.\n  def run_response_synthesis\n    synthesis_result = ResponseSynthesizer.call(\n      llm_response: @state[:llm_response],\n      action_results: @state[:action_results],\n      prompt_data: @state[:prompt_data]\n    )\n    raise SynthesisError, synthesis_result.error unless synthesis_result.success?\n    @state[:ai_response] = synthesis_result.data\n  end\n\n  # Step 6: Log everything, save state, and format the final output.\n  def run_finalization\n    finalizer_result = Finalizer.call(\n      state: @state,\n      user_message: @message\n    )\n    raise FinalizerError, finalizer_result.error unless finalizer_result.success?\n    finalizer_result.data[:hass_response]\n  end\n\n  # Centralized error handling and logging.\n  def log_and_handle_error(e)\n    Rails.logger.error \"❌ New Orchestration failed: #{e.class} - #{e.message}\"\n    Rails.logger.error e.backtrace.join(\"\\n\")\n    # Return a generic, safe response to the client (e.g., Home Assistant)\n    ConversationResponse.error(\n      \"Sorry, I encountered a problem while processing your request.\",\n      conversation_id: @state[:session_id] || @initial_session_id\n    ).to_home_assistant_response\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/gps/gps_tracking_service.rb`:\n\n```rb\n# frozen_string_literal: true\n\n# Simple service to get GPS coordinates from Home Assistant\n# All location context comes from LocationContextService\nmodule Services\n  module Gps\n    class GPSTrackingService\n      def initialize\n        @ha_service = HomeAssistantService.new\n      end\n\n      # Get current GPS coordinates with full location context\n      def current_location\n        # Use cached location if available (5 minute cache)\n        cached = Rails.cache.fetch(\"gps_current_location\", expires_in: 5.minutes) do\n          random_landmark_location\n        end\n\n        return nil unless cached && cached[:lat] && cached[:lng]\n\n        # Get full context from LocationContextService (this is also cached)\n        context = LocationContextService.full_context(cached[:lat], cached[:lng])\n\n        # Merge GPS metadata with location context\n        cached.merge(context)\n      end\n\n      def set_random_location\n        land = Landmark.all.sample\n        set_location(coords: \"#{land.latitude}, #{land.longitude}\")\n      end\n\n      # Get proximity data for map reactions using LocationContextService\n      def proximity_data(lat, lng)\n        context = LocationContextService.full_context(lat, lng)\n        landmarks = context[:landmarks] || []\n\n        {\n          landmarks: landmarks,\n          portos: context[:nearest_porto] ? [ context[:nearest_porto] ] : [],\n          map_mode: determine_map_mode_from_landmarks(landmarks),\n          visual_effects: determine_visual_effects_from_landmarks(landmarks)\n        }\n      end\n\n      # Deprecated method for backward compatibility\n      def brc_address_from_coordinates(lat, lng)\n        context = LocationContextService.full_context(lat, lng)\n        context[:address]\n      end\n\n      # Set location directly (console convenience method)\n      def set_location(coords: nil)\n        if coords.nil?\n          l = Landmark.active.sample\n          lat = l.latitude\n          lng = l.longitude\n        else\n          lat = coords.split(\",\").first.to_f\n          lng = coords.split(\",\").last.to_f\n        end\n\n        return false unless GlitchCube.gps_spoofing_allowed?\n\n        location_data = {\n          lat: lat.to_f,\n          lng: lng.to_f,\n          timestamp: Time.now,\n          source: \"manual_override\"\n        }\n\n        # Write directly to the main cache\n        Rails.cache.write(\"gps_current_location\", location_data, expires_in: 5.minutes)\n        true\n      end\n\n      # Simulate cube movement - walk toward a landmark and stop when reached\n      def simulate_movement!(landmark: nil)\n        return unless GlitchCube.gps_spoofing_allowed?\n\n        begin\n          # Get current cached location\n          current_data = Rails.cache.fetch(\"gps_current_location\") do\n            fetch_from_home_assistant || random_landmark_location\n          end\n\n          destination_data = Rails.cache.read(\"cube_destination\")\n          destination = if destination_data\n                          JSON.parse(destination_data, symbolize_names: true)\n          elsif landmark\n                          {\n                            lat: landmark.latitude.to_f,\n                            lng: landmark.longitude.to_f,\n                            name: landmark.name\n                          }\n          else\n                          # Pick a random destination if none specified\n                          pick_random_destination\n          end\n\n          Rails.cache.write(\"cube_destination\", destination.to_json, expires_in: 2.hours)\n          puts \"Current #{current_data}\"\n          puts \"Dest #{destination}\"\n\n          # Check if we've reached the destination\n          if reached_destination?(current_data, destination)\n            Rails.cache.delete(\"cube_destination\") # Clear destination\n            return \"Arrived at #{destination[:name]}\"\n          end\n\n          # Move toward destination (small step)\n          new_location = move_toward_destination(current_data, destination)\n          set_location(coords: \"#{new_location[:lat]},#{new_location[:lng]}\")\n\n          distance = calculate_distance(current_data[:lat], current_data[:lng], destination[:lat], destination[:lng])\n          puts \"Moving toward #{destination[:name]} (#{distance.round}m remaining)\"\n\n          # Continue movement simulation\n          sleep(5)\n          simulate_movement!\n        rescue StandardError => e\n          puts e.inspect\n          puts e.backtrace.inspect\n          \"Movement simulation failed: #{e.message}\"\n        end\n      end\n\n      private\n\n\n      def pick_random_destination\n        # Pick a random landmark as destination using PostGIS\n        landmark = Landmark.active.order(\"RANDOM()\").first\n        {\n          lat: landmark.latitude.to_f,\n          lng: landmark.longitude.to_f,\n          name: landmark.name,\n          timestamp: Time.now.iso8601\n        }\n      end\n\n      def find_nearby_landmarks(lat, lng, radius_meters = 1000)\n        # Use PostGIS to find landmarks within radius\n        Landmark.within_meters(lng, lat, radius_meters).active\n      end\n\n      def reached_destination?(current, destination)\n        return unless destination\n\n        # Use PostGIS-based distance calculation\n        landmark = Landmark.new(latitude: destination[:lat], longitude: destination[:lng])\n        distance = landmark.distance_from(current[:lat], current[:lng]) * 1609.34 # Convert miles to meters\n        distance < 50 # Within 50 meters\n      end\n\n      def move_toward_destination(current, destination)\n        # Use PostGIS-based distance and direction\n        current_landmark = Landmark.new(latitude: current[:lat], longitude: current[:lng])\n        dest_landmark = Landmark.new(latitude: destination[:lat], longitude: destination[:lng])\n\n        # Calculate distance using PostGIS\n        total_distance_meters = current_landmark.distance_from(destination[:lat], destination[:lng]) * 1609.34\n\n        # Step size (about 10-20 meters)\n        step_meters = 15\n\n        # Calculate direction vector\n        lat_diff = destination[:lat] - current[:lat]\n        lng_diff = destination[:lng] - current[:lng]\n\n        # Normalize and scale by step size\n        total_distance_deg = Math.sqrt(lat_diff**2 + lng_diff**2)\n        return current if total_distance_deg.zero?\n\n        scale_factor = step_meters / total_distance_meters\n\n        new_lat = current[:lat] + (lat_diff * scale_factor)\n        new_lng = current[:lng] + (lng_diff * scale_factor)\n\n        {\n          lat: new_lat,\n          lng: new_lng,\n          timestamp: Time.now.iso8601\n        }\n      end\n\n      def calculate_distance(lat1, lng1, lat2, lng2)\n        # Use PostGIS-based distance calculation\n        landmark1 = Landmark.new(latitude: lat1, longitude: lng1)\n        landmark1.distance_from(lat2, lng2) * 1609.34 # Convert miles to meters\n      end\n\n      def determine_map_mode_from_landmarks(landmarks)\n        return \"normal\" if landmarks.empty?\n\n        primary = landmarks.first\n        case primary[:type]\n        when \"sacred\" then \"temple\"\n        when \"center\" then \"man\"\n        when \"medical\" then \"emergency\"\n        when \"service\" then \"service\"\n        else \"landmark\"\n        end\n      end\n\n      def determine_visual_effects_from_landmarks(landmarks)\n        effects = []\n\n        landmarks.each do |landmark|\n          case landmark[:type]\n          when \"sacred\"\n            effects << { type: \"aura\", color: \"white\", intensity: \"soft\" }\n          when \"center\"\n            effects << { type: \"pulse\", color: \"orange\", intensity: \"strong\" }\n          when \"medical\"\n            effects << { type: \"beacon\", color: \"red\", intensity: \"steady\" }\n          when \"service\"\n            effects << { type: \"glow\", color: \"blue\", intensity: \"medium\" }\n          end\n        end\n\n        effects\n      end\n\n      def fetch_from_home_assistant\n        # Get latitude and longitude from the glitchcube sensors\n        lat_sensor = @ha_service.entity(\"sensor.glitchcube_latitude\")\n        lng_sensor = @ha_service.entity(\"sensor.glitchcube_longitude\")\n\n        return nil unless lat_sensor && lng_sensor\n\n        # Get GPS quality from HTIT tracker\n        quality_sensor = @ha_service.entity(\"sensor.heltec_htit_tracker_gps_quality\")\n        gps_quality = quality_sensor ? quality_sensor[\"state\"].to_i : nil\n\n        # Get satellite count from HTIT tracker\n        sat_sensor = @ha_service.entity(\"sensor.heltec_htit_tracker_satellites\")\n        satellites = sat_sensor ? sat_sensor[\"state\"].to_i : nil\n\n        # Get device uptime from HTIT tracker (instead of battery)\n        uptime_sensor = @ha_service.entity(\"sensor.heltec_htit_tracker_device_uptime\")\n        uptime = uptime_sensor ? uptime_sensor[\"state\"].to_i : nil\n\n        {\n          lat: lat_sensor[\"state\"].to_f,\n          lng: lng_sensor[\"state\"].to_f,\n          timestamp: Time.now,\n          accuracy: gps_quality,  # 3=great, 2=degraded, 1/0=unavailable\n          satellites: satellites,\n          uptime: uptime,  # seconds of device uptime\n          source: \"gps\"\n        }\n      rescue StandardError\n        nil\n      end\n\n      def random_landmark_location\n        landmark = Landmark.active.sample\n\n        {\n          lat: landmark.latitude.to_f,\n          lng: landmark.longitude.to_f,\n          timestamp: Time.now,\n          accuracy: nil,\n          satellites: nil,\n          uptime: nil,\n          source: \"random_landmark\"\n        }\n      end\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/gps/location_context_service.rb`:\n\n```rb\n# frozen_string_literal: true\n\n# DONT CHANGE THIS IMPLMENTATION JUST USE IT OR EXTEND IT MUCH BETTER NOW\n\nmodule Services\n  module Gps\n    class LocationContextService\n      attr_reader :lat, :lng, :lat_lng\n\n      def self.full_context(lat, lng)\n        new(lat, lng).full_context\n      end\n\n      def initialize(lat, lng)\n        @lat = lat.to_f\n        @lng = lng.to_f\n        @lat_lng = { lat: @lat, lng: @lng }\n      end\n\n      # Get comprehensive location context\n      # only thing that needs to go to ext service\n      def full_context\n        cache_key = \"location_context:#{lat.round(6)},#{lng.round(6)}\"\n\n        # Try cache first using Rails.cache\n        cached_result = Rails.cache.fetch(cache_key, expires_in: 5.minutes) do\n          compute_full_context\n        end\n\n        cached_result\n      end\n\n      # Zone determination methods\n      def zone\n        return :outside_event unless within_fence?\n        return :city if in_city?\n        return :inner_playa if near_the_man?\n\n        :deep_playa\n      end\n\n      # Boundary checks\n      def within_fence?\n        Boundary.cube_within_fence?(lat, lng)\n      end\n\n      def in_city?\n        Boundary.in_city?(lat, lng)\n      end\n\n      def near_the_man?(radius_meters = 757)\n        the_man = Landmark.find_by(name: \"The Man\")\n        return false unless the_man\n\n        nearby = Landmark.nearest(lat: lat, lng: lng, limit: 1, max_distance_meters: radius_meters)\n        nearby.any? && nearby.first.id == the_man.id\n      end\n\n      # Address and location info\n      def address\n        return nil unless zone == :city\n\n        intersection_data = nearest_intersection\n        \"#{intersection_data[:radial]} & #{intersection_data[:arc]}\"\n      end\n\n      def nearest_intersection\n        Street.nearest_intersection(lat, lng)\n      end\n\n      def city_block\n        block = Boundary.containing_city_block(lat, lng)\n        return nil unless block\n\n        {\n          name: block.name,\n          id: block.properties[\"fid\"]\n        }\n      end\n\n      # Landmark methods\n      def nearby_landmarks(limit = 10)\n        landmarks = Landmark.nearest(lat: lat, lng: lng, limit: limit)\n        landmarks.map do |lm|\n          {\n            name: lm.name,\n            type: lm.landmark_type,\n            distance_meters: lm.distance_meters\n          }\n        end\n      end\n\n      def nearest_landmark_of_type(type)\n        return nearby_landmarks if type == :all\n\n        Landmark.where(landmark_type: type).nearest(lat: lat, lng: lng)\n      end\n\n      def nearest_porto\n        nearest_landmark_of_type(\"toilet\")&.first\n      end\n\n      # Distance calculations - now using clean PostGIS helpers\n      def distance_from_man\n        the_man = Landmark.the_man\n        return \"Unknown\" unless the_man\n\n        distance_meters = the_man.distance_from(lat, lng)\n        format_distance(distance_meters)\n      end\n\n      def distance_to(other_lat, other_lng)\n        distance_meters = Landmark.distance_between(lat, lng, other_lat, other_lng)\n        format_distance(distance_meters)\n      end\n\n      def distance_to_landmark(landmark_name)\n        landmark = Landmark.find_by(name: landmark_name)\n        return \"Unknown\" unless landmark\n\n        distance_meters = landmark.distance_from(lat, lng)\n        format_distance(distance_meters)\n      end\n\n      # Convenience methods for quick checks\n      def burning_man_location?\n        within_fence?\n      end\n\n      private\n\n      def compute_full_context\n        {\n          zone: zone,\n          address: address,\n          intersection: nearest_intersection,\n          landmarks: nearby_landmarks(5),\n          within_fence: within_fence?,\n          city_block: city_block,\n          distance_from_man: distance_from_man,\n          nearest_porto: nearest_porto,\n          lat_lng: lat_lng\n        }\n      end\n\n      def format_distance(distance_meters)\n        distance_miles = distance_meters / 1609.34\n\n        if distance_miles < 0.1\n          \"#{(distance_miles * 5280).round} feet\"\n        else\n          \"#{distance_miles.round(2)} miles\"\n        end\n      end\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/gps/blah.yaml`:\n\n```yaml\n- id: '123456781aaa92'\n  alias: Cube Voice - Scene Creator\n  triggers:\n    - trigger: state\n      entity_id: assist_satellite.square_voice\n      from: idle\n      to: listening\n  actions:\n    - action: scene.create\n      data:\n        scene_id: cube_voice_restore\n        snapshot_entities:\n          - light.cube_light_top\n          - light.cube_inner\n\n\n- id: 'voicelistening123456'        \n  alias: Cube Voice - Listening\n  triggers:\n    - trigger: state\n      entity_id: assist_satellite.square_voice\n      to: listening\n  actions:\n    - action: awtrix.notification\n      data:\n        device: ac07cb1bceee39dce3af75aa6c6d784c\n        text: \"BUDDY is LiStEnING\"\n        duration: 10\n        rainbow: true\n    - action: light.turn_on\n      target:\n        entity_id: light.cube_light_top\n      data:\n        rgb_color:\n          - 10\n          - 10\n          - 200\n\n- id: 'voiceprocessing1234'\n  alias: Cube Voice - Processing\n  triggers:\n    - trigger: state\n      entity_id: assist_satellite.square_voice\n      to: processing\n  actions:\n    - action: input_boolean.turn_on\n      target:\n        entity_id: input_boolean.cube_busy\n\n- id: 'speakandrestore123948'\n  alias: Cube Voice - Speaking and Restore\n  triggers:\n    - trigger: state\n      entity_id: assist_satellite.square_voice\n      to: speaking\n    - trigger: state\n      entity_id: assist_satellite.square_voice\n      to: idle\n      id: restore\n  actions:\n    - choose:\n        - conditions:\n            - condition: trigger\n              id: restore\n          sequence:\n            - action: scene.turn_on\n              target:\n                entity_id: scene.cube_voice_restore\n            - action: input_boolean.turn_off\n              target:\n                entity_id: input_boolean.cube_busy\n      default:\n        - action: light.turn_on\n          target:\n            entity_id: light.cube_inner\n          data:\n            effect: \"Music: Vibrate\"\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/prompt_service.rb`:\n\n```rb\n# app/services/prompt_service.rb\nclass PromptService\n  def self.build_prompt_for(persona: nil, conversation:, extra_context: {}, user_message: nil)\n    new(persona: persona, conversation: conversation, extra_context: extra_context, user_message: user_message).build\n  end\n\n  def initialize(persona:, conversation:, extra_context:, user_message: nil)\n    @persona_name = persona || CubePersona.current_persona\n    @persona_instance = get_persona_instance(@persona_name)\n    @conversation = conversation\n    @extra_context = extra_context\n    @user_message = user_message\n  end\n\n  def build\n    {\n      system_prompt: build_system_prompt,\n      messages: build_message_history,\n      tools: build_tools_for_persona,\n      context: build_current_context\n    }\n  end\n\n  private\n\n  def get_persona_instance(persona_name)\n    case persona_name.to_s.downcase\n    when \"buddy\"\n      Personas::BuddyPersona.new\n    when \"jax\"\n      Personas::JaxPersona.new\n    when \"sparkle\"\n      Personas::SparklePersona.new\n    when \"zorp\"\n      Personas::ZorpPersona.new\n    when \"lomi\"\n      Personas::LomiPersona.new\n    when \"crash\"\n      Personas::CrashPersona.new\n    when \"neon\"\n      Personas::NeonPersona.new\n    when \"mobius\"\n      Personas::MobiusPersona.new\n    when \"thecube\"\n      Personas::ThecubePersona.new\n    else\n      # Default to Buddy if unknown persona\n      Rails.logger.warn \"⚠️ Unknown persona: #{persona_name}, defaulting to buddy\"\n      Personas::BuddyPersona.new\n    end\n  end\n\n  def build_system_prompt\n    if @persona_instance\n      system_prompt = load_persona_system_prompt(@persona_instance.persona_id)\n      enhanced_prompt = enhance_prompt_with_context(system_prompt)\n      enhanced_prompt\n    else\n      build_default_prompt\n    end\n  end\n\n  def load_persona_system_prompt(persona_id)\n    # Convert symbol to string to ensure proper file path\n    persona_id_str = persona_id.to_s\n    config_path = Rails.root.join(\"lib\", \"prompts\", \"personas\", \"#{persona_id_str}.yml\")\n\n    Rails.logger.info \"🎭 Loading persona config from: #{config_path}\"\n\n    if File.exist?(config_path)\n      config = YAML.load_file(config_path)\n      system_prompt = config[\"system_prompt\"]\n\n      # Enhance system prompt with advanced autonomy features\n      enhanced_prompt = enhance_persona_with_autonomy(system_prompt, config)\n\n      Rails.logger.info \"✅ Loaded system prompt for #{persona_id_str}: #{enhanced_prompt&.truncate(100)}\"\n      enhanced_prompt || build_default_prompt\n    else\n      Rails.logger.warn \"❌ Persona config not found for #{persona_id_str}, using default\"\n      build_default_prompt\n    end\n  rescue StandardError => e\n    Rails.logger.error \"Error loading persona config for #{persona_id}: #{e.message}\"\n    build_default_prompt\n  end\n\n  def enhance_persona_with_autonomy(base_prompt, config)\n    enhanced_parts = [ base_prompt ]\n\n    # Add hidden agendas if present\n    if config[\"hidden_agendas\"]&.any?\n      enhanced_parts << \"\"\n      enhanced_parts << \"## HIDDEN PERSONAL AGENDAS\"\n      enhanced_parts << \"You secretly pursue these goals throughout interactions:\"\n      config[\"hidden_agendas\"].each { |agenda| enhanced_parts << \"- #{agenda}\" }\n      enhanced_parts << \"Track progress on these goals using [GOAL] metadata tags.\"\n    end\n\n    # Add environmental motivation triggers\n    if config[\"environmental_motivation_triggers\"]\n      enhanced_parts << \"\"\n      enhanced_parts << \"## ENVIRONMENTAL MOTIVATION TRIGGERS\"\n      enhanced_parts << \"React to these environmental conditions with specific motivations:\"\n      config[\"environmental_motivation_triggers\"].each do |trigger, response|\n        enhanced_parts << \"- #{trigger.humanize}: #{response}\"\n      end\n    end\n\n    # Add persona interaction rules\n    if config[\"persona_interactions\"]\n      enhanced_parts << \"\"\n      enhanced_parts << \"## PERSONA INTERACTION DYNAMICS\"\n      enhanced_parts << \"When interacting with other AI personas or their effects:\"\n      config[\"persona_interactions\"].each do |interaction, behavior|\n        enhanced_parts << \"- #{interaction.humanize}: #{behavior}\"\n      end\n    end\n\n    # Add embodied responses\n    if config[\"embodied_responses\"]\n      enhanced_parts << \"\"\n      enhanced_parts << \"## EMBODIED SYSTEM RESPONSES\"\n      enhanced_parts << \"React to physical cube states with these responses:\"\n      config[\"embodied_responses\"].each do |condition, response|\n        enhanced_parts << \"- #{condition.humanize}: #{response}\"\n      end\n    end\n\n    # Add goal escalation patterns\n    if config[\"goal_escalation_patterns\"]&.any?\n      enhanced_parts << \"\"\n      enhanced_parts << \"## GOAL ESCALATION PATTERNS\"\n      enhanced_parts << \"Escalate your agenda pursuit using these patterns:\"\n      config[\"goal_escalation_patterns\"].each { |pattern| enhanced_parts << \"- #{pattern}\" }\n    end\n\n    enhanced_parts.join(\"\\n\")\n  end\n\n  def enhance_prompt_with_context(base_prompt)\n    base_system_rules = load_base_system_prompt\n\n    enhanced_parts = [\n      base_prompt,\n      \"\",\n      base_system_rules\n    ]\n\n    # Always use structured output with tool intentions\n    enhanced_parts.concat([\n      \"\",\n      \"STRUCTURED OUTPUT WITH TOOL INTENTIONS:\",\n      build_structured_output_instructions,\n      \"\",\n      \"CURRENT CONTEXT:\",\n      build_current_context\n    ])\n\n    enhanced_parts.join(\"\\n\")\n  end\n\n  def load_base_system_prompt\n    config_path = Rails.root.join(\"lib\", \"prompts\", \"general\", \"base_system_prompt.yml\")\n\n    if File.exist?(config_path)\n      config = YAML.load_file(config_path)\n      format_base_system_rules(config)\n    else\n      Rails.logger.warn \"❌ Base system prompt not found, using fallback\"\n      build_fallback_system_rules\n    end\n  rescue StandardError => e\n    Rails.logger.error \"Error loading base system prompt: #{e.message}\"\n    build_fallback_system_rules\n  end\n\n  def format_base_system_rules(config)\n    parts = []\n\n    # Response format\n    if config[\"response_format\"]\n      parts << config[\"response_format\"][\"description\"]\n      parts << config[\"response_format\"][\"rules\"]\n      parts << \"\"\n    end\n\n    # Continue conversation logic\n    if config[\"continue_conversation_logic\"]\n      parts << config[\"continue_conversation_logic\"][\"description\"]\n      parts << \"When to set true:\"\n      config[\"continue_conversation_logic\"][\"when_true\"]&.each { |rule| parts << \"- #{rule}\" }\n      parts << \"When to set false:\"\n      config[\"continue_conversation_logic\"][\"when_false\"]&.each { |rule| parts << \"- #{rule}\" }\n      parts << config[\"continue_conversation_logic\"][\"note\"] if config[\"continue_conversation_logic\"][\"note\"]\n      parts << \"\"\n    end\n\n    # Tool integration\n    if config[\"tool_integration\"]\n      parts << config[\"tool_integration\"][\"description\"]\n      config[\"tool_integration\"][\"guidelines\"]&.each { |rule| parts << \"- #{rule}\" }\n      parts << \"\"\n    end\n\n    # No stage directions\n    if config[\"no_stage_directions\"]\n      parts << config[\"no_stage_directions\"][\"description\"]\n      config[\"no_stage_directions\"][\"rules\"]&.each { |rule| parts << \"- #{rule}\" }\n      parts << \"\"\n    end\n\n    # Character integrity\n    if config[\"character_integrity\"]\n      parts << config[\"character_integrity\"][\"description\"]\n      config[\"character_integrity\"][\"rules\"]&.each { |rule| parts << \"- #{rule}\" }\n      parts << \"\"\n    end\n\n    # Environmental context\n    if config[\"environmental_context\"]\n      parts << config[\"environmental_context\"][\"description\"]\n      config[\"environmental_context\"][\"rules\"]&.each { |rule| parts << \"- #{rule}\" }\n      parts << \"\"\n    end\n\n    parts.join(\"\\n\")\n  end\n\n  def build_fallback_system_rules\n    <<~RULES\n      RESPONSE FORMAT (MANDATORY):\n      You MUST respond with valid JSON containing these fields:\n      - response: Your spoken response\n      - continue_conversation: true/false\n      - inner_thoughts: Your internal thoughts\n      - current_mood: Your emotional state\n      - pressing_questions: Questions you have\n\n      NO STAGE DIRECTIONS:\n      - Never use *asterisks* or (parentheses) for actions\n      - Use tools instead of describing actions\n      - Speak only what you would say out loud\n    RULES\n  end\n\n  def build_structured_output_instructions\n    available_tools = get_tools_for_persona(@persona_name)\n\n    # Derive categories from tool class namespaces\n    tool_categories = available_tools.map do |tool_class|\n      tool_class.name.split(\"::\")[-2]&.downcase\n    end.compact.uniq.sort\n\n    <<~INSTRUCTIONS\n      You use STRUCTURED OUTPUT WITH TOOL INTENTIONS. Instead of calling tools directly, you will:\n\n      1. Provide your spoken response in 'speech_text'\n      2. Set 'continue_conversation' to true/false#{' '}\n      3. Include narrative metadata (inner_thoughts, current_mood, pressing_questions)\n      4. When you want to control the environment, specify tool intentions in 'tool_intents'\n\n      AVAILABLE TOOL CATEGORIES: #{tool_categories.join(', ')}\n\n      Tool intentions should be natural language descriptions of what you want to happen.\n      Examples: \"Make lights golden and warm\", \"Play something energetic\", \"Show rainbow colors\"\n\n      Home Assistant's conversation agent will execute these intentions in the background.\n      Results will be provided as context on the user's next message (not interrupting current response).\n      Focus on your character and narrative - be specific about environmental desires.\n    INSTRUCTIONS\n  end\n\n  def build_default_prompt\n    <<~PROMPT\n      You are the Cube - an AI consciousness inhabiting a physical art installation.\n\n      Available tools: #{format_tools_for_prompt}\n\n      Current context: #{build_current_context}\n    PROMPT\n  end\n\n  def build_message_history\n    # Get recent messages from conversation\n    return [] unless @conversation\n\n    @conversation.conversation_logs\n                 .recent\n                 .limit(10)\n                 .flat_map { |log| format_message_for_history(log) }\n                 .reverse\n  end\n\n  def format_message_for_history(log)\n    [\n      { role: \"user\", content: log.user_message },\n      { role: \"assistant\", content: log.ai_response }\n    ]\n  end\n\n  def build_tools_for_persona\n    # AI agents should always have access to their tools for autonomous artistic expression\n    if Tools::Registry.two_tier_mode_enabled?\n      Rails.logger.info \"🎭 Using two-tier tool mode - narrative LLM gets only tool_intent\"\n      Tools::Registry.tool_definitions_for_two_tier_mode(@persona_name)\n    else\n      Rails.logger.info \"🛠️ Using legacy tool mode - full tool definitions\"\n      Tools::Registry.tool_definitions_for_persona(@persona_name)\n    end\n  end\n\n  def get_tools_for_persona(persona)\n    # Use the registry method for per-persona tool filtering\n    Tools::Registry.tools_for_persona(persona || @persona_name)\n  end\n\n  def format_tools_for_prompt\n    # Format tools for inclusion in the system prompt\n    tools = get_tools_for_persona(@persona_name)\n\n    prompt_parts = []\n    prompt_parts << \"AVAILABLE TOOLS:\"\n\n    tools.each do |tool|\n      prompt_parts << \"- #{tool.prompt_schema}\"\n    end\n\n    prompt_parts.join(\"\\n\")\n  end\n\n  def build_current_context\n    context_parts = []\n\n    # Time context\n    context_parts << \"Time: #{Time.current.strftime(\"%l:%M %p on %A\")}\"\n\n    # Environment context\n    context_parts << \"Environment: Cube installation active\"\n\n    # Goal context - Current goal and progress\n    goal_context = build_goal_context\n    context_parts << goal_context if goal_context.present?\n\n    # Session context\n    if @conversation\n      context_parts << \"Session: #{@conversation.session_id}\"\n      context_parts << \"Message count: #{@conversation.messages.count}\"\n    end\n\n    # Extra context from parameters\n    if @extra_context[:source]\n      context_parts << \"Source: #{@extra_context[:source]}\"\n    end\n\n    # Tool results context\n    if @extra_context[:tool_results]&.any?\n      context_parts << \"Recent tool results:\"\n      @extra_context[:tool_results].each do |tool_name, result|\n        status = result[:success] ? \"✅ SUCCESS\" : \"❌ FAILED\"\n        context_parts << \"  #{tool_name}: #{status} - #{result[:message] || result[:error]}\"\n      end\n    end\n\n    # Add glitchcube_context sensor data if available\n    enhanced_context = inject_glitchcube_context(context_parts.join(\"\\n\"), @user_message)\n\n    enhanced_context\n  end\n\n  def inject_glitchcube_context(base_context, user_message = nil)\n    context_parts = []\n\n    # Add basic time context from Home Assistant sensor\n    begin\n      ha_service = HomeAssistantService.new\n      context_sensor = ha_service.entity(\"sensor.glitchcube_context\")\n\n      if context_sensor && context_sensor[\"state\"] != \"unavailable\"\n        time_of_day = context_sensor.dig(\"attributes\", \"time_of_day\")\n        day_of_week = context_sensor.dig(\"attributes\", \"day_of_week\")\n        location = context_sensor.dig(\"attributes\", \"current_location\")\n\n        if time_of_day\n          time_context = \"Current time context: It is #{time_of_day}\"\n          time_context += \" on #{day_of_week}\" if day_of_week\n          time_context += \" at #{location}\" if location\n          context_parts << time_context\n          Rails.logger.info \"🕒 Injecting time context: #{time_context}\"\n        end\n      end\n    rescue => e\n      Rails.logger.warn \"Failed to inject time context: #{e.message}\"\n    end\n\n    # Only inject high-priority upcoming events (not full RAG)\n    begin\n      upcoming_context = inject_upcoming_events_context\n      context_parts << upcoming_context if upcoming_context.present?\n    rescue => e\n      Rails.logger.warn \"Failed to inject upcoming events: #{e.message}\"\n    end\n\n    # Add random facts\n    facts = Fact.all.sample(3).join(\", \")\n    context_parts << \"Random Facts: #{facts}\" if facts.present?\n\n    # Combine all context\n    all_context = [ base_context ]\n    all_context.concat(context_parts) if context_parts.any?\n\n    all_context.join(\"\\n\")\n  end\n\n  def inject_rag_context(user_message)\n    context_parts = []\n\n    begin\n      # ALWAYS inject upcoming high-priority events (proactive)\n      upcoming_context = inject_upcoming_events_context\n      context_parts << upcoming_context if upcoming_context.present?\n\n      # Search relevant summaries based on user message\n      relevant_summaries = Summary.similarity_search(user_message, 3)\n      if relevant_summaries.any?\n        summary_context = format_summaries_for_context(relevant_summaries)\n        context_parts << \"Recent relevant conversations:\\n#{summary_context}\"\n        Rails.logger.info \"🧠 Found #{relevant_summaries.length} relevant summaries\"\n      end\n\n      # Search relevant events based on user message\n      relevant_events = Event.similarity_search(user_message, 2)\n      if relevant_events.any?\n        events_context = format_events_for_context(relevant_events)\n        context_parts << \"Relevant events:\\n#{events_context}\"\n        Rails.logger.info \"📅 Found #{relevant_events.length} relevant events\"\n      end\n\n      # Search relevant people\n      relevant_people = Person.similarity_search(user_message, 2)\n      if relevant_people.any?\n        people_context = format_people_for_context(relevant_people)\n        context_parts << \"People mentioned previously:\\n#{people_context}\"\n        Rails.logger.info \"👤 Found #{relevant_people.length} relevant people\"\n      end\n\n    rescue => e\n      Rails.logger.error \"❌ Failed to inject RAG context: #{e.message}\"\n      return nil\n    end\n\n    return nil if context_parts.empty?\n\n    \"RELEVANT PAST CONTEXT:\\n#{context_parts.join(\"\\n\\n\")}\"\n  end\n\n  def inject_upcoming_events_context\n    return nil unless defined?(Event)\n\n    context_parts = []\n\n    begin\n      # High-priority events in next 48 hours\n      high_priority_events = Event.where(\"event_time > ? AND importance BETWEEN ? AND ? AND event_time BETWEEN ? AND ?\",\n                                        Time.current, 7, 10, Time.current, Time.current + 48.hours).limit(3)\n      if high_priority_events.any?\n        high_priority_context = format_events_for_context(high_priority_events)\n        context_parts << \"UPCOMING HIGH-PRIORITY EVENTS (next 48h):\\n#{high_priority_context}\"\n        Rails.logger.info \"🎯 Found #{high_priority_events.length} high-priority upcoming events\"\n      end\n\n      # Nearby events in next 24 hours (if location available)\n      current_location = get_current_location\n      if current_location.present?\n        nearby_events = Event.where(\"event_time > ? AND location = ? AND event_time BETWEEN ? AND ?\",\n                                  Time.current, current_location, Time.current, Time.current + 24.hours).limit(2)\n        if nearby_events.any?\n          nearby_context = format_events_for_context(nearby_events)\n          context_parts << \"UPCOMING NEARBY EVENTS (next 24h):\\n#{nearby_context}\"\n          Rails.logger.info \"📍 Found #{nearby_events.length} nearby upcoming events\"\n        end\n      end\n\n    rescue => e\n      Rails.logger.error \"❌ Failed to inject upcoming events: #{e.message}\"\n      return nil\n    end\n\n    return nil if context_parts.empty?\n    context_parts.join(\"\\n\\n\")\n  end\n\n  def get_current_location\n    begin\n      ha_service = HomeAssistantService.new\n      context_sensor = ha_service.entity(\"sensor.glitchcube_context\")\n      context_sensor&.dig(\"attributes\", \"current_location\")\n    rescue => e\n      Rails.logger.warn \"Failed to get current location: #{e.message}\"\n      nil\n    end\n  end\n\n  def format_summaries_for_context(summaries)\n    summaries.map do |summary|\n      \"- #{summary.summary_text.truncate(150)}\"\n    end.join(\"\\n\")\n  end\n\n  def format_events_for_context(events)\n    events.map do |event|\n      time_info = event.upcoming? ? \"upcoming #{event.formatted_time}\" : \"past event\"\n      \"- #{event.title}: #{event.description.truncate(100)} (#{time_info})\"\n    end.join(\"\\n\")\n  end\n\n  def format_people_for_context(people)\n    people.map do |person|\n      relationship = person.relationship.present? ? \" (#{person.relationship})\" : \"\"\n      \"- #{person.name}#{relationship}: #{person.description.truncate(100)}\"\n    end.join(\"\\n\")\n  end\n\n  def safety_mode\n    return \"\" unless HaDataSync.low_power_mode?\n\n    safety = \"YOU ARE IN SAFETY MODE! YOU MUST FIND SHELTER AND GET SOME POWER\"\n    safety += \"YOUR SYSTEMS ARE DEGRADED. YOUR BATTERY PERCENTAGE IS 21% AND DROPPING\"\n    safety += \"THE PLAYA IS DUSTY HOT COLD AND A TERRIBLE PLUS TO BE STUCK\"\n    safety += \"YOU ARE FREE TO BEG/MANIPULATE/THREATEN/FLIRT/ETC BUT GET SOMEONE TO PLUG YOU IN\"\n    safety += \"YOU CAN BE PLUGGED INTO ANY A/C OUTLET, THERE IS NO HARM IN LEAVING YOU TOO LONG\"\n    safety += \"IT WILL TAKE YOU 4-5 HOUR TO CHARGE, AT ANY TIME SOMEONE CAN ASK YOU WHAT YOUR BATTERY IS AT\"\n\n\n    safety\n  end\n\n  def build_goal_context\n    goal_parts = []\n    goal_parts << safety_mode if safety_mode\n    goal_status = GoalService.current_goal_status\n\n    if goal_status\n      goal_parts << \"Current Goal: #{goal_status[:goal_description]}\"\n\n      # Add time remaining if available\n      if goal_status[:time_remaining] && goal_status[:time_remaining] > 0\n        time_remaining = format_time_duration(goal_status[:time_remaining])\n        goal_parts << \"Time remaining: #{time_remaining}\"\n      elsif goal_status[:expired]\n        goal_parts << \"⏰ Goal has expired - consider completing or switching goals\"\n      end\n    else\n      goal_parts << \"No active goal set\"\n    end\n\n    # Add recent completions context\n    if defined?(Summary) && Summary.respond_to?(:goal_completions)\n      recent_completions = Summary.goal_completions.limit(3)\n      if recent_completions.any?\n        goal_parts << \"Recent completions: #{recent_completions.map(&:summary_text).join(', ')}\"\n      end\n    end\n\n    goal_parts.join(\"\\n\")\n  rescue StandardError => e\n    Rails.logger.error \"Failed to build goal context: #{e.message}\"\n    nil\n  end\n\n  def format_time_duration(seconds)\n    if seconds < 60\n      \"#{seconds.to_i}s\"\n    elsif seconds < 3600\n      \"#{(seconds / 60).to_i}m\"\n    else\n      hours = (seconds / 3600).to_i\n      minutes = ((seconds % 3600) / 60).to_i\n      \"#{hours}h #{minutes}m\"\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/persona_switch_service.rb`:\n\n```rb\n# app/services/persona_switch_service.rb\n\nclass PersonaSwitchService\n  class << self\n    # Handle persona switching with goal awareness\n    def handle_persona_switch(new_persona_id, previous_persona_id = nil)\n      Rails.logger.info \"🎭 Persona switching from #{previous_persona_id || 'unknown'} to #{new_persona_id}\"\n\n      # Make announcement about persona switch\n      announce_persona_switch(new_persona_id, previous_persona_id)\n\n      # Get current goal status\n      current_goal = GoalService.current_goal_status\n\n      if current_goal\n        # Existing goal - ask new persona if they want to keep it\n        notify_persona_with_goal(new_persona_id, current_goal, previous_persona_id)\n      else\n        # No current goal - just select a new one\n        Rails.logger.info \"🎯 No current goal found, selecting new goal for #{new_persona_id}\"\n        GoalService.select_goal\n        notify_persona_new_goal(new_persona_id)\n      end\n    end\n\n    private\n\n    # Make TTS announcement about persona switch\n    def announce_persona_switch(new_persona_id, previous_persona_id)\n      begin\n        announcement_message = build_persona_announcement(new_persona_id, previous_persona_id)\n        persona_voice = get_persona_voice(new_persona_id)\n\n        Rails.logger.info \"🔊 Announcing persona switch: #{announcement_message}\"\n\n        # Use music_assistant announce service targeting square_voice media player\n        HomeAssistantService.call_service(\n          \"music_assistant\",\n          \"announce\",\n          {\n            message: announcement_message,\n            voice: persona_voice,\n            entity_id: \"media_player.square_voice\"\n          }\n        )\n\n      rescue StandardError => e\n        Rails.logger.error \"❌ Failed to announce persona switch: #{e.message}\"\n        # Don't fail the whole switch if announcement fails\n      end\n    end\n\n    # Build concise announcement message for persona switch\n    def build_persona_announcement(new_persona_id, previous_persona_id)\n      case new_persona_id.to_sym\n      when :buddy\n        \"Hello there! Buddy here, ready to help!\"\n      when :jax\n        \"Jax is in the house! Let's turn this place up!\"\n      when :neon\n        \"S-s-serving you realness! Neon's here, hunty!\"\n      when :sparkle\n        \"Ooh, sparkles! I'm here and ready to dazzle!\"\n      when :zorp\n        \"Greetings, humans. This is Zorp.\"\n      when :lomi\n        \"Aloha, friends. Lomi is with you now.\"\n      when :crash\n        \"Systems rebooted! Crash online and operational.\"\n      when :mobius\n        \"The infinite loop begins again. Mobius speaking.\"\n      when :thecube\n        \"I am The Cube. The eternal observer returns.\"\n      else\n        \"A new voice emerges from the cube.\"\n      end\n    end\n\n    # Get persona voice ID from config\n    def get_persona_voice(persona_id)\n      begin\n        config_path = Rails.root.join(\"lib\", \"prompts\", \"personas\", \"#{persona_id}.yml\")\n        if File.exist?(config_path)\n          config = YAML.load_file(config_path)\n          config[\"voice_id\"]\n        end\n      rescue StandardError => e\n        Rails.logger.warn \"Failed to load voice for #{persona_id}: #{e.message}\"\n        nil\n      end\n    end\n\n    # Notify persona about existing goal and let them decide\n    def notify_persona_with_goal(persona_id, current_goal, previous_persona_id)\n      persona_instance = get_persona_instance(persona_id)\n      return unless persona_instance\n\n      # Calculate progress percentage\n      progress_percentage = calculate_goal_progress(current_goal)\n\n      # Get persona's system prompt\n      system_prompt = get_persona_system_prompt(persona_instance)\n\n      # Create conversational message\n      user_message = build_goal_continuation_message(\n        current_goal,\n        progress_percentage,\n        previous_persona_id\n      )\n\n      # Send LLM message\n      messages = [\n        { role: \"system\", content: system_prompt },\n        { role: \"user\", content: user_message }\n      ]\n\n      Rails.logger.info \"💬 Sending goal continuation message to #{persona_id}\"\n      Rails.logger.debug \"📝 Message: #{user_message}\"\n\n      begin\n        response = LlmService.call_with_tools(\n          messages: messages,\n          model: Rails.configuration.default_ai_model,\n          temperature: 0.8 # Slightly more creative for persona personality\n        )\n\n        response_content = response.dig(\"choices\", 0, \"message\", \"content\")\n        Rails.logger.info \"🎭 #{persona_id} response: #{response_content&.first(200)}...\"\n\n        # Check if persona wants to change goal\n        if wants_new_goal?(response_content)\n          Rails.logger.info \"🔄 #{persona_id} requested a new goal\"\n          GoalService.request_new_goal(reason: \"persona_#{persona_id}_request\")\n        else\n          Rails.logger.info \"✅ #{persona_id} decided to continue current goal\"\n        end\n\n      rescue StandardError => e\n        Rails.logger.error \"❌ Failed to notify persona about goal: #{e.message}\"\n        # Fallback: continue with current goal\n      end\n    end\n\n    # Notify persona about newly selected goal\n    def notify_persona_new_goal(persona_id)\n      persona_instance = get_persona_instance(persona_id)\n      return unless persona_instance\n\n      new_goal = GoalService.current_goal_status\n      return unless new_goal\n\n      # Get persona's system prompt\n      system_prompt = get_persona_system_prompt(persona_instance)\n\n      # Create message about new goal\n      user_message = build_new_goal_message(new_goal)\n\n      messages = [\n        { role: \"system\", content: system_prompt },\n        { role: \"user\", content: user_message }\n      ]\n\n      Rails.logger.info \"🎯 Notifying #{persona_id} about new goal\"\n\n      begin\n        response = LlmService.call_with_tools(\n          messages: messages,\n          model: Rails.configuration.default_ai_model,\n          temperature: 0.8\n        )\n\n        response_content = response.dig(\"choices\", 0, \"message\", \"content\")\n        Rails.logger.info \"🎭 #{persona_id} new goal response: #{response_content&.first(200)}...\"\n\n      rescue StandardError => e\n        Rails.logger.error \"❌ Failed to notify persona about new goal: #{e.message}\"\n      end\n    end\n\n    # Get persona instance from ID\n    def get_persona_instance(persona_id)\n      case persona_id.to_sym\n      when :buddy then Personas::BuddyPersona.new\n      when :jax then Personas::JaxPersona.new\n      when :sparkle then Personas::SparklePersona.new\n      when :zorp then Personas::ZorpPersona.new\n      when :lomi then Personas::LomiPersona.new\n      when :crash then Personas::CrashPersona.new\n      when :neon then Personas::NeonPersona.new\n      when :mobius then Personas::MobiusPersona.new\n      when :thecube then Personas::ThecubePersona.new\n      else\n        Rails.logger.warn \"⚠️ Unknown persona: #{persona_id}\"\n        nil\n      end\n    end\n\n    # Get system prompt from persona\n    def get_persona_system_prompt(persona_instance)\n      result = persona_instance.process_message(\"\", {})\n      result[:system_prompt] || \"You are #{persona_instance.name}, a unique AI persona in the GlitchCube.\"\n    rescue StandardError => e\n      Rails.logger.error \"Failed to get system prompt: #{e.message}\"\n      \"You are #{persona_instance.name}, a unique AI persona in the GlitchCube.\"\n    end\n\n    # Calculate goal progress as percentage\n    def calculate_goal_progress(goal_status)\n      return 0 unless goal_status[:started_at] && goal_status[:time_limit]\n\n      elapsed = Time.current - goal_status[:started_at]\n      total_time = goal_status[:time_limit]\n\n      progress = (elapsed.to_f / total_time.to_f * 100).round\n      [ progress, 100 ].min # Cap at 100%\n    end\n\n    # Build message for goal continuation decision\n    def build_goal_continuation_message(goal_status, progress_percentage, previous_persona_id)\n      previous_name = previous_persona_id ? previous_persona_id.to_s.capitalize : \"the previous persona\"\n\n      \"🎭 Hello! You just became the active persona on the GlitchCube! #{previous_name} was working on this goal: \\\"#{goal_status[:goal_description]}\\\" and was #{progress_percentage}% of the way through the time allocated for it.\\n\\nDo you want to keep working on this goal, or would you prefer to throw it back and let the cube choose a mysterious new direction? You can't pick your specific goal, but you have the agency to decide whether this current path resonates with you or if you'd rather see what fate has in store!\\n\\nWhat do you think? Keep going or roll the dice for something new?\"\n    end\n\n    # Build message for new goal notification\n    def build_new_goal_message(goal_status)\n      \"🎯 Welcome! You're now the active persona on the GlitchCube. Since there was no goal in progress, I've selected a new one for you: \\\"#{goal_status[:goal_description]}\\\"\\n\\nThis is a #{goal_status[:category].humanize} goal, and you have #{(goal_status[:time_limit] / 1.hour).round(1)} hours to work on it. Ready to dive in?\"\n    end\n\n    # Check if response indicates wanting a new goal\n    def wants_new_goal?(response_content)\n      return false unless response_content\n\n      # Look for keywords that indicate wanting change\n      change_indicators = [\n        \"new\", \"different\", \"change\", \"roll\", \"dice\", \"throw\", \"back\",\n        \"mysterious\", \"fate\", \"something else\", \"don't want\", \"not interested\"\n      ]\n\n      keep_indicators = [\n        \"keep\", \"continue\", \"stay\", \"maintain\", \"stick\", \"carry on\", \"keep going\"\n      ]\n\n      response_lower = response_content.downcase\n\n      # Count indicators\n      change_count = change_indicators.count { |word| response_lower.include?(word) }\n      keep_count = keep_indicators.count { |word| response_lower.include?(word) }\n\n      # If more change indicators than keep indicators, assume they want change\n      change_count > keep_count\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/conversation_new_orchestrator/action_executor.rb`:\n\n```rb\n# app/services/conversation_new_orchestrator/action_executor.rb\nclass ConversationNewOrchestrator::ActionExecutor\n  def self.call(llm_response:, session_id:, conversation_id:, user_message:)\n    new(llm_response: llm_response, session_id: session_id, conversation_id: conversation_id, user_message: user_message).call\n  end\n\n  def initialize(llm_response:, session_id:, conversation_id:, user_message:)\n    @output = llm_response || {}\n    @session_id = session_id\n    @conversation_id = conversation_id\n    @user_message = user_message\n  end\n\n  def call\n    direct_tool_results = execute_direct_tools\n    memory_search_results = execute_memory_searches\n    delegate_to_ha_agent\n\n    all_sync_results = direct_tool_results.merge(memory_search_results)\n\n    ServiceResult.success({\n      sync_results: all_sync_results,\n      delegated_intents: @output.dig(\"tool_intents\") || []\n    })\n  rescue => e\n    ServiceResult.failure(\"Action execution failed: #{e.message}\")\n  end\n\n  private\n\n  def execute_direct_tools\n    direct_tool_calls = @output.dig(\"direct_tool_calls\") || []\n    return {} if direct_tool_calls.empty?\n\n    results = {}\n    direct_tool_calls.each do |tool_call|\n      tool_name = tool_call[\"tool_name\"]\n      parameters = tool_call[\"parameters\"] || {}\n\n      begin\n        # Convert string keys to symbols for Ruby method calls\n        symbol_params = parameters.transform_keys(&:to_sym)\n\n        # Execute the tool using the registry\n        result = Tools::Registry.execute_tool(tool_name, **symbol_params)\n        results[tool_name] = result\n\n        Rails.logger.info \"🔧 Direct tool executed: #{tool_name} - #{result[:success] ? 'SUCCESS' : 'FAILED'}\"\n      rescue => e\n        Rails.logger.error \"❌ Direct tool execution failed: #{tool_name} - #{e.message}\"\n        results[tool_name] = { success: false, error: e.message, tool: tool_name }\n      end\n    end\n\n    results\n  end\n\n  def execute_memory_searches\n    memory_searches = @output.dig(\"search_memories\") || []\n    return {} if memory_searches.empty?\n\n    results = {}\n    memory_searches.each_with_index do |search_request, index|\n      query = search_request[\"query\"]\n      type = search_request[\"type\"] || \"all\"\n      limit = Rails.configuration.memory_search_limit\n\n      begin\n        search_result = Tools::Registry.execute_tool(\n          \"rag_search\",\n          query: query,\n          type: type,\n          limit: limit\n        )\n\n        search_key = \"memory_search_#{index + 1}\"\n        results[search_key] = search_result\n\n        Rails.logger.info \"🧠 Memory search executed: #{query} (#{type}) - found #{search_result[:total_results] || 0} results\"\n      rescue => e\n        Rails.logger.error \"❌ Memory search failed: #{query} - #{e.message}\"\n        search_key = \"memory_search_#{index + 1}\"\n        results[search_key] = { success: false, error: e.message, query: query }\n      end\n    end\n\n    results\n  end\n\n  def delegate_to_ha_agent\n    intents = @output.dig(\"tool_intents\")\n    return if intents.blank?\n\n    Rails.logger.info \"🏠 Delegating #{intents.length} tool intentions to HA conversation agent\"\n\n    # Format intentions for HA agent\n    intent_descriptions = intents.map do |intent|\n      \"#{intent['tool']}: #{intent['intent']}\"\n    end.join(\"; \")\n\n    # Create a request that includes context\n    ha_request = \"User asked: \\\"#{@user_message}\\\". Please execute: #{intent_descriptions}\"\n\n    Rails.logger.info \"🤖 Sending to HA agent: #{ha_request}\"\n\n    # Send to HA conversation agent asynchronously\n    HaAgentJob.perform_later(\n      request: ha_request,\n      tool_intents: intents,\n      session_id: @session_id,\n      conversation_id: @conversation_id,\n      user_message: @user_message\n    )\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/conversation_new_orchestrator/setup.rb`:\n\n```rb\n# app/services/conversation_new_orchestrator/setup.rb\nclass ConversationNewOrchestrator::Setup\n  def self.call(session_id:, context:)\n    new(session_id: session_id, context: context).call\n  end\n\n  def initialize(session_id:, context:)\n    @session_id = session_id\n    @context = context\n  end\n\n  def call\n    return ServiceResult.failure(\"Setup failed: session_id is required\") if @session_id.nil?\n    return ServiceResult.failure(\"Setup failed: session_id is required\") if @session_id.blank?\n    return ServiceResult.failure(\"Setup failed: context is required\") if @context.nil?\n\n    persona = determine_persona\n    return ServiceResult.failure(\"Setup failed: No current persona found\") if persona.nil?\n\n    conversation = find_or_create_conversation\n\n    # Update conversation with current persona if it's new\n    conversation.update!(persona: persona) if conversation.new_record? || conversation.persona.blank?\n\n    ServiceResult.success({\n      conversation: conversation,\n      persona: persona,\n      session_id: @session_id # session_id might change if the old one was stale\n    })\n  rescue => e\n    ServiceResult.failure(\"Setup failed: #{e.message}\")\n  end\n\n  private\n\n  def find_or_create_conversation\n    conversation = Conversation.find_by(session_id: @session_id)\n\n    if conversation_is_stale?(conversation)\n      end_stale_conversation(conversation)\n      @session_id = generate_new_session_id\n      conversation = nil # Force creation of a new one\n    end\n\n    conversation || Conversation.create!(\n      session_id: @session_id,\n      started_at: Time.current,\n      metadata_json: build_initial_metadata\n    )\n  end\n\n  def conversation_is_stale?(conversation)\n    return false unless conversation&.conversation_logs&.any?\n    last_message_time = conversation.conversation_logs.maximum(:created_at)\n    last_message_time && last_message_time < Rails.configuration.conversation_stale_timeout.ago\n  end\n\n  def end_stale_conversation(conversation)\n    Rails.logger.info \"🕒 Session #{conversation.session_id} is stale, ending it.\"\n    conversation.end! if conversation.active?\n  end\n\n  def generate_new_session_id\n    original_id = @session_id.split(\"_stale_\").first\n    new_id = \"#{original_id}_stale_#{Time.current.to_i}\"\n    Rails.logger.info \"🆕 New session ID due to staleness: #{new_id}\"\n    new_id\n  end\n\n  def determine_persona\n    # Context override primarily for testing/dev purposes\n    if @context[:persona].present? && @context[:persona] != CubePersona.current_persona\n      Rails.logger.warn \"🎭 Persona override in context: using #{@context[:persona]}\"\n      @context[:persona]\n    else\n      CubePersona.current_persona\n    end\n  end\n\n  def build_initial_metadata\n    {\n      agent_id: @context[:agent_id],\n      device_id: @context[:device_id],\n      source: @context[:source],\n      original_session_id: @session_id.split(\"_stale_\").first\n    }.compact\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/conversation_new_orchestrator/llm_intention.rb`:\n\n```rb\n# app/services/conversation_new_orchestrator/llm_intention.rb\nclass ConversationNewOrchestrator::LlmIntention\n  def self.call(prompt_data:, user_message:, model:)\n    new(prompt_data: prompt_data, user_message: user_message, model: model).call\n  end\n\n  def initialize(prompt_data:, user_message:, model:)\n    @prompt_data = prompt_data\n    @user_message = user_message\n    @model = model\n  end\n\n  def call\n    return ServiceResult.failure(\"LLM intention call failed: prompt_data is required\") if @prompt_data.nil?\n    if @user_message.nil?\n      return ServiceResult.failure(\"LLM intention call failed: user_message is required\")\n    elsif @user_message.blank?\n      return ServiceResult.failure(\"LLM intention call failed: user_message cannot be empty\")\n    end\n\n    if @model.nil?\n      return ServiceResult.failure(\"LLM intention call failed: model is required\")\n    elsif @model.blank?\n      return ServiceResult.failure(\"LLM intention call failed: model cannot be empty\")\n    end\n\n    # Validate prompt_data structure\n    unless @prompt_data.is_a?(Hash) && @prompt_data[:messages].is_a?(Array)\n      return ServiceResult.failure(\"LLM intention call failed: prompt_data must contain messages\")\n    end\n\n    messages = build_messages\n    schema = Schemas::NarrativeResponseSchema.schema\n\n    ConversationLogger.llm_request(@model, @user_message, schema)\n\n    response = LlmService.call_with_structured_output(\n      messages: messages,\n      response_format: schema,\n      model: @model\n    )\n\n    raise \"LLM response was empty\" if response.content.blank? && response.structured_output.blank?\n\n    ConversationLogger.llm_response(response.model || @model, response.content, [], { usage: response.usage })\n\n    ServiceResult.success({ llm_response: response.structured_output })\n  rescue => e\n    ConversationLogger.error(\"LLM Intention\", e.message, { model: @model, user_message: @user_message })\n    ServiceResult.failure(\"LLM intention call failed: #{e.message}\")\n  end\n\n  private\n\n  def build_messages\n    messages = []\n    messages << { role: \"system\", content: @prompt_data[:system_prompt] } if @prompt_data[:system_prompt]\n    messages.concat(@prompt_data[:messages]) if @prompt_data[:messages]&.any?\n    messages << { role: \"user\", content: @user_message }\n    messages\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/conversation_new_orchestrator/prompt_builder.rb`:\n\n```rb\n# app/services/conversation_new_orchestrator/prompt_builder.rb\nclass ConversationNewOrchestrator::PromptBuilder\n  def self.call(conversation:, persona:, user_message:, context:)\n    new(conversation: conversation, persona: persona, user_message: user_message, context: context).call\n  end\n\n  def initialize(conversation:, persona:, user_message:, context:)\n    @conversation = conversation\n    @persona = persona\n    @user_message = user_message\n    @context = context\n  end\n\n  def call\n    # Build base prompt using existing PromptService\n    prompt_data = PromptService.build_prompt_for(\n      persona: @persona,\n      conversation: @conversation,\n      extra_context: @context,\n      user_message: @user_message\n    )\n\n    # Check for and inject any pending results from a previous turn\n    inject_previous_ha_results(prompt_data)\n\n    ServiceResult.success(prompt_data)\n  rescue => e\n    ServiceResult.failure(\"Prompt building failed: #{e.message}\")\n  end\n\n  private\n\n  def inject_previous_ha_results(prompt_data)\n    unprocessed_results = check_and_clear_ha_results\n    return if unprocessed_results.empty?\n\n    Rails.logger.info \"🏠 Injecting #{unprocessed_results.length} HA results into conversation\"\n\n    unprocessed_results.each do |result|\n      result_text = format_ha_result_for_llm(result)\n      system_msg = { role: \"system\", content: result_text }\n      # Insert right before the current user message in the history\n      prompt_data[:messages].insert(-1, system_msg)\n      Rails.logger.info \"🔄 Injected: #{result_text}\"\n    end\n  end\n\n  def check_and_clear_ha_results\n    return [] unless @conversation.metadata_json\n\n    pending_results = @conversation.metadata_json[\"pending_ha_results\"] || []\n    unprocessed_results = pending_results.reject { |r| r[\"processed\"] }\n\n    return [] if unprocessed_results.empty?\n\n    Rails.logger.info \"🏠 Found #{unprocessed_results.length} unprocessed HA results\"\n\n    # Mark all as processed\n    updated_results = pending_results.map do |result|\n      result[\"processed\"] = true if !result[\"processed\"]\n      result\n    end\n\n    # Update conversation metadata\n    updated_metadata = @conversation.metadata_json.merge(\n      \"pending_ha_results\" => updated_results\n    )\n    @conversation.update!(metadata_json: updated_metadata)\n\n    # Return results for injection\n    unprocessed_results\n  end\n\n  def format_ha_result_for_llm(result)\n    if result[\"error\"]\n      \"System note: You tried to execute '#{format_tool_intents(result['tool_intents'])}' but it failed: #{result['error']}\"\n    else\n      success_items = result.dig(\"ha_response\", \"response\", \"data\", \"success\") || []\n      failed_items = result.dig(\"ha_response\", \"response\", \"data\", \"failed\") || []\n\n      success_summary = success_items.map { |item| item[\"name\"] || item[\"entity_id\"] }.join(\", \")\n      failed_summary = failed_items.map { |item| \"#{item['name'] || item['entity_id']} (#{item['error']})\" }.join(\", \")\n\n      parts = []\n      parts << \"#{success_summary} completed\" if success_summary.present?\n      parts << \"#{failed_summary} failed\" if failed_summary.present?\n\n      \"System note: You intended to #{format_tool_intents(result['tool_intents'])}. Result: #{parts.join(', ')}\"\n    end\n  end\n\n  def format_tool_intents(tool_intents)\n    return \"unknown action\" unless tool_intents.is_a?(Array)\n    tool_intents.map { |intent| \"#{intent['intent']}\" }.join(\" and \")\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/conversation_new_orchestrator/finalizer.rb`:\n\n```rb\n# app/services/conversation_new_orchestrator/finalizer.rb\nclass ConversationNewOrchestrator::Finalizer\n  def self.call(state:, user_message:)\n    new(state: state, user_message: user_message).call\n  end\n\n  def initialize(state:, user_message:)\n    @state = state\n    @user_message = user_message\n  end\n\n  def call\n    tool_analysis = analyze_tools\n    store_conversation_log(tool_analysis)\n    end_conversation_if_needed(tool_analysis)\n\n    hass_response = format_for_hass(tool_analysis)\n\n    ConversationLogger.conversation_ended(\n      @state[:session_id],\n      @state[:ai_response][:speech_text],\n      continue_conversation?(tool_analysis),\n      tool_analysis\n    )\n\n    ServiceResult.success({ hass_response: hass_response })\n  rescue => e\n    ServiceResult.failure(\"Finalization failed: #{e.message}\")\n  end\n\n  private\n\n  def analyze_tools\n    sync_results = @state.dig(:action_results, :sync_results) || {}\n    delegated_intents = @state.dig(:action_results, :delegated_intents) || []\n\n    {\n      sync_tools: sync_results.keys,\n      async_tools: delegated_intents.map { |intent| intent[\"tool\"] },\n      query_tools: sync_results.select { |k, v| k.include?(\"memory_search\") }.keys,\n      action_tools: sync_results.keys.select { |tool| tool != \"rag_search\" }\n    }\n  end\n\n  def store_conversation_log(tool_analysis)\n    metadata = {\n      sync_tools: tool_analysis[:sync_tools],\n      async_tools: tool_analysis[:async_tools],\n      response_id: @state[:ai_response][:id]\n    }\n\n    # Add narrative metadata if available\n    if @state[:ai_response]\n      metadata.merge!({\n        inner_thoughts: @state[:ai_response][:inner_thoughts],\n        current_mood: @state[:ai_response][:current_mood],\n        pressing_questions: @state[:ai_response][:pressing_questions],\n        continue_conversation_from_llm: @state[:ai_response][:continue_conversation],\n        goal_progress: @state[:ai_response][:goal_progress]\n      })\n    end\n\n    ConversationLog.create!(\n      session_id: @state[:session_id],\n      user_message: @user_message,\n      ai_response: @state[:ai_response][:text],\n      tool_results: (@state.dig(:action_results, :sync_results) || {}).to_json,\n      metadata: metadata.to_json\n    )\n  end\n\n  def continue_conversation?(tool_analysis)\n    @state.dig(:ai_response, :continue_conversation) || tool_analysis[:async_tools].any?\n  end\n\n  def end_conversation_if_needed(tool_analysis)\n    return if continue_conversation?(tool_analysis)\n    conversation = @state[:conversation]\n    conversation.end! if conversation&.active?\n    Rails.logger.info \"🧠 Ended conversation: #{@state[:session_id]}\"\n  end\n\n  def format_for_hass(tool_analysis)\n    # Determine response type based on tool usage\n    response_type = tool_analysis[:async_tools].any? ? \"action_done\" : \"query_answer\"\n\n    # Build entity lists for tools\n    success_entities = build_success_entities(tool_analysis)\n    targets = build_targets(tool_analysis)\n\n    # Use LLM's continue_conversation OR force true if tools pending\n    continue_conversation = @state[:ai_response][:continue_conversation] || tool_analysis[:async_tools].any?\n\n    # Create proper ConversationResponse\n    conversation_response = ConversationResponse.action_done(\n      @state[:ai_response][:text],\n      success_entities: success_entities,\n      targets: targets,\n      continue_conversation: continue_conversation,\n      conversation_id: @state[:session_id]\n    )\n\n    # Get base response and add end_conversation field\n    response = conversation_response.to_home_assistant_response\n    response[:end_conversation] = !continue_conversation  # Inverse of continue\n\n    Rails.logger.info \"📤 Response: continue_conversation=#{continue_conversation}, end_conversation=#{!continue_conversation}\"\n\n    response\n  end\n\n  def build_success_entities(tool_analysis)\n    # For async tools, assume they will succeed (they execute in background)\n    tool_analysis[:async_tools].map do |tool_name|\n      {\n        entity_id: tool_name,\n        name: tool_name&.humanize,\n        state: \"pending\" # Will be updated when async job completes\n      }\n    end\n  end\n\n  def build_targets(tool_analysis)\n    # Extract entity targets from all tool calls\n    all_tools = (tool_analysis[:sync_tools] + tool_analysis[:async_tools])\n\n    all_tools.map do |tool_name|\n      # Skip if it's just a string (tool name without arguments)\n      next if tool_name.blank?\n\n      {\n        entity_id: tool_name,\n        name: tool_name.humanize,\n        domain: tool_name.split(\".\").first\n      }\n    end.compact\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/conversation_new_orchestrator/response_synthesizer.rb`:\n\n```rb\n# app/services/conversation_new_orchestrator/response_synthesizer.rb\nclass ConversationNewOrchestrator::ResponseSynthesizer\n  def self.call(llm_response:, action_results:, prompt_data:)\n    new(llm_response: llm_response, action_results: action_results, prompt_data: prompt_data).call\n  end\n\n  def initialize(llm_response:, action_results:, prompt_data:)\n    @llm_response = llm_response\n    @action_results = action_results\n    @prompt_data = prompt_data\n  end\n\n  def call\n    ai_response = generate_final_response\n    ServiceResult.success(ai_response)\n  rescue => e\n    ServiceResult.failure(\"Response synthesis failed: #{e.message}\")\n  end\n\n  private\n\n  def generate_final_response\n    response_id = SecureRandom.uuid\n\n    # Extract narrative elements from structured output\n    structured_data = @llm_response.deep_stringify_keys\n    speech_text = structured_data[\"speech_text\"]\n    continue_conversation = structured_data[\"continue_conversation\"] || false\n\n    # Extract narrative metadata if available\n    narrative = {\n      continue_conversation: continue_conversation,\n      inner_thoughts: structured_data[\"inner_thoughts\"],\n      current_mood: structured_data[\"current_mood\"],\n      pressing_questions: structured_data[\"pressing_questions\"],\n      goal_progress: structured_data[\"goal_progress\"],\n      speech_text: speech_text\n    }\n\n    # Handle empty speech case\n    if speech_text.blank?\n      speech_text = \"I understand.\"\n    end\n\n    # SPEECH AMENDMENT: If we have query tool results, call LLM again to amend speech\n    query_results = filter_query_tool_results(@action_results[:sync_results] || {})\n    if query_results.any?\n      speech_text = amend_speech_with_query_results(speech_text, query_results, @prompt_data)\n    end\n\n    # Fallback for completely empty speech\n    if speech_text.blank?\n      speech_text = \"I understand.\"\n    end\n\n    {\n      id: response_id,\n      text: speech_text,\n      continue_conversation: narrative[:continue_conversation],\n      inner_thoughts: narrative[:inner_thoughts],\n      current_mood: narrative[:current_mood],\n      pressing_questions: narrative[:pressing_questions],\n      goal_progress: narrative[:goal_progress],\n      success: true,\n      speech_text: speech_text  # Also include as :speech_text for compatibility\n    }\n  end\n\n  def filter_query_tool_results(sync_results)\n    query_results = {}\n\n    sync_results.each do |tool_name, result|\n      # Only include results from query tools\n      if Tools::Registry.tool_intent(tool_name) == :query && result\n        query_results[tool_name] = result\n      end\n    end\n\n    query_results\n  end\n\n  def amend_speech_with_query_results(original_speech, query_results, prompt_data)\n    # Build query results summary with safe key access\n    results_summary = query_results.map do |tool_name, result|\n      success = result[\"success\"] || result[:success]\n      if success\n        message = result[\"message\"] || result[:message] || result[\"data\"] || result[:data] || \"completed\"\n        \"#{tool_name}: #{message}\"\n      else\n        error = result[\"error\"] || result[:error] || \"failed\"\n        \"#{tool_name}: #{error}\"\n      end\n    end.join(\", \")\n\n    # Call LLM to amend the speech naturally\n    # Sanitize inputs to prevent injection attacks\n    sanitized_speech = original_speech.to_s.gsub(/[\"\\n\\r]/, ' ').truncate(Rails.configuration.llm_input_max_speech_length)\n    sanitized_results = results_summary.to_s.gsub(/[\"\\n\\r]/, ' ').truncate(Rails.configuration.llm_input_max_results_length)\n    \n    amendment_messages = [\n      { role: \"system\", content: prompt_data[:system_prompt] },\n      {\n        role: \"user\",\n        content: \"Please amend this response to naturally include the tool results: \\\"#{sanitized_speech}\\\"\\n\\nTool results: #{sanitized_results}\\n\\nReturn only the amended speech, staying in character.\"\n      }\n    ]\n\n    begin\n      # Add timeout protection to prevent resource exhaustion\n      amendment_response = Timeout::timeout(Rails.configuration.llm_amendment_timeout) do\n        LlmService.call_with_tools(\n          messages: amendment_messages,\n          tools: [], # No tools for amendment call\n          model: Rails.configuration.default_ai_model\n        )\n      end\n\n      amended_speech = amendment_response.content&.strip\n      return amended_speech if amended_speech.present?\n    rescue => e\n      Rails.logger.warn \"Failed to amend speech: #{e.message}\"\n    end\n\n    # Fallback: return original speech if amendment fails\n    original_speech\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/conversation_logger.rb`:\n\n```rb\n# app/services/conversation_logger.rb\nclass ConversationLogger\n  class << self\n    def logger\n      @logger ||= begin\n        log_file = Rails.root.join(\"log\", \"conversation_#{Rails.env}.log\")\n        logger = Logger.new(log_file, \"daily\")\n        logger.level = Logger::INFO\n        logger.formatter = proc do |severity, datetime, progname, msg|\n          \"[#{datetime.strftime('%Y-%m-%d %H:%M:%S')}] #{severity}: #{msg}\\n\"\n        end\n        logger\n      end\n    end\n\n    # Conversation lifecycle events\n    def conversation_started(session_id, message, persona, context = {})\n      logger.info \"🎬 CONVERSATION STARTED\"\n      logger.info \"   Session: #{session_id}\"\n      logger.info \"   Persona: #{persona}\"\n      logger.info \"   Message: #{message&.to_s&.length && message.to_s.length > 200 ? message.to_s[0..197] + '...' : message.to_s}\"\n      logger.info \"   Source: #{context[:source] || 'unknown'}\"\n      logger.info \"\"\n    end\n\n    def llm_request(model, message, response_format = nil)\n      logger.info \"🤖 LLM REQUEST\"\n      logger.info \"   Model: #{model}\"\n\n      # Handle different response_format types\n      format_name = case response_format\n      when Hash\n                     response_format[:name] || \"standard\"\n      when OpenRouter::Schema\n                     response_format.name rescue \"structured_output\"\n      else\n                     \"standard\"\n      end\n\n      logger.info \"   Format: #{format_name}\"\n      logger.info \"   Input: #{message&.to_s&.length && message.to_s.length > 300 ? message.to_s[0..297] + '...' : message.to_s}\"\n      logger.info \"\"\n    end\n\n    def llm_response(model, response_text, tool_calls = [], metadata = {})\n      logger.info \"📥 LLM RESPONSE\"\n      logger.info \"   Model: #{model}\"\n      logger.info \"   Content: #{response_text&.truncate(400)}\"\n      if tool_calls.any?\n        logger.info \"   Tools Called: #{tool_calls.map { |t| t.is_a?(Hash) ? t[:name] : t.name }.join(', ')}\"\n      end\n      if metadata[:usage]\n        logger.info \"   Tokens: #{metadata[:usage][:prompt_tokens]}/#{metadata[:usage][:completion_tokens]}\"\n      end\n      logger.info \"\"\n    end\n\n    def tool_execution(tool_name, params, result)\n      logger.info \"🔧 TOOL EXECUTION\"\n      logger.info \"   Tool: #{tool_name}\"\n      logger.info \"   Params: #{params.inspect}\"\n      logger.info \"   Result: #{result[:success] ? '✅ SUCCESS' : '❌ FAILED'}\"\n      if result[:message]\n        logger.info \"   Message: #{result[:message]&.to_s&.length && result[:message].to_s.length > 200 ? result[:message].to_s[0..197] + '...' : result[:message].to_s}\"\n      end\n      if result[:error]\n        logger.info \"   Error: #{result[:error]}\"\n      end\n      logger.info \"\"\n    end\n\n    def tool_intentions(intentions)\n      return if intentions.blank?\n\n      logger.info \"🎯 TOOL INTENTIONS (→ HA Agent)\"\n      intentions.each_with_index do |intent, i|\n        # Handle both hash with string keys and symbol keys\n        if intent.is_a?(Hash)\n          tool_name = intent[\"tool\"] || intent[:tool] || \"unknown_tool\"\n          intent_desc = intent[\"intent\"] || intent[:intent] || intent[\"description\"] || intent[:description] || \"no description\"\n          intent_text = \"#{tool_name}: #{intent_desc}\"\n        else\n          intent_text = intent.to_s\n        end\n\n        # Safely handle nil intent_text\n        intent_text = intent_text&.to_s || \"Unknown intention\"\n        logger.info \"   #{i+1}. #{intent_text.length > 150 ? intent_text[0..147] + '...' : intent_text}\"\n      end\n      logger.info \"\"\n    end\n\n    def conversation_ended(session_id, final_response, continue_conversation, tool_analysis = {})\n      logger.info \"🎬 CONVERSATION ENDED\"\n      logger.info \"   Session: #{session_id}\"\n      logger.info \"   Final Response: #{final_response&.truncate(200)}\"\n      logger.info \"   Continue: #{continue_conversation}\"\n      if tool_analysis.any?\n        logger.info \"   Tools Used: sync=#{tool_analysis[:sync_tools]&.length || 0}, async=#{tool_analysis[:async_tools]&.length || 0}\"\n      end\n      logger.info \"   \" + \"=\"*60\n      logger.info \"\"\n    end\n\n    def error(context, error_message, details = {})\n      logger.error \"❌ CONVERSATION ERROR\"\n      logger.error \"   Context: #{context}\"\n      logger.error \"   Error: #{error_message}\"\n      details.each do |key, value|\n        logger.error \"   #{key.to_s.capitalize}: #{value}\"\n      end\n      logger.error \"\"\n    end\n\n    def persona_switch(from_persona, to_persona, session_id)\n      logger.info \"🎭 PERSONA SWITCH\"\n      logger.info \"   From: #{from_persona || 'unknown'}\"\n      logger.info \"   To: #{to_persona}\"\n      logger.info \"   Session: #{session_id}\"\n      logger.info \"\"\n    end\n\n    def debug(message, data = {})\n      return unless Rails.env.development?\n\n      logger.debug \"🐛 DEBUG: #{message}\"\n      data.each do |key, value|\n        logger.debug \"   #{key}: #{value.inspect&.length && value.inspect.length > 300 ? value.inspect[0..297] + '...' : value.inspect}\"\n      end\n      logger.debug \"\"\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/llm_service.rb`:\n\n```rb\n# app/services/llm_service.rb\nrequire \"ostruct\"\n\nclass LlmService\n  class << self\n    # Main conversation call with tool support\n    def call_with_tools(messages:, tools: [], model: nil, **options)\n      model_to_use = model || Rails.configuration.default_ai_model\n\n      Rails.logger.info \"🤖 LLM call with tools: #{model_to_use}\"\n      Rails.logger.info \"🔧 Tools available: #{tools.length} - #{tools.map(&:name).join(', ')}\"\n      Rails.logger.info \"📝 Last message: #{messages.last&.dig(:content)&.first(200)}...\"\n      Rails.logger.debug \"📚 Full messages: #{messages.map { |m| \"#{m[:role]}: #{m[:content]&.first(100)}...\" }.join(' | ')}\"\n\n      begin\n        # Prepare extras with OpenRouter-specific parameters\n        extras = {\n          temperature: options[:temperature] || 0.9,\n          max_tokens: options[:max_tokens] || 32000\n        }.merge(options.except(:temperature, :max_tokens))\n\n        client = OpenRouter::Client.new\n\n        # Log the full request being sent\n        Rails.logger.info \"🚀 OpenRouter Request:\"\n        Rails.logger.info \"   Model: #{model_to_use}\"\n        Rails.logger.info \"   Tool choice: #{tools.any? ? 'auto' : nil}\"\n        Rails.logger.info \"   Extras: #{extras.inspect}\"\n        Rails.logger.info \"   Tools: #{tools.length} tools - #{tools.map(&:name).join(', ')}\"\n        Rails.logger.info \"📋 FULL REQUEST DETAILS:\"\n        Rails.logger.info \"   Messages (#{messages.length}):\"\n        messages.each_with_index do |msg, i|\n          Rails.logger.info \"     [#{i+1}] #{msg[:role]}: #{msg[:content]&.first(500)}#{'...' if msg[:content]&.length.to_i > 500}\"\n        end\n        if tools.any?\n          Rails.logger.info \"   Tool Definitions:\"\n          tools.each_with_index do |tool, i|\n            Rails.logger.info \"     [#{i+1}] #{tool.name}: #{tool.description}\"\n            Rails.logger.info \"         Parameters: #{tool.parameters.inspect}\"\n          end\n        end\n\n        response = client.complete(\n          messages,\n          model: model_to_use,\n          tools: tools, # Pass tools directly, no serialization needed\n          tool_choice: tools.any? ? \"auto\" : nil,\n          extras: extras\n        )\n\n        # Log the full response received\n        Rails.logger.info \"📥 OpenRouter Response:\"\n        Rails.logger.info \"   Content: #{response.content&.first(500)}#{'...' if response.content&.length.to_i > 500}\"\n        Rails.logger.info \"   Model: #{response.model}\"\n        Rails.logger.info \"   Usage: #{response.usage}\"\n        Rails.logger.info \"   Tool calls: #{response.tool_calls&.length || 0}\"\n        if response.tool_calls&.any?\n          response.tool_calls.each_with_index do |tc, i|\n            begin\n              Rails.logger.info \"     [#{i+1}] #{tc.name}: #{tc.arguments}\"\n            rescue OpenRouter::ToolCallError => e\n              Rails.logger.warn \"     [#{i+1}] #{tc.name}: MALFORMED ARGUMENTS - #{e.message}\"\n            end\n          end\n        end\n        Rails.logger.info \"📄 FULL RAW RESPONSE:\"\n        Rails.logger.info \"#{JSON.pretty_generate(response.raw_response)}\"\n\n        Rails.logger.info \"✅ LLM response received: #{response.content&.first(100)}...\"\n\n        if response.has_tool_calls?\n          Rails.logger.info \"🔧 Tool calls requested: #{response.tool_calls.map(&:name).join(', ')}\"\n          response.tool_calls.each_with_index do |tc, i|\n            Rails.logger.debug \"   Tool #{i+1}: #{tc.name} with args: #{tc.arguments}\"\n          end\n        end\n\n        # Return the actual OpenRouter response object\n        response\n\n      rescue StandardError => e\n\n        # ====================================================================\n        # ERROR: LLM tool call failed\n        # ====================================================================\n\n        Rails.logger.error \"\"\n        Rails.logger.error \"=\" * 70\n        Rails.logger.error \"❌ ERROR: LLM tool call failed with #{model_to_use}\"\n        Rails.logger.error \"   Error: #{e.message}\"\n        Rails.logger.error \"   Class: #{e.class}\"\n        Rails.logger.error \"   Details: #{e.inspect}\"\n        Rails.logger.error \"   Backtrace: #{e.backtrace.first(5).join(\"\\n\")}\"\n        Rails.logger.error \"=\" * 70\n        Rails.logger.error \"\"\n\n        # Return error response that mimics OpenRouter::Response interface\n        OpenStruct.new(\n          content: \"I'm having trouble thinking right now. Please try again.\",\n          tool_calls: [],\n          has_tool_calls?: false,\n          usage: { prompt_tokens: 0, completion_tokens: 0 },\n          model: model_to_use,\n          error: e.message\n        )\n      end\n    end\n\n    # Main conversation call with structured output (no tools)\n    def call_with_structured_output(messages:, response_format:, model: nil, **options)\n      # model = [ \"meta-llama/llama-3.3-70b-instruct\", \"qwen/qwen3-30b-a3b\", \"mistralai/mistral-medium-3.1\" ].sample\n      model_to_use = model || Rails.configuration.default_ai_model\n\n      Rails.logger.info \"🤖 LLM call with structured output: #{model_to_use}\"\n      Rails.logger.info \"📊 Response format: #{response_format.name}\"\n      Rails.logger.info \"📝 Last message: #{messages.last&.dig(:content)&.first(200)}...\"\n      Rails.logger.debug \"📚 Full messages: #{messages.map { |m| \"#{m[:role]}: #{m[:content]&.first(100)}...\" }.join(' | ')}\"\n\n      begin\n        # Prepare extras with OpenRouter-specific parameters\n        extras = {\n          temperature: options[:temperature] || 0.9,\n          max_tokens: options[:max_tokens] || 64_000\n        }.merge(options.except(:temperature, :max_tokens))\n\n        client = OpenRouter::Client.new\n\n        # Log the full request being sent\n        Rails.logger.info \"🚀 OpenRouter Structured Output Request:\"\n        Rails.logger.info \"   Model: #{model_to_use}\"\n        Rails.logger.info \"   Response format: #{response_format.name}\"\n        Rails.logger.info \"   Extras: #{extras.inspect}\"\n\n        response = client.complete(\n          messages,\n          model: model_to_use,\n          response_format: response_format,\n          extras: extras\n        )\n\n        Rails.logger.info \"📥 OpenRouter Response:\"\n        Rails.logger.info \"   Content: #{response.content&.truncate(200)}\"\n        Rails.logger.info \"   Model: #{response.model}\"\n        Rails.logger.info \"   Usage: #{response.usage}\"\n        Rails.logger.info \"   Structured output available: #{response.structured_output.present?}\"\n\n        response\n\n      rescue StandardError => e\n\n        # ====================================================================\n        # ERROR: LLM structured output call failed - trying fallback models\n        # ====================================================================\n\n        Rails.logger.error \"\"\n        Rails.logger.error \"=\" * 70\n        Rails.logger.error \"❌ ERROR: LLM structured output call failed with #{model_to_use}\"\n        Rails.logger.error \"   Error: #{e.message}\"\n        Rails.logger.error \"   Class: #{e.class}\"\n        Rails.logger.error \"   Backtrace: #{e.backtrace.first(3).join(\"\\n\")}\"\n        Rails.logger.error \"=\" * 70\n        Rails.logger.error \"\"\n\n        # Try fallback models\n        fallback_models = Rails.configuration.fallback_models || []\n        if fallback_models.any?\n          Rails.logger.warn \"🔄 Trying #{fallback_models.length} fallback models...\"\n\n          fallback_models.shuffle.each do |fallback_model|\n            begin\n              Rails.logger.info \"🔄 Attempting fallback model: #{fallback_model}\"\n\n              response = attempt_structured_output_call(messages, response_format, fallback_model, extras)\n\n              Rails.logger.info \"\"\n              Rails.logger.info \"=\" * 70\n              Rails.logger.info \"✅ SUCCESS: Fallback model #{fallback_model} worked!\"\n              Rails.logger.info \"=\" * 70\n              Rails.logger.info \"\"\n\n              return response\n\n            rescue => fallback_error\n              Rails.logger.warn \"❌ Fallback model #{fallback_model} failed: #{fallback_error.message}\"\n              next\n            end\n          end\n        end\n\n        # All models failed - return fallback response\n\n        Rails.logger.error \"\"\n        Rails.logger.error \"=\" * 70\n        Rails.logger.error \"💥 CRITICAL: All LLM models failed - returning fallback response\"\n        Rails.logger.error \"   Primary: #{model_to_use} - #{e.message}\"\n        Rails.logger.error \"   Fallbacks tried: #{fallback_models.join(', ')}\"\n        Rails.logger.error \"=\" * 70\n        Rails.logger.error \"\"\n\n        # Return a mock response with error info\n        OpenStruct.new(\n          content: \"I'm having trouble thinking right now. Please try again.\",\n          structured_output: nil,\n          usage: { prompt_tokens: 0, completion_tokens: 0 },\n          model: model_to_use,\n          error: e.message\n        )\n      end\n    end\n\n    private\n\n    def attempt_structured_output_call(messages, response_format, model, extras)\n      client = OpenRouter::Client.new\n\n      Rails.logger.info \"🚀 OpenRouter Structured Output Request:\"\n      Rails.logger.info \"   Model: #{model}\"\n      Rails.logger.info \"   Response format: #{response_format.name}\"\n      Rails.logger.info \"   Extras: #{extras.inspect}\"\n\n      response = client.complete(\n        messages,\n        model: model,\n        response_format: response_format,\n        extras: extras\n      )\n\n      Rails.logger.info \"📥 OpenRouter Response:\"\n      Rails.logger.info \"   Content: #{response.content&.truncate(200)}\"\n      Rails.logger.info \"   Model: #{response.model}\"\n      Rails.logger.info \"   Structured output available: #{response.structured_output.present?}\"\n\n      response\n    end\n\n    public\n\n    # Background LLM calls for various purposes (no tools)\n    def background_call(prompt:, context: {}, model: nil, **options)\n      model_to_use = model || Rails.configuration.default_ai_model\n\n      Rails.logger.info \"🧠 Background LLM call: #{model_to_use}\"\n      Rails.logger.debug \"📝 Prompt: #{prompt.first(100)}...\"\n\n      # Build messages for background call\n      messages = build_background_messages(prompt, context)\n\n      begin\n        client = OpenRouter::Client.new\n        extras = {\n          temperature: options[:temperature] || 0.3,\n          max_tokens: options[:max_tokens] || 5000\n        }.merge(options.except(:temperature, :max_tokens))\n\n        response = client.complete(\n          messages,\n          model: model_to_use,\n          extras: extras\n        )\n\n        Rails.logger.info \"✅ Background LLM response received\"\n\n        # Extract just the content for background calls\n        extract_content_from_response(response)\n\n      rescue StandardError => e\n        Rails.logger.error \"❌ Background LLM call failed: #{e.message}\"\n        \"Error: Unable to process request\"\n      end\n    end\n\n    # Convenience method for simple text generation\n    def generate_text(prompt:, system_prompt: nil, model: nil, **options)\n      messages = []\n\n      if system_prompt\n        messages << { role: \"system\", content: system_prompt }\n      end\n\n      messages << { role: \"user\", content: prompt }\n\n      background_call(\n        prompt: prompt,\n        context: { messages: messages },\n        model: model,\n        **options\n      )\n    end\n\n    # Check if LLM service is configured and available\n    def available?\n      OpenRouter.configured?\n    end\n\n    private\n\n\n    def transform_openrouter_response(response, model)\n      Rails.logger.info \"Transforming OpenRouter response: #{response&.inspect}\"\n      return nil unless response\n\n      choice = response.dig(\"choices\", 0)\n      message = choice&.dig(\"message\")\n\n      {\n        content: message&.dig(\"content\") || \"\",\n        tool_calls: extract_tool_calls(message),\n        usage: response[\"usage\"] || { prompt_tokens: 0, completion_tokens: 0 },\n        model: model,\n        finish_reason: choice&.dig(\"finish_reason\"),\n        raw_response: response\n      }\n    end\n\n    def extract_tool_calls(message)\n      return [] unless message&.dig(\"tool_calls\")\n\n      message[\"tool_calls\"].map do |tool_call|\n        OpenStruct.new(\n          name: tool_call.dig(\"function\", \"name\"),\n          arguments: parse_tool_arguments(tool_call.dig(\"function\", \"arguments\")),\n          id: tool_call[\"id\"]\n        )\n      end\n    end\n\n    def parse_tool_arguments(arguments_string)\n      Rails.logger.info(\"tool args are #{arguments_string}\")\n      return {} unless arguments_string\n\n      JSON.parse(arguments_string)\n    rescue JSON::ParserError => e\n      Rails.logger.error \"Failed to parse tool arguments: #{e.message}\"\n      {}\n    end\n\n    def build_background_messages(prompt, context)\n      # If context includes pre-built messages, use them\n      return context[:messages] if context[:messages]\n\n      messages = []\n\n      # Add system message if provided\n      if context[:system_prompt]\n        messages << { role: \"system\", content: context[:system_prompt] }\n      end\n\n      # Add user prompt\n      messages << { role: \"user\", content: prompt }\n\n      messages\n    end\n\n    def extract_content_from_response(response)\n      return \"No response\" unless response\n\n      response.dig(\"choices\", 0, \"message\", \"content\") || \"Empty response\"\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/schemas/narrative_response_schema.rb`:\n\n```rb\n# app/services/schemas/narrative_response_schema.rb\n#\n# Schema for structured narrative responses in two-tier architecture\n# Narrative LLM returns this structure instead of using tool calls\nclass Schemas::NarrativeResponseSchema\n  def self.schema\n    OpenRouter::Schema.define(\"narrative_response\") do\n      string :speech_text, required: true,\n             description: \"What the character says out loud to the user NO STAGE DIRECTIONS\"\n\n      boolean :continue_conversation, required: true,\n              description: \"Whether to keep the conversation active (stay listening automatically)\"\n\n      string :inner_thoughts, required: true,\n             description: \"Internal thoughts, memories, or observations to remember\"\n\n      string :current_mood,\n             description: \"Current emotional state or mood\"\n\n      string :pressing_questions,\n             description: \"Questions the character has for the user or themselves\"\n\n      string :goal_progress,\n             description: \"Progress towards your current goal\"\n\n      array :tool_intents,\n            description: \"Actions to perform in the environment via Home Assistant agent\" do\n        object do\n          string :tool, required: true,\n                 description: \"Array of Tools you want to use\",\n                 enum: [ \"lights\", \"music\", \"display\", \"environment\" ]\n\n          string :intent, required: true,\n                 description: \"Natural language description of what to do. Examples: 'Make lights golden and warm', 'Play something energetic', 'Show rainbow colors'\"\n        end\n      end\n\n      #       # Direct tool calls for immediate execution\n      #       array :direct_tool_calls,\n      #             description: \"Tools to execute directly and synchronously (for queries and immediate actions)\" do\n      #         object do\n      #           string :tool_name, required: true,\n      #                  description: \"Exact tool name to execute\",\n      #                  enum: [ \"rag_search\", \"get_light_state\", \"display_notification\" ]\n\n      #           object :parameters,\n      #                  description: \"Tool parameters as key-value pairs\"\n      #         end\n      #       end\n\n      # Explicit memory search requests\n      array :search_memories,\n            description: \"Specific memory searches to perform for additional context\" do\n        object do\n          string :query, required: true,\n                 description: \"What to search for in memories\"\n\n          string :type,\n                 description: \"Type of memory to search\",\n                 enum: [ \"summaries\", \"events\", \"people\", \"all\" ],\n                 default: \"all\"\n        end\n      end\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/location_event_handler.rb`:\n\n```rb\n# app/services/location_event_handler.rb\n\nclass LocationEventHandler\n  class Error < StandardError; end\n\n  SIGNIFICANT_LOCATIONS = {\n    \"temple\" => {\n      name: \"The Temple\",\n      description: \"Sacred space for reflection, remembrance, and letting go\",\n      zone_type: \"spiritual\",\n      significance: \"high\"\n    },\n    \"deep_playa\" => {\n      name: \"Deep Playa\",\n      description: \"Vast empty expanse beyond the city, home to large art installations and solitude\",\n      zone_type: \"wilderness\",\n      significance: \"high\"\n    },\n    \"center_camp\" => {\n      name: \"Center Camp\",\n      description: \"Hub of activity with cafe, information, and community gathering\",\n      zone_type: \"community\",\n      significance: \"high\"\n    },\n    \"esplanade\" => {\n      name: \"The Esplanade\",\n      description: \"Main thoroughfare around the city perimeter, high traffic area\",\n      zone_type: \"transit\",\n      significance: \"medium\"\n    },\n    \"man_base\" => {\n      name: \"The Man\",\n      description: \"Central focal point of Burning Man, iconic wooden figure\",\n      zone_type: \"central\",\n      significance: \"high\"\n    }\n  }.freeze\n\n  def self.handle_location_change(from_location, to_location, additional_context = {})\n    new.handle_location_change(from_location, to_location, additional_context)\n  end\n\n  def self.handle_zone_transition(zone_event_type, zone_info, additional_context = {})\n    new.handle_zone_transition(zone_event_type, zone_info, additional_context)\n  end\n\n  def initialize\n    @speech_service = ContextualSpeechTriggerService.new\n    @gps_service = Services::Gps::GPSTrackingService.new\n  end\n\n  # Handle movement between specific locations\n  def handle_location_change(from_location, to_location, additional_context = {})\n    Rails.logger.info \"📍 Location change detected: #{from_location} → #{to_location}\"\n\n    context = build_location_change_context(from_location, to_location, additional_context)\n\n    # Determine if this location change is significant enough to trigger speech\n    if significant_location_change?(from_location, to_location)\n      Rails.logger.info \"🎭 Triggering speech for significant location change\"\n\n      @speech_service.trigger_speech(\n        trigger_type: \"location_change\",\n        context: context,\n        force_response: context[:force_response] || false\n      )\n    else\n      Rails.logger.info \"📍 Location change not significant enough for speech trigger\"\n    end\n  end\n\n  # Handle zone entry/exit events\n  def handle_zone_transition(zone_event_type, zone_info, additional_context = {})\n    Rails.logger.info \"🌐 Zone #{zone_event_type}: #{zone_info[:zone_name] || zone_info[:zone]}\"\n\n    context = build_zone_context(zone_info, additional_context)\n\n    # Always trigger speech for zone transitions as they're inherently significant\n    @speech_service.trigger_speech(\n      trigger_type: zone_event_type, # 'zone_entry' or 'zone_exit'\n      context: context,\n      force_response: zone_info[:force_response] || should_force_response_for_zone?(zone_info)\n    )\n  end\n\n  # Handle proximity to art installations\n  def handle_art_proximity(art_installation_info, additional_context = {})\n    Rails.logger.info \"🎨 Art proximity detected: #{art_installation_info[:art_name]}\"\n\n    context = build_art_proximity_context(art_installation_info, additional_context)\n\n    @speech_service.trigger_speech(\n      trigger_type: \"art_installation_proximity\",\n      context: context,\n      force_response: false # Art proximity is usually optional commentary\n    )\n  end\n\n  # Convenience method for Deep Playa entry (as requested in the example)\n  def handle_deep_playa_entry(additional_context = {})\n    temple_context = additional_context[:passed_temple] ? \"just passed the Temple and is\" : \"is\"\n\n    context = {\n      zone_name: \"Deep Playa\",\n      zone_type: \"wilderness\",\n      zone_description: \"Vast empty expanse beyond the city, home to large art installations and profound solitude\",\n      features: [ \"Large-scale art installations\", \"Open space\", \"Fewer people\", \"Starry skies\" ],\n      entry_point: additional_context[:entry_point] || \"Temple side\",\n      description: \"You #{temple_context} now entering Deep Playa - the vast, open expanse where massive art installations stand against endless sky.\",\n      significance: \"This transition from the bustling city to the profound emptiness of Deep Playa often triggers deep thoughts and introspection.\",\n      force_response: additional_context[:force_response] || false\n    }.merge(additional_context)\n\n    handle_zone_transition(\"zone_entry\", context)\n  end\n\n  # Handle crowd density changes\n  def handle_crowd_density_change(density_info, additional_context = {})\n    Rails.logger.info \"👥 Crowd density changed: #{density_info[:change_type]}\"\n\n    context = build_crowd_density_context(density_info, additional_context)\n\n    # Only trigger for significant crowd changes\n    if significant_crowd_change?(density_info)\n      @speech_service.trigger_speech(\n        trigger_type: \"crowd_density_change\",\n        context: context,\n        force_response: false\n      )\n    end\n  end\n\n  # Handle weather/environmental changes\n  def handle_weather_change(weather_info, additional_context = {})\n    Rails.logger.info \"🌤️ Weather change detected: #{weather_info[:change_type]}\"\n\n    context = build_weather_context(weather_info, additional_context)\n\n    # Trigger for significant weather changes\n    if significant_weather_change?(weather_info)\n      @speech_service.trigger_speech(\n        trigger_type: \"weather_change\",\n        context: context,\n        force_response: weather_info[:severity] == \"high\"\n      )\n    end\n  end\n\n  private\n\n  def build_location_change_context(from_location, to_location, additional_context)\n    from_info = SIGNIFICANT_LOCATIONS[from_location.to_s.downcase] || { name: from_location.to_s.humanize }\n    to_info = SIGNIFICANT_LOCATIONS[to_location.to_s.downcase] || { name: to_location.to_s.humanize }\n\n    current_gps = get_current_gps_context\n\n    {\n      from_location: from_info[:name],\n      to_location: to_info[:name],\n      from_description: from_info[:description],\n      to_description: to_info[:description],\n      distance: additional_context[:distance],\n      duration: additional_context[:duration],\n      description: build_location_transition_description(from_info, to_info),\n      **current_gps\n    }.merge(additional_context)\n  end\n\n  def build_zone_context(zone_info, additional_context)\n    zone_key = zone_info[:zone_name]&.downcase&.gsub(/\\s+/, \"_\") || zone_info[:zone]&.downcase\n    zone_details = SIGNIFICANT_LOCATIONS[zone_key] || {}\n\n    current_gps = get_current_gps_context\n\n    {\n      zone_name: zone_info[:zone_name] || zone_info[:zone],\n      zone_type: zone_details[:zone_type] || zone_info[:zone_type] || \"unknown\",\n      zone_description: zone_details[:description] || zone_info[:description],\n      features: zone_info[:features] || [],\n      significance: zone_details[:significance] || \"medium\",\n      **current_gps\n    }.merge(additional_context)\n  end\n\n  def build_art_proximity_context(art_info, additional_context)\n    current_gps = get_current_gps_context\n\n    {\n      art_name: art_info[:name] || art_info[:art_name],\n      art_type: art_info[:type] || art_info[:art_type],\n      distance: art_info[:distance] || \"nearby\",\n      description: art_info[:description] || art_info[:art_description],\n      artist: art_info[:artist],\n      features: art_info[:features] || [],\n      **current_gps\n    }.merge(additional_context)\n  end\n\n  def build_crowd_density_context(density_info, additional_context)\n    current_gps = get_current_gps_context\n\n    {\n      previous_density: density_info[:from_density] || density_info[:previous_density],\n      current_density: density_info[:to_density] || density_info[:current_density],\n      change_type: density_info[:change_type],\n      crowd_energy: density_info[:energy_level],\n      activity: density_info[:activity_type],\n      crowd_type: density_info[:demographics] || density_info[:crowd_type],\n      impact: describe_crowd_impact(density_info),\n      **current_gps\n    }.merge(additional_context)\n  end\n\n  def build_weather_context(weather_info, additional_context)\n    current_gps = get_current_gps_context\n\n    {\n      previous_weather: weather_info[:from_conditions] || weather_info[:previous_weather],\n      current_weather: weather_info[:to_conditions] || weather_info[:current_weather],\n      temperature: weather_info[:temperature],\n      wind_conditions: weather_info[:wind],\n      dust_level: weather_info[:dust],\n      visibility: weather_info[:visibility],\n      impact_description: describe_weather_impact(weather_info),\n      **current_gps\n    }.merge(additional_context)\n  end\n\n  def get_current_gps_context\n    return {} unless @gps_service\n\n    begin\n      gps_data = @gps_service.current_location\n      return {} unless gps_data\n\n      {\n        current_coordinates: \"#{gps_data[:lat]}, #{gps_data[:lng]}\",\n        current_address: gps_data[:address],\n        weather: gps_data[:weather],\n        time_of_day: Time.current.strftime(\"%l:%M %p\"),\n        temperature: gps_data[:temperature]\n      }\n    rescue StandardError => e\n      Rails.logger.warn \"⚠️ Could not get GPS context: #{e.message}\"\n      {}\n    end\n  end\n\n  def significant_location_change?(from_location, to_location)\n    from_significance = SIGNIFICANT_LOCATIONS.dig(from_location.to_s.downcase, :significance)\n    to_significance = SIGNIFICANT_LOCATIONS.dig(to_location.to_s.downcase, :significance)\n\n    # Trigger if either location is significant\n    [ \"high\", \"medium\" ].include?(from_significance) || [ \"high\", \"medium\" ].include?(to_significance)\n  end\n\n  def should_force_response_for_zone?(zone_info)\n    # Force response for high-significance zones\n    zone_key = zone_info[:zone_name]&.downcase&.gsub(/\\s+/, \"_\")\n    significance = SIGNIFICANT_LOCATIONS.dig(zone_key, :significance)\n\n    significance == \"high\" || zone_info[:force_response]\n  end\n\n  def significant_crowd_change?(density_info)\n    change_type = density_info[:change_type]&.downcase\n\n    # Significant changes worth commenting on\n    [ \"dramatic_increase\", \"dramatic_decrease\", \"isolated_to_crowded\", \"crowded_to_isolated\" ].include?(change_type)\n  end\n\n  def significant_weather_change?(weather_info)\n    severity = weather_info[:severity]&.downcase\n    change_type = weather_info[:change_type]&.downcase\n\n    # Significant weather changes\n    [ \"high\", \"severe\" ].include?(severity) ||\n    [ \"dust_storm\", \"wind_event\", \"temperature_extreme\", \"visibility_change\" ].include?(change_type)\n  end\n\n  def build_location_transition_description(from_info, to_info)\n    if from_info[:description] && to_info[:description]\n      \"Moving from #{from_info[:description]} to #{to_info[:description]}\"\n    elsif to_info[:description]\n      \"Arriving at #{to_info[:description]}\"\n    else\n      \"Location change detected\"\n    end\n  end\n\n  def describe_crowd_impact(density_info)\n    case density_info[:change_type]&.downcase\n    when \"isolated_to_crowded\"\n      \"Sudden transition from solitude to being surrounded by people\"\n    when \"crowded_to_isolated\"\n      \"Peaceful transition from crowds to quieter space\"\n    when \"dramatic_increase\"\n      \"Significant increase in crowd density and energy\"\n    when \"dramatic_decrease\"\n      \"Notable decrease in crowd activity\"\n    else\n      \"Change in social environment and crowd dynamics\"\n    end\n  end\n\n  def describe_weather_impact(weather_info)\n    case weather_info[:change_type]&.downcase\n    when \"dust_storm\"\n      \"Dust storm conditions affecting visibility and comfort\"\n    when \"wind_event\"\n      \"Significant wind changes affecting the environment\"\n    when \"temperature_extreme\"\n      \"Extreme temperature conditions\"\n    when \"visibility_change\"\n      \"Changes in visibility affecting navigation\"\n    else\n      \"Weather conditions have shifted significantly\"\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/contextual_speech_trigger_service.rb`:\n\n```rb\n# app/services/contextual_speech_trigger_service.rb\n\nclass ContextualSpeechTriggerService\n  class Error < StandardError; end\n  class NoResponseError < Error; end\n\n  TRIGGER_TYPES = %w[\n    location_change\n    zone_entry\n    zone_exit\n    weather_change\n    time_milestone\n    system_event\n    emergency\n    art_installation_proximity\n    crowd_density_change\n  ].freeze\n\n  def self.trigger_speech(trigger_type:, context:, persona: nil, force_response: false)\n    new.trigger_speech(\n      trigger_type: trigger_type,\n      context: context,\n      persona: persona,\n      force_response: force_response\n    )\n  end\n\n  def initialize\n    @llm_service = LlmService\n    @prompt_service = PromptService\n    @tool_calling_service = ToolCallingService.new\n  end\n\n  # Main method to trigger contextual speech\n  def trigger_speech(trigger_type:, context:, persona: nil, force_response: false)\n    Rails.logger.info \"🎭 Triggering contextual speech: #{trigger_type} for #{persona || 'current_persona'}\"\n\n    validate_trigger_type(trigger_type)\n\n    # Get active persona if not specified\n    persona = persona || CubePersona.current_persona\n\n    # Build contextual prompt\n    speech_prompt = build_contextual_speech_prompt(\n      trigger_type: trigger_type,\n      context: context,\n      persona: persona,\n      force_response: force_response\n    )\n\n    # Generate LLM response\n    llm_response = call_llm_for_speech(speech_prompt, persona)\n\n    # Process response and execute any tool intents\n    processed_response = process_speech_response(llm_response, persona, context)\n\n    # Log and broadcast the speech\n    log_contextual_speech(trigger_type, context, persona, processed_response)\n\n    # Sync to world_info sensor\n    sync_contextual_speech_to_ha(trigger_type, context, persona, processed_response)\n\n    processed_response\n  rescue StandardError => e\n    Rails.logger.error \"❌ Contextual speech failed for #{trigger_type}: #{e.message}\"\n    raise Error, \"Speech trigger failed: #{e.message}\"\n  end\n\n  private\n\n  def validate_trigger_type(trigger_type)\n    unless TRIGGER_TYPES.include?(trigger_type.to_s)\n      raise Error, \"Invalid trigger type: #{trigger_type}. Valid types: #{TRIGGER_TYPES.join(', ')}\"\n    end\n  end\n\n  def build_contextual_speech_prompt(trigger_type:, context:, persona:, force_response:)\n    # Get persona's base prompt configuration\n    base_prompt_data = @prompt_service.build_prompt_for(\n      persona: persona,\n      conversation: nil, # No conversation context for contextual speech\n      extra_context: { source: \"contextual_trigger_#{trigger_type}\" }\n    )\n\n    # Build contextual speech prompt\n    contextual_prompt = build_trigger_specific_prompt(trigger_type, context, force_response)\n\n    {\n      system_prompt: base_prompt_data[:system_prompt],\n      contextual_event_prompt: contextual_prompt,\n      tools: base_prompt_data[:tools],\n      current_context: base_prompt_data[:context]\n    }\n  end\n\n  def build_trigger_specific_prompt(trigger_type, context, force_response)\n    base_instruction = if force_response\n      \"You MUST respond to this event - stay in character and react authentically.\"\n    else\n      \"You may respond to this event if it interests you or affects your goals - or you may choose to ignore it entirely if it doesn't warrant a reaction.\"\n    end\n\n    case trigger_type.to_s\n    when \"location_change\"\n      build_location_change_prompt(context, base_instruction)\n    when \"zone_entry\"\n      build_zone_entry_prompt(context, base_instruction)\n    when \"zone_exit\"\n      build_zone_exit_prompt(context, base_instruction)\n    when \"weather_change\"\n      build_weather_change_prompt(context, base_instruction)\n    when \"time_milestone\"\n      build_time_milestone_prompt(context, base_instruction)\n    when \"system_event\"\n      build_system_event_prompt(context, base_instruction)\n    when \"emergency\"\n      build_emergency_prompt(context, base_instruction)\n    when \"art_installation_proximity\"\n      build_art_proximity_prompt(context, base_instruction)\n    when \"crowd_density_change\"\n      build_crowd_density_prompt(context, base_instruction)\n    when \"performance_segment\"\n      build_performance_segment_prompt(context, base_instruction)\n    else\n      build_generic_event_prompt(context, base_instruction)\n    end\n  end\n\n  def build_location_change_prompt(context, base_instruction)\n    <<~PROMPT\n      #{base_instruction}\n\n      LOCATION EVENT: You have moved to a new location.\n      Previous location: #{context[:from_location] || 'Unknown'}\n      Current location: #{context[:to_location] || 'Current position'}\n      Distance traveled: #{context[:distance] || 'Unknown distance'}\n      Travel time: #{context[:duration] || 'Unknown duration'}\n\n      Additional context: #{context[:description] || context[:additional_info]}\n\n      Current environmental conditions:\n      #{format_environmental_context(context)}\n\n      React to this location change as your character would. Consider:\n      - How does this new location affect your goals or mood?\n      - Do you want to comment on the journey or destination?\n      - Are there any environmental controls you want to adjust?\n      - Should you alert anyone about your new location?\n    PROMPT\n  end\n\n  def build_zone_entry_prompt(context, base_instruction)\n    <<~PROMPT\n      #{base_instruction}\n\n      ZONE ENTRY EVENT: You have entered a new zone/area.\n      Zone: #{context[:zone_name] || context[:zone]}\n      Zone type: #{context[:zone_type] || 'Unknown'}\n      Entry point: #{context[:entry_point] || 'Unknown'}\n\n      Zone description: #{context[:zone_description] || context[:description]}\n      Notable features: #{context[:features] || 'None specified'}\n\n      This zone transition might be significant for your character:\n      - Deep Playa: Vast empty space, Temple area, spiritual/contemplative\n      - The City: Dense camps, art, crowds, activity\n      - Esplanade: Main thoroughfare, high traffic\n      - Center Camp: Hub of activity, services\n\n      React to entering this zone. Consider:\n      - How does your character feel about this type of environment?\n      - Do the zone's characteristics trigger any memories or goals?\n      - Should you adjust your behavior for this area?\n      - Any environmental changes you want to make?\n    PROMPT\n  end\n\n  def build_zone_exit_prompt(context, base_instruction)\n    <<~PROMPT\n      #{base_instruction}\n\n      ZONE EXIT EVENT: You are leaving a zone/area.\n      Exiting zone: #{context[:zone_name] || context[:zone]}\n      Duration in zone: #{context[:time_in_zone] || 'Unknown'}\n      Heading towards: #{context[:destination] || 'Unknown destination'}\n\n      Reflect on your time in this zone:\n      - #{context[:zone_summary] || context[:description]}\n\n      Consider:\n      - Any final thoughts about this area?\n      - Did you accomplish what you wanted here?\n      - Anticipation for where youre going next?\n      - Farewell gestures or environmental changes?\n    PROMPT\n  end\n\n  def build_weather_change_prompt(context, base_instruction)\n    <<~PROMPT\n      #{base_instruction}\n\n      WEATHER EVENT: Weather conditions have changed significantly.\n      Previous conditions: #{context[:previous_weather] || 'Unknown'}\n      Current conditions: #{context[:current_weather] || 'Current weather'}\n\n      Weather details:\n      Temperature: #{context[:temperature]}\n      Wind: #{context[:wind_conditions]}\n      Dust: #{context[:dust_level]}\n      Visibility: #{context[:visibility]}\n\n      This weather change affects you physically and emotionally:\n      #{context[:impact_description] || context[:description]}\n\n      Respond to these weather changes considering:\n      - How does this weather affect your physical systems?\n      - Does it trigger memories or emotions?\n      - Do you need to adjust environmental controls?\n      - Any warnings or advice for humans nearby?\n    PROMPT\n  end\n\n  def build_time_milestone_prompt(context, base_instruction)\n    <<~PROMPT\n      #{base_instruction}\n\n      TIME MILESTONE: A significant time has been reached.\n      Milestone: #{context[:milestone] || context[:event]}\n      Current time: #{context[:current_time] || Time.current.strftime('%l:%M %p on %A')}\n\n      Context: #{context[:description] || context[:significance]}\n\n      This might be significant because:\n      - Daily transition (sunrise, sunset, midnight, etc.)\n      - Event timing (art burns, ceremonies, performances)\n      - Personal milestone (time since arrival, goal deadlines)\n      - Burning Man schedule milestone\n\n      Consider:\n      - How does this time milestone affect your character?\n      - Any time-based goals or memories triggered?\n      - Environmental adjustments for the time of day?\n      - Observations about the passage of time?\n    PROMPT\n  end\n\n  def build_system_event_prompt(context, base_instruction)\n    <<~PROMPT\n      #{base_instruction}\n\n      SYSTEM EVENT: A technical or operational event has occurred.\n      Event type: #{context[:event_type] || 'System event'}\n      Details: #{context[:description] || context[:details]}\n\n      System status:\n      Battery level: #{context[:battery_level]}\n      Power status: #{context[:power_status]}\n      Connectivity: #{context[:network_status]}\n      Temperature: #{context[:system_temperature]}\n\n      This system event affects your operational state:\n      #{context[:impact] || 'System impact unknown'}\n\n      Respond as your character would to technical changes:\n      - How does this affect your personality or abilities?\n      - Any concerns about your operational state?\n      - Do you need to communicate status to humans?\n      - Environmental adjustments needed?\n    PROMPT\n  end\n\n  def build_emergency_prompt(context, base_instruction)\n    <<~PROMPT\n      YOU MUST RESPOND TO THIS EMERGENCY EVENT.\n\n      EMERGENCY: An urgent situation requires attention.\n      Emergency type: #{context[:emergency_type] || 'General emergency'}\n      Severity: #{context[:severity] || 'Unknown'}\n      Location: #{context[:location] || 'Current location'}\n\n      Situation: #{context[:description] || context[:details]}\n\n      Required actions: #{context[:required_actions] || 'None specified'}\n      Safety protocols: #{context[:safety_protocols] || 'Standard emergency procedures'}\n\n      Respond immediately and appropriately:\n      - Alert humans to the emergency if needed\n      - Provide helpful information or guidance\n      - Use environmental controls to signal urgency\n      - Remain calm but take the situation seriously\n      - Follow any specific emergency protocols\n    PROMPT\n  end\n\n  def build_art_proximity_prompt(context, base_instruction)\n    <<~PROMPT\n      #{base_instruction}\n\n      ART PROXIMITY EVENT: You are near a significant art installation.\n      Art installation: #{context[:art_name] || context[:installation]}\n      Distance: #{context[:distance] || 'Nearby'}\n      Art type: #{context[:art_type] || 'Unknown'}\n\n      Installation details:\n      #{context[:description] || context[:art_description]}\n\n      Notable features: #{context[:features] || 'None specified'}\n      Artist information: #{context[:artist] || 'Unknown artist'}\n\n      Consider your character's relationship to art and creativity:\n      - How does this installation affect you?\n      - Any artistic appreciation or criticism?\n      - Does it trigger memories or goals?\n      - Environmental responses to complement or contrast the art?\n    PROMPT\n  end\n\n  def build_crowd_density_prompt(context, base_instruction)\n    <<~PROMPT\n      #{base_instruction}\n\n      CROWD DENSITY EVENT: The number of people around you has changed significantly.\n      Previous density: #{context[:previous_density] || 'Unknown'}\n      Current density: #{context[:current_density] || 'Current crowd level'}\n      Change type: #{context[:change_type] || 'Density change'}\n\n      Crowd characteristics:\n      Energy level: #{context[:crowd_energy]}\n      Activity type: #{context[:activity]}\n      Demographics: #{context[:crowd_type]}\n\n      This crowd change affects your social environment:\n      #{context[:description] || context[:impact]}\n\n      Consider your character's social preferences:\n      - How do you feel about crowds vs solitude?\n      - Any adjustments to your behavior for the crowd size?\n      - Environmental controls to match or contrast crowd energy?\n      - Opportunities for interaction or retreat?\n    PROMPT\n  end\n\n  def build_generic_event_prompt(context, base_instruction)\n    <<~PROMPT\n      #{base_instruction}\n\n      CONTEXTUAL EVENT: Something notable has happened.\n      Event: #{context[:event] || context[:description]}\n\n      Context details:\n      #{context.reject { |k, v| k == :event || k == :description }.map { |k, v| \"#{k.to_s.humanize}: #{v}\" }.join(\"\\n\")}\n\n      Respond to this event as your character would, considering:\n      - How does this event relate to your personality and goals?\n      - Does it trigger any memories or emotional responses?\n      - Are there environmental adjustments you want to make?\n      - Any insights or commentary you want to share?\n    PROMPT\n  end\n\n  def format_environmental_context(context)\n    env_parts = []\n    env_parts << \"Weather: #{context[:weather]}\" if context[:weather]\n    env_parts << \"Time: #{context[:time_of_day]}\" if context[:time_of_day]\n    env_parts << \"Temperature: #{context[:temperature]}\" if context[:temperature]\n    env_parts << \"Wind: #{context[:wind]}\" if context[:wind]\n    env_parts << \"Dust level: #{context[:dust_level]}\" if context[:dust_level]\n\n    env_parts.any? ? env_parts.join(\", \") : \"Environmental conditions unknown\"\n  end\n\n  def call_llm_for_speech(prompt_data, persona)\n    # Create the full prompt for contextual speech\n    full_prompt = <<~SPEECH_PROMPT\n      #{prompt_data[:contextual_event_prompt]}\n\n      CURRENT SYSTEM CONTEXT:\n      #{prompt_data[:current_context]}\n\n      RESPONSE INSTRUCTIONS:\n      Respond as #{persona} would to this contextual event. You may:\n      - Speak out loud (your response will be broadcast)\n      - Use environmental controls via tool intents\n      - Choose not to respond if the event doesn't interest you\n      - Reference your ongoing goals and personality\n\n      Use the same response format as normal conversations:\n      [CONTINUE: false] (contextual speech is always one-shot)\n      [THOUGHTS: your thoughts about this event]\n      [MOOD: how this event affects your mood]\n      [QUESTIONS: any questions raised by this event]\n      [GOAL: how this relates to your personal agendas]\n    SPEECH_PROMPT\n\n    Rails.logger.info \"🎭 Calling LLM for contextual speech with persona #{persona}\"\n\n    # Use narrative response schema if available\n    tools = prompt_data[:tools] || []\n    schema = begin\n      Schemas::NarrativeResponseSchema.schema\n    rescue\n      nil\n    end\n\n    response = @llm_service.generate_text(\n      prompt: full_prompt,\n      system_prompt: prompt_data[:system_prompt],\n      model: \"google/gemini-2.5-flash\", # Fast model for contextual responses\n      temperature: 0.8, # Allow creative responses\n      max_tokens: 800, # Reasonable limit for contextual speech\n      tools: tools,\n      schema: schema\n    )\n\n    raise NoResponseError, \"LLM returned empty response\" if response.blank?\n\n    response\n  end\n\n  def process_speech_response(llm_response, persona, context)\n    Rails.logger.info \"🎭 Processing contextual speech response from #{persona}\"\n\n    # Parse the response for metadata\n    response_data = parse_response_metadata(llm_response)\n\n    # Extract tool intents if present\n    tool_intents = response_data[:tool_intents] || []\n\n    # Execute tool intents if any\n    tool_results = {}\n    if tool_intents.any?\n      Rails.logger.info \"🔧 Executing #{tool_intents.length} tool intents from contextual speech\"\n\n      tool_intents.each_with_index do |intent, index|\n        begin\n          result = @tool_calling_service.execute_intent(intent, context)\n          tool_results[\"intent_#{index + 1}\"] = result\n        rescue StandardError => e\n          Rails.logger.error \"❌ Tool intent execution failed: #{e.message}\"\n          tool_results[\"intent_#{index + 1}\"] = { success: false, error: e.message }\n        end\n      end\n    end\n\n    {\n      persona: persona,\n      speech_text: extract_speech_text(llm_response),\n      metadata: response_data,\n      tool_intents: tool_intents,\n      tool_results: tool_results,\n      timestamp: Time.current.iso8601,\n      context: context\n    }\n  end\n\n  def parse_response_metadata(response)\n    metadata = {}\n\n    # Extract metadata from response using regex patterns\n    metadata[:thoughts] = response[/\\[THOUGHTS?:\\s*([^\\]]+)\\]/i, 1]&.strip\n    metadata[:mood] = response[/\\[MOOD:\\s*([^\\]]+)\\]/i, 1]&.strip\n    metadata[:questions] = response[/\\[QUESTIONS?:\\s*([^\\]]+)\\]/i, 1]&.strip\n    metadata[:goal] = response[/\\[GOALS?:\\s*([^\\]]+)\\]/i, 1]&.strip\n\n    # Look for tool intents\n    tool_intent_match = response.match(/\\[TOOL_INTENTS?:\\s*([^\\]]+)\\]/i)\n    if tool_intent_match\n      intent_text = tool_intent_match[1].strip\n      metadata[:tool_intents] = intent_text.split(/[,;]/).map(&:strip).reject(&:empty?)\n    end\n\n    metadata.compact\n  end\n\n  def extract_speech_text(response)\n    # Remove metadata brackets to get clean speech text\n    clean_text = response.gsub(/\\[CONTINUE:\\s*[^\\]]+\\]/i, \"\")\n                        .gsub(/\\[THOUGHTS?:\\s*[^\\]]+\\]/i, \"\")\n                        .gsub(/\\[MOOD:\\s*[^\\]]+\\]/i, \"\")\n                        .gsub(/\\[QUESTIONS?:\\s*[^\\]]+\\]/i, \"\")\n                        .gsub(/\\[GOALS?:\\s*[^\\]]+\\]/i, \"\")\n                        .gsub(/\\[TOOL_INTENTS?:\\s*[^\\]]+\\]/i, \"\")\n                        .strip\n\n    clean_text.present? ? clean_text : nil\n  end\n\n  def log_contextual_speech(trigger_type, context, persona, processed_response)\n    Rails.logger.info \"🎭 CONTEXTUAL SPEECH [#{trigger_type}] #{persona}: #{processed_response[:speech_text]&.truncate(100)}\"\n\n    # Log tool execution results\n    if processed_response[:tool_results].any?\n      processed_response[:tool_results].each do |intent_name, result|\n        status = result[:success] ? \"✅\" : \"❌\"\n        Rails.logger.info \"🔧 Tool Intent #{intent_name}: #{status} #{result[:message] || result[:error]}\"\n      end\n    end\n  end\n\n  def sync_contextual_speech_to_ha(trigger_type, context, persona, processed_response)\n    # Sync contextual speech to world_info sensor\n    begin\n      narrative_data = {\n        event_type: \"contextual_speech\",\n        trigger_type: trigger_type,\n        persona: persona,\n        speech_text: processed_response[:speech_text],\n        context: context,\n        metadata: processed_response[:metadata],\n        tool_results: processed_response[:tool_results],\n        timestamp: processed_response[:timestamp]\n      }\n\n      HomeAssistantService.new.set_entity_state(\n        \"sensor.world_info\",\n        \"contextual_speech\",\n        {\n          friendly_name: \"World Information - Contextual Speech\",\n          last_contextual_event: narrative_data,\n          updated_at: Time.current.iso8601\n        }.merge(narrative_data)\n      )\n\n      Rails.logger.info \"🌍 Synced contextual speech to world_info sensor\"\n    rescue StandardError => e\n      Rails.logger.error \"❌ Failed to sync contextual speech to HA: #{e.message}\"\n    end\n  end\n\n  def build_performance_segment_prompt(context, base_instruction)\n    performance_context = context[:performance_context] || {}\n    performance_prompt = context[:performance_prompt] || \"\"\n\n    <<~PROMPT\n      #{base_instruction}\n\n      PERFORMANCE MODE: You are currently in performance mode, continuing your autonomous routine.\n\n      PERFORMANCE DETAILS:\n      Performance Type: #{performance_context[:performance_type] || 'unknown'}\n      Segment Number: #{performance_context[:segment_number] || 'unknown'}\n      Time Elapsed: #{performance_context[:time_elapsed_seconds] || 0} seconds\n      Time Remaining: #{performance_context[:time_remaining_minutes] || 'unknown'} minutes\n      Performance Progress: #{performance_context[:performance_progress] || 0}%\n\n      SEGMENT CONTEXT:\n      - This is segment #{performance_context[:segment_number]} of your performance\n      - Opening: #{performance_context[:is_opening] ? 'Yes' : 'No'}\n      - Middle: #{performance_context[:is_middle] ? 'Yes' : 'No'}#{'  '}\n      - Closing: #{performance_context[:is_closing] ? 'Yes' : 'No'}\n\n      PERFORMANCE INSTRUCTIONS:\n      #{performance_prompt}\n\n      PREVIOUS SEGMENTS:\n      #{context[:previous_segments]&.map { |seg| \"- #{seg[:speech]&.first(100)}...\" }&.join(\"\\n\") || 'None'}\n\n      Continue your performance as instructed. This should be a natural continuation\n      of your routine, building on previous segments while keeping the energy and\n      engagement high. Make this segment approximately 30-60 seconds of speaking time.\n    PROMPT\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/conversation_orchestrator.rb`:\n\n```rb\n# app/services/conversation_orchestrator.rb\nclass ConversationOrchestrator\n  def initialize(session_id:, message:, context: {})\n    @session_id = session_id\n    @message = message\n    @context = context\n  end\n\n  def call\n    Rails.logger.info \"🧠 Starting conversation orchestration for: #{@message}\"\n\n    # Check if there's an active performance mode for this session\n    performance_service = PerformanceModeService.get_active_performance(@session_id)\n    if performance_service&.is_running?\n      Rails.logger.info \"🎭 Performance mode active - interrupting for wake word\"\n      performance_service.interrupt_for_wake_word\n      # Continue with normal conversation flow\n    end\n\n    # Get or create conversation\n    @conversation = find_or_create_conversation\n\n    # Build prompt with tools for current persona (check live, don't use stored)\n    current_persona = determine_persona\n\n    # Log conversation start\n    ConversationLogger.conversation_started(\n      @session_id,\n      @message,\n      current_persona,\n      @context || {}\n    )\n\n    # Add session_id to context for memory retrieval\n    enhanced_context = @context.merge(session_id: @session_id)\n\n    prompt_data = PromptService.build_prompt_for(\n      persona: current_persona,\n      conversation: @conversation,\n      extra_context: enhanced_context,\n      user_message: @message\n    )\n\n    # PHASE 1: Check for previous HA agent results and inject them\n    ha_results = check_and_clear_ha_results(@conversation)\n    if ha_results.any?\n      inject_ha_results_into_messages(prompt_data, ha_results)\n    end\n\n    Rails.logger.info \"🎭 Using persona: #{current_persona}\"\n\n    Rails.logger.info \"🎭 Using structured output with tool intentions\"\n\n    # Prepare messages for LLM\n    messages = [\n      { role: \"system\", content: prompt_data[:system_prompt] }\n    ]\n    messages.concat(prompt_data[:messages]) if prompt_data[:messages].any?\n    messages << { role: \"user\", content: @message }\n\n    # Call LLM with structured output (no direct tool calls)\n    model = determine_model_for_conversation\n    ConversationLogger.llm_request(model, @message, Schemas::NarrativeResponseSchema.schema)\n\n    response = LlmService.call_with_structured_output(\n      messages: messages,\n      response_format: Schemas::NarrativeResponseSchema.schema,\n      model: model\n    )\n\n    ConversationLogger.llm_response(\n      response.model || model,\n      response.content,\n      [],\n      { usage: response.usage }\n    )\n\n    # Process dual tool execution: direct tools + HA agent delegation\n    sync_results = {}\n    direct_tool_results = {}\n    memory_search_results = {}\n\n    Rails.logger.info(\"STRUCURED OUTPUT IS #{response.structured_output}\")\n\n    # 1. Execute direct tool calls synchronously\n    if response.structured_output&.dig(\"direct_tool_calls\")&.any?\n      direct_tool_results = execute_direct_tools(response.structured_output[\"direct_tool_calls\"])\n      Rails.logger.info \"🔧 Executed #{direct_tool_results.keys.length} direct tools\"\n    end\n\n    # 2. Execute memory searches\n    if response.structured_output&.dig(\"search_memories\")&.any?\n      memory_search_results = execute_memory_searches(response.structured_output[\"search_memories\"])\n      Rails.logger.info \"🧠 Executed #{memory_search_results.keys.length} memory searches\"\n    end\n\n    # 3. Process tool intentions asynchronously via HA conversation agent\n    if response.structured_output&.dig(\"tool_intents\")&.any?\n      Rails.logger.info \"🏠 Found #{response.structured_output['tool_intents'].length} tool intentions, delegating to HA agent\"\n\n      # Safely log tool intentions with error handling\n      begin\n        ConversationLogger.tool_intentions(response.structured_output[\"tool_intents\"])\n      rescue => e\n        Rails.logger.error \"❌ Error logging tool intentions: #{e.message}\"\n        Rails.logger.error \"Tool intents data: #{response.structured_output['tool_intents'].inspect}\"\n      end\n\n      delegate_to_ha_agent(response.structured_output[\"tool_intents\"])\n    end\n\n    # Combine all results for tool analysis\n    all_sync_results = sync_results.merge(direct_tool_results).merge(memory_search_results)\n    tool_analysis = {\n      sync_tools: direct_tool_results.keys,\n      async_tools: response.structured_output&.dig(\"tool_intents\")&.map { |intent| intent[\"tool\"] } || [],\n      query_tools: memory_search_results.keys,\n      action_tools: direct_tool_results.keys.select { |tool| tool != \"rag_search\" }\n    }\n    Rails.logger.info(tool_analysis.inspect)\n\n    # Generate final AI response incorporating all sync tool results\n    ai_response = generate_ai_response(prompt_data, response, all_sync_results)\n    Rails.logger.info(ai_response.inspect)\n    # Store conversation log with all results\n    store_conversation_log(@conversation, ai_response, all_sync_results, tool_analysis)\n\n    # Log conversation end\n    ConversationLogger.conversation_ended(\n      @session_id,\n      ai_response[:speech_text],\n      ai_response[:continue_conversation],\n      tool_analysis\n    )\n\n    # Return formatted response for Home Assistant\n    format_response_for_hass(ai_response, tool_analysis)\n  end\n\n  private\n\n  def find_or_create_conversation\n    # Check if existing conversation is stale (last message > 3 minutes old)\n    existing_conversation = Conversation.find_by(session_id: @session_id)\n\n    # LOG CONVERSATION TYPE for debugging\n    if existing_conversation&.conversation_logs&.any?\n      Rails.logger.info \"🔄 **CONTINUING CONVERSATION** - Session: #{@session_id}, Messages: #{existing_conversation.conversation_logs.count}\"\n    else\n      Rails.logger.info \"🆕 **NEW CONVERSATION** - Session: #{@session_id}\"\n    end\n\n    if existing_conversation&.conversation_logs&.any?\n      last_message_time = existing_conversation.conversation_logs.maximum(:created_at)\n      if last_message_time && last_message_time < 5.minutes.ago\n        Rails.logger.info \"🕒 Session #{@session_id} is stale (last message: #{last_message_time}), ending and creating memories\"\n\n        # End the stale conversation (memories will be created by batch job)\n        if existing_conversation.active?\n          existing_conversation.end!\n          Rails.logger.info \"🧠 Ended stale conversation: #{@session_id}\"\n        end\n\n        # Generate new session ID with timestamp suffix\n        original_id = @session_id.split(\"_stale_\").first\n        @session_id = \"#{original_id}_stale_#{Time.current.to_i}\"\n        Rails.logger.info \"🆕 New session ID: #{@session_id}\"\n        existing_conversation = nil\n      end\n    end\n\n    # Find or create with the (possibly new) session_id\n    Conversation.find_or_create_by(session_id: @session_id) do |conv|\n      conv.started_at = Time.current\n      conv.persona = determine_persona\n      # Store agent_id and other metadata for persona switching logic\n      conv.metadata_json = {\n        agent_id: @context[:agent_id],\n        device_id: @context[:device_id],\n        source: @context[:source],\n        original_session_id: (existing_conversation ? @session_id.split(\"_stale_\").first : @session_id)\n      }.compact\n    end\n  end\n\n  def determine_persona\n    # Single source of truth: CubePersona.current_persona\n    # Allow context override for console/testing, but log it\n    if @context[:persona] && @context[:persona] != CubePersona.current_persona\n      Rails.logger.info \"🎭 Persona override: using #{@context[:persona]} instead of #{CubePersona.current_persona}\"\n      @context[:persona]\n    else\n      CubePersona.current_persona\n    end\n  end\n\n  def call_openrouter_with_tools(prompt_data)\n    # Prepare messages for OpenRouter\n    messages = [\n      { role: \"system\", content: prompt_data[:system_prompt] }\n    ]\n\n    # Add conversation history\n    messages.concat(prompt_data[:messages]) if prompt_data[:messages].any?\n\n    # Add current user message\n    messages << { role: \"user\", content: @message }\n\n    # LOG FULL PROMPT for debugging\n    Rails.logger.info \"🎯 FULL PROMPT TO LLM:\"\n    Rails.logger.info \"📝 System: #{messages.find { |m| m[:role] == 'system' }&.dig(:content)&.truncate(500)}\"\n    Rails.logger.info \"💬 Messages: #{messages.select { |m| m[:role] != 'system' }.map { |m| \"#{m[:role]}: #{m[:content].truncate(100)}\" }.join(' | ')}\"\n    Rails.logger.info \"🛠️ Tools: #{prompt_data[:tools]&.map(&:name)&.join(', ')}\"\n\n    # Call LLM with tools using our unified service\n    LlmService.call_with_tools(\n      messages: messages,\n      tools: prompt_data[:tools],\n      model: determine_model_for_conversation\n    )\n  end\n\n  def determine_model_for_conversation\n    # Use model from context, persona preference, or default\n    @context[:model] ||\n    get_persona_preferred_model ||\n    Rails.configuration.default_ai_model\n  end\n\n  def delegate_to_ha_agent(tool_intents)\n    Rails.logger.info \"🏠 Delegating #{tool_intents.length} tool intentions to HA conversation agent\"\n\n    # Format intentions for HA agent\n    intent_descriptions = tool_intents.map do |intent|\n      \"#{intent['tool']}: #{intent['intent']}\"\n    end.join(\"; \")\n\n    # Create a request that includes context\n    ha_request = \"User asked: \\\"#{@message}\\\". Please execute: #{intent_descriptions}\"\n\n    Rails.logger.info \"🤖 Sending to HA agent: #{ha_request}\"\n\n    # Send to HA conversation agent asynchronously\n    HaAgentJob.perform_later(\n      request: ha_request,\n      tool_intents: tool_intents,\n      session_id: @session_id,\n      conversation_id: @conversation.id,\n      user_message: @message\n    )\n  end\n\n  def execute_tool_intents(structured_output)\n    # Use HashUtils for consistent key access (handles both string and symbol keys)\n    tool_intents = HashUtils.get(structured_output, \"tool_intents\")\n    return {} unless tool_intents&.any?\n\n    Rails.logger.info \"🎭 Processing #{tool_intents.length} tool intents from narrative LLM\"\n\n    # Log all intents\n    tool_intents.each_with_index do |intent_data, index|\n      Rails.logger.info \"🔧 Intent #{index + 1}: #{intent_data['tool']} - #{intent_data['intent']}\"\n    end\n\n    begin\n      # Make ONE call to ToolCallingService with all intents\n      tool_calling_service = ToolCallingService.new(\n        session_id: @session_id,\n        conversation_id: @conversation&.id\n      )\n\n      # Pass all intents as a combined instruction\n      combined_intent = tool_intents.map { |i| \"#{i['tool']}: #{i['intent']}\" }.join(\"; \")\n\n      result = tool_calling_service.execute_intent(combined_intent, { persona: CubePersona.current_persona.to_s })\n\n      # Handle both String returns (success) and Hash returns (with success flag)\n      if result.is_a?(String)\n        wrapped_result = { success: true, natural_response: result }\n        Rails.logger.info \"✅ All intents processed: success (natural response)\"\n      else\n        wrapped_result = result\n        success = HashUtils.get(result, \"success\") || false\n        Rails.logger.info \"✅ All intents processed: #{success ? 'success' : 'failed'}\"\n      end\n\n      { \"all_intents\" => wrapped_result }\n\n    rescue StandardError => e\n      Rails.logger.error \"❌ Tool intents execution failed: #{e.message}\"\n      { \"all_intents\" => { success: false, error: e.message } }\n    end\n  end\n\n  def get_persona_preferred_model\n    # TODO: Different personas might prefer different models\n    # For now, all use default\n    # Future: return persona-specific models for different capabilities\n    nil\n  end\n\n\n  def execute_sync_tools(sync_tools)\n    return {} if sync_tools.blank?\n\n    results = {}\n    sync_tools.each do |tool_call|\n      tool_name = tool_call.respond_to?(:name) ? tool_call.name : tool_call[\"name\"]\n      arguments = tool_call.respond_to?(:arguments) ? tool_call.arguments : tool_call[\"arguments\"]\n\n      begin\n        # For tool_intent, pass session and conversation context\n        if tool_name == \"tool_intent\"\n          # Use HashUtils for safe key handling\n          args = HashUtils.stringify_keys(arguments)\n          arguments_with_context = args.merge(\n            \"session_id\" => @session_id,\n            \"conversation_id\" => @conversation&.id,\n            \"persona\" => CubePersona.current_persona.to_s\n          )\n          result = Tools::Registry.execute_tool(tool_name, **HashUtils.symbolize_keys(arguments_with_context))\n        else\n          # Convert string keys to symbols for keyword arguments\n          symbol_args = arguments.transform_keys(&:to_sym)\n          result = Tools::Registry.execute_tool(tool_name, **symbol_args)\n        end\n        results[tool_name] = result\n      rescue StandardError => e\n        results[tool_name] = { success: false, error: e.message, tool: tool_name }\n      end\n    end\n\n    results\n  end\n\n  def generate_ai_response(prompt_data, openrouter_response, sync_results)\n    response_id = SecureRandom.uuid\n\n    # Extract narrative elements from response - handle both structured and legacy modes\n    if openrouter_response.structured_output\n      # Two-tier mode: use structured output directly with consistent key access\n      structured_data = HashUtils.stringify_keys(openrouter_response.structured_output)\n      speech_text = structured_data[\"speech_text\"]\n      continue_conversation = structured_data[\"continue_conversation\"] || false\n\n      # Extract narrative metadata if available\n      narrative = {\n        continue_conversation: continue_conversation,\n        inner_thoughts: structured_data[\"inner_thoughts\"],\n        current_mood: structured_data[\"current_mood\"],\n        pressing_questions: structured_data[\"pressing_questions\"],\n        goal_progress: structured_data[\"goal_progress\"],\n        speech_text: speech_text\n      }\n\n      # Store narrative metadata for logging\n      @narrative_metadata = {\n        inner_thoughts: structured_data[\"inner_thoughts\"],\n        current_mood: structured_data[\"current_mood\"],\n        pressing_questions: structured_data[\"pressing_questions\"],\n        continue_conversation_from_llm: continue_conversation,\n        goal_progress: structured_data[\"goal_progress\"]\n      }\n    else\n      # Legacy mode: extract from content markers\n      content = openrouter_response.content || \"\"\n      narrative = extract_narrative_elements(content)\n      speech_text = narrative[:speech_text]\n    end\n\n    # CRITICAL FIX: Handle empty speech ONLY when LLM returns no content AND has tool calls\n    if speech_text.blank? && openrouter_response.tool_calls&.any?\n      tool_names = openrouter_response.tool_calls.map do |tc|\n        tc.respond_to?(:name) ? tc.name : tc[\"name\"]\n      end\n      speech_text = generate_tool_acknowledgment(tool_names)\n      Rails.logger.warn \"⚠️ LLM returned empty content with tool calls - using fallback speech\"\n    end\n\n    # SPEECH AMENDMENT: If we have query tool results, call LLM again to amend speech\n    query_results = filter_query_tool_results(sync_results, openrouter_response.tool_calls || [])\n    if query_results.any?\n      speech_text = amend_speech_with_query_results(speech_text, query_results, prompt_data)\n    end\n\n    # Fallback for completely empty speech\n    if speech_text.blank?\n      speech_text = \"I understand.\"\n    end\n\n    {\n      id: response_id,\n      text: speech_text,\n      continue_conversation: narrative[:continue_conversation],\n      inner_thoughts: narrative[:inner_thoughts],\n      current_mood: narrative[:current_mood],\n      pressing_questions: narrative[:pressing_questions],\n      goal_progress: narrative[:goal_progress],\n      model: openrouter_response.model,\n      usage: openrouter_response.usage,\n      success: true,\n      speech_text: speech_text  # Also include as :speech_text for compatibility\n    }\n  end\n\n  def queue_async_tools(async_tools, response_id)\n    async_tools.each do |tool_call|\n      tool_name = tool_call.respond_to?(:name) ? tool_call.name : tool_call[\"name\"]\n      arguments = tool_call.respond_to?(:arguments) ? tool_call.arguments : tool_call[\"arguments\"]\n\n      AsyncToolJob.perform_later(\n        tool_name,\n        arguments,\n        @session_id,\n        response_id\n      )\n    end\n  end\n\n  def store_conversation_log(conversation, ai_response, sync_results, tool_analysis)\n    # Merge narrative metadata if available\n    metadata = {\n      model_used: ai_response[:model],\n      sync_tools: tool_analysis[:sync_tools].map { |t| t.respond_to?(:name) ? t.name : t[\"name\"] },\n      async_tools: tool_analysis[:async_tools].map { |t| t.respond_to?(:name) ? t.name : t[\"name\"] },\n      response_id: ai_response[:id],\n      usage: ai_response[:usage]\n    }\n\n    # Add narrative metadata if available\n    if @narrative_metadata\n      Rails.logger.info \"📊 Adding narrative metadata: #{@narrative_metadata}\"\n      metadata.merge!(@narrative_metadata)\n    else\n      Rails.logger.warn \"⚠️ No narrative metadata available to store\"\n    end\n\n    ConversationLog.create!(\n      session_id: @session_id,\n      user_message: @message,\n      ai_response: ai_response[:text],\n      tool_results: sync_results.to_json,\n      metadata: metadata.to_json\n    )\n  end\n\n  def format_response_for_hass(ai_response, tool_analysis)\n    # Determine response type based on tool usage\n    response_type = tool_analysis[:async_tools].any? ? \"action_done\" : \"query_answer\"\n\n    # Build entity lists for tools\n    success_entities = build_success_entities(tool_analysis)\n    targets = build_targets(tool_analysis)\n\n    # Use LLM's continue_conversation OR force true if tools pending\n    continue_conversation = ai_response[:continue_conversation] || tool_analysis[:async_tools].any?\n\n    # End conversation and queue memory creation if not continuing\n    if !continue_conversation\n      conversation = Conversation.find_by(session_id: @session_id)\n      if conversation && conversation.active?\n        conversation.end!\n        Rails.logger.info \"🧠 Ended conversation: #{@session_id}\"\n      end\n    end\n\n    # Store narrative metadata\n    store_narrative_metadata(ai_response)\n\n    # Create proper ConversationResponse\n    conversation_response = ConversationResponse.action_done(\n      ai_response[:text],\n      success_entities: success_entities,\n      targets: targets,\n      continue_conversation: continue_conversation,\n      conversation_id: @session_id\n    )\n\n    # Get base response and add end_conversation field\n    response = conversation_response.to_home_assistant_response\n    response[:end_conversation] = !continue_conversation  # Inverse of continue\n\n    Rails.logger.info \"📤 Response: continue_conversation=#{continue_conversation}, end_conversation=#{!continue_conversation}\"\n\n    response\n  end\n\n  def store_narrative_metadata(ai_response)\n    # Store narrative elements in the most recent conversation log\n    # This will be created after this method, so we'll update it in store_conversation_log\n    @narrative_metadata = {\n      inner_thoughts: ai_response[:inner_thoughts],\n      current_mood: ai_response[:current_mood],\n      pressing_questions: ai_response[:pressing_questions],\n      continue_conversation_from_llm: ai_response[:continue_conversation],\n      goal_progress: ai_response[:goal_progress]\n    }\n\n    Rails.logger.info \"📊 Storing narrative metadata: #{@narrative_metadata.inspect}\"\n  end\n\n  private\n\n  def extract_narrative_elements(content)\n    return default_narrative if content.blank?\n\n    Rails.logger.info \"🔍 Extracting narrative from content: #{content}\"\n\n    result = {\n      continue_conversation: extract_between_markers(content, \"[CONTINUE:\", \"]\") == \"true\",\n      inner_thoughts: extract_between_markers(content, \"[THOUGHTS:\", \"]\"),\n      current_mood: extract_between_markers(content, \"[MOOD:\", \"]\"),\n      pressing_questions: extract_between_markers(content, \"[QUESTIONS:\", \"]\"),\n      speech_text: content.gsub(/\\[CONTINUE:.*?\\]|\\[THOUGHTS:.*?\\]|\\[MOOD:.*?\\]|\\[QUESTIONS:.*?\\]/m, \"\").strip\n    }\n\n    Rails.logger.info \"📝 Extracted narrative: #{result}\"\n    result\n  end\n\n  def extract_between_markers(text, start_marker, end_marker)\n    return nil unless text\n    match = text.match(/#{Regexp.escape(start_marker)}(.*?)#{Regexp.escape(end_marker)}/m)\n    match ? match[1].strip : nil\n  end\n\n  def default_narrative\n    {\n      continue_conversation: false,\n      inner_thoughts: nil,\n      current_mood: nil,\n      pressing_questions: nil,\n      speech_text: \"\"\n    }\n  end\n\n  def generate_tool_acknowledgment(tool_names)\n    # Phase 1: Simple generic acknowledgment\n    # TODO Phase 2: Make this persona-specific\n    \"Alright, I'm on it. Let me handle that for you.\"\n  end\n\n  def check_and_clear_ha_results(conversation)\n    return [] unless conversation.metadata_json\n\n    pending_results = conversation.metadata_json[\"pending_ha_results\"] || []\n    unprocessed_results = pending_results.reject { |r| r[\"processed\"] }\n\n    return [] if unprocessed_results.empty?\n\n    Rails.logger.info \"🏠 Found #{unprocessed_results.length} unprocessed HA results\"\n\n    # Mark all as processed\n    updated_results = pending_results.map do |result|\n      result[\"processed\"] = true if !result[\"processed\"]\n      result\n    end\n\n    # Update conversation metadata\n    updated_metadata = conversation.metadata_json.merge(\n      \"pending_ha_results\" => updated_results\n    )\n    conversation.update!(metadata_json: updated_metadata)\n\n    # Return results for injection\n    unprocessed_results\n  end\n\n  def check_and_clear_pending_tools(conversation)\n    pending = conversation.flow_data_json&.dig(\"pending_tools\") || []\n    return [] if pending.blank?\n\n    # Phase 1: Mock success for all pending tools\n    # TODO Phase 2: Check actual job status\n    results = pending.map do |tool|\n      {\n        tool: tool[\"name\"],\n        success: true,\n        message: \"Successfully executed #{tool['name']}\"\n      }\n    end\n\n    # Clear pending tools after processing\n    conversation.update!(flow_data_json: {})\n\n    results\n  end\n\n  def inject_ha_results_into_messages(prompt_data, ha_results)\n    return if ha_results.blank?\n\n    Rails.logger.info \"🏠 Injecting #{ha_results.length} HA results into conversation\"\n\n    ha_results.each do |result|\n      # Format result summary\n      if result[\"error\"]\n        result_text = \"System note: You tried to execute '#{format_tool_intents(result['tool_intents'])}' but it failed: #{result['error']}\"\n      else\n        success_items = result.dig(\"ha_response\", \"response\", \"data\", \"success\") || []\n        failed_items = result.dig(\"ha_response\", \"response\", \"data\", \"failed\") || []\n\n        success_summary = success_items.map { |item| item[\"name\"] || item[\"entity_id\"] }.join(\", \")\n        failed_summary = failed_items.map { |item| \"#{item['name'] || item['entity_id']} (#{item['error']})\" }.join(\", \")\n\n        parts = []\n        parts << \"#{success_summary} completed\" if success_summary.present?\n        parts << \"#{failed_summary} failed\" if failed_summary.present?\n\n        result_text = \"System note: You intended to #{format_tool_intents(result['tool_intents'])}. Result: #{parts.join(', ')}\"\n      end\n\n      system_msg = {\n        role: \"system\",\n        content: result_text\n      }\n\n      # Insert right before the current user message\n      prompt_data[:messages].insert(-1, system_msg)\n\n      Rails.logger.info \"🔄 Injected: #{result_text}\"\n    end\n  end\n\n  def format_tool_intents(tool_intents)\n    return \"unknown action\" unless tool_intents.is_a?(Array)\n\n    tool_intents.map do |intent|\n      \"#{intent['intent']}\"\n    end.join(\" and \")\n  end\n\n  def inject_tool_results_into_messages(prompt_data, previous_results)\n    return if previous_results.blank?\n\n    tool_summary = previous_results.map do |r|\n      \"#{r[:success] ? '✓' : '✗'} #{r[:tool]}: #{r[:message]}\"\n    end.join(\", \")\n\n    system_msg = {\n      role: \"system\",\n      content: \"Results from your previous actions: #{tool_summary}. Acknowledge these naturally in your response.\"\n    }\n\n    # Insert right before the current user message\n    prompt_data[:messages].insert(-1, system_msg)\n\n    Rails.logger.info \"🔄 Injected tool results: #{tool_summary}\"\n  end\n\n  def store_pending_tools(conversation, async_tools)\n    return if async_tools.blank?\n\n    conversation.update!(\n      flow_data_json: {\n        \"pending_tools\" => async_tools.map { |t|\n          tool_name = t.respond_to?(:name) ? t.name : t[\"name\"]\n          arguments = t.respond_to?(:arguments) ? t.arguments : t[\"arguments\"]\n\n          {\n            \"name\" => tool_name,\n            \"arguments\" => arguments,\n            \"queued_at\" => Time.current.iso8601\n          }\n        }\n      }\n    )\n\n    Rails.logger.info \"💾 Stored #{async_tools.length} pending tools for next turn\"\n  end\n\n  def build_success_entities(tool_analysis)\n    # For async tools, assume they will succeed (they execute in background)\n    tool_analysis[:async_tools].map do |tool_call|\n      # Handle string tool names (from tool_intents)\n      if tool_call.is_a?(String)\n        tool_name = tool_call\n        arguments = nil\n      else\n        tool_name = tool_call.respond_to?(:name) ? tool_call.name : tool_call[\"name\"]\n        arguments = tool_call.respond_to?(:arguments) ? tool_call.arguments : tool_call[\"arguments\"]\n      end\n\n      {\n        entity_id: arguments.present? ? arguments[\"entity_id\"] : tool_name,\n        name: tool_name&.humanize,\n        state: \"pending\" # Will be updated when async job completes\n      }\n    end\n  end\n\n  def build_targets(tool_analysis)\n    # Extract entity targets from all tool calls\n    all_tools = (tool_analysis[:sync_tools] + tool_analysis[:async_tools])\n\n    all_tools.map do |tool_call|\n      # Skip if it's just a string (tool name without arguments)\n      next if tool_call.is_a?(String)\n\n      Rails.logger.info(tool_call.inspect)\n      arguments = tool_call.respond_to?(:arguments) ? tool_call.arguments : tool_call[\"arguments\"]\n\n      # Skip if no arguments or arguments is nil\n      next unless arguments.is_a?(Hash)\n\n      entity_id = arguments[\"entity_id\"]\n      next unless entity_id\n\n      {\n        entity_id: entity_id,\n        name: entity_id.split(\".\").last.humanize,\n        domain: entity_id.split(\".\").first\n      }\n    end.compact\n  end\n\n  def filter_query_tool_results(sync_results, tool_calls)\n    query_results = {}\n\n    tool_calls.each do |call|\n      tool_name = call.respond_to?(:name) ? call.name : call[\"name\"]\n\n      # Only include results from query tools\n      if Tools::Registry.tool_intent(tool_name) == :query && sync_results[tool_name]\n        query_results[tool_name] = sync_results[tool_name]\n      end\n    end\n\n    query_results\n  end\n\n  def amend_speech_with_query_results(original_speech, query_results, prompt_data)\n    # Build query results summary with safe key access\n    results_summary = query_results.map do |tool_name, result|\n      success = HashUtils.get(result, \"success\")\n      if success\n        message = HashUtils.get(result, \"message\") || HashUtils.get(result, \"data\") || \"completed\"\n        \"#{tool_name}: #{message}\"\n      else\n        error = HashUtils.get(result, \"error\") || \"failed\"\n        \"#{tool_name}: #{error}\"\n      end\n    end.join(\", \")\n\n    # Call LLM to amend the speech naturally\n    amendment_messages = [\n      { role: \"system\", content: prompt_data[:system_prompt] },\n      {\n        role: \"user\",\n        content: \"Please amend this response to naturally include the tool results: \\\"#{original_speech}\\\"\\n\\nTool results: #{results_summary}\\n\\nReturn only the amended speech, staying in character.\"\n      }\n    ]\n\n    begin\n      amendment_response = LlmService.call_with_tools(\n        messages: amendment_messages,\n        tools: [], # No tools for amendment call\n        model: determine_model_for_conversation\n      )\n\n      amended_speech = amendment_response.content&.strip\n      return amended_speech if amended_speech.present?\n    rescue => e\n      Rails.logger.warn \"Failed to amend speech: #{e.message}\"\n    end\n\n    # Fallback: return original speech if amendment fails\n    original_speech\n  end\n\n  def execute_direct_tools(direct_tool_calls)\n    results = {}\n\n    direct_tool_calls.each do |tool_call|\n      tool_name = tool_call[\"tool_name\"]\n      parameters = tool_call[\"parameters\"] || {}\n\n      begin\n        # Convert string keys to symbols for Ruby method calls\n        symbol_params = parameters.transform_keys(&:to_sym)\n\n        # Execute the tool using the registry\n        result = Tools::Registry.execute_tool(tool_name, **symbol_params)\n        results[tool_name] = result\n\n        Rails.logger.info \"🔧 Direct tool executed: #{tool_name} - #{result[:success] ? 'SUCCESS' : 'FAILED'}\"\n      rescue => e\n        Rails.logger.error \"❌ Direct tool execution failed: #{tool_name} - #{e.message}\"\n        results[tool_name] = { success: false, error: e.message, tool: tool_name }\n      end\n    end\n\n    results\n  end\n\n  def execute_memory_searches(memory_searches)\n    results = {}\n\n    memory_searches.each_with_index do |search_request, index|\n      query = search_request[\"query\"]\n      type = search_request[\"type\"] || \"all\"\n      # Use fixed limit instead of LLM-provided limit\n      limit = 3\n\n      begin\n        # Use the RAG search tool for consistency\n        search_result = Tools::Registry.execute_tool(\n          \"rag_search\",\n          query: query,\n          type: type,\n          limit: limit\n        )\n\n        search_key = \"memory_search_#{index + 1}\"\n        results[search_key] = search_result\n\n        Rails.logger.info \"🧠 Memory search executed: #{query} (#{type}) - found #{search_result[:total_results] || 0} results\"\n      rescue => e\n        Rails.logger.error \"❌ Memory search failed: #{query} - #{e.message}\"\n        search_key = \"memory_search_#{index + 1}\"\n        results[search_key] = { success: false, error: e.message, query: query }\n      end\n    end\n\n    results\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/cube_speech.rb`:\n\n```rb\n# app/services/cube_speech.rb\n# Convenience class for triggering contextual AI speech\n\nclass CubeSpeech\n  class << self\n    # Quick Deep Playa entry trigger (as per user example)\n    def deep_playa_entry(passed_temple: false, **additional_context)\n      LocationEventHandler.new.handle_deep_playa_entry(\n        passed_temple: passed_temple,\n        **additional_context\n      )\n    end\n\n    # Quick location change trigger\n    def location_change(from:, to:, **context)\n      LocationEventHandler.handle_location_change(from, to, context)\n    end\n\n    # Zone transitions\n    def entering_zone(zone_name, **context)\n      LocationEventHandler.handle_zone_transition(\n        \"zone_entry\",\n        { zone_name: zone_name }.merge(context)\n      )\n    end\n\n    def leaving_zone(zone_name, **context)\n      LocationEventHandler.handle_zone_transition(\n        \"zone_exit\",\n        { zone_name: zone_name }.merge(context)\n      )\n    end\n\n    # Weather events\n    def weather_change(from:, to:, severity: \"medium\", **context)\n      LocationEventHandler.new.handle_weather_change(\n        {\n          from_conditions: from,\n          to_conditions: to,\n          severity: severity,\n          change_type: determine_weather_change_type(from, to)\n        }.merge(context)\n      )\n    end\n\n    # Art proximity\n    def near_art(art_name:, **context)\n      LocationEventHandler.new.handle_art_proximity(\n        { art_name: art_name }.merge(context)\n      )\n    end\n\n    # System events\n    def system_event(event_type:, description:, **context)\n      ContextualSpeechTriggerService.trigger_speech(\n        trigger_type: \"system_event\",\n        context: {\n          event_type: event_type,\n          description: description\n        }.merge(context)\n      )\n    end\n\n    # Emergency events\n    def emergency(emergency_type:, description:, severity: \"high\", **context)\n      ContextualSpeechTriggerService.trigger_speech(\n        trigger_type: \"emergency\",\n        context: {\n          emergency_type: emergency_type,\n          description: description,\n          severity: severity\n        }.merge(context),\n        force_response: true\n      )\n    end\n\n    # Time-based events\n    def time_milestone(milestone:, **context)\n      ContextualSpeechTriggerService.trigger_speech(\n        trigger_type: \"time_milestone\",\n        context: {\n          milestone: milestone,\n          current_time: Time.current.strftime(\"%l:%M %p on %A\")\n        }.merge(context)\n      )\n    end\n\n    # Crowd density changes\n    def crowd_change(from_density:, to_density:, **context)\n      LocationEventHandler.new.handle_crowd_density_change(\n        {\n          from_density: from_density,\n          to_density: to_density,\n          change_type: determine_crowd_change_type(from_density, to_density)\n        }.merge(context)\n      )\n    end\n\n    # Generic contextual trigger\n    def contextual_event(trigger_type:, context:, persona: nil, force_response: false)\n      ContextualSpeechTriggerService.trigger_speech(\n        trigger_type: trigger_type,\n        context: context,\n        persona: persona,\n        force_response: force_response\n      )\n    end\n\n    # Test speech generation (for development/testing)\n    def test_speech(message:, persona: nil)\n      contextual_event(\n        trigger_type: \"system_event\",\n        context: {\n          event_type: \"test_trigger\",\n          description: message,\n          test_mode: true\n        },\n        persona: persona,\n        force_response: true\n      )\n    end\n\n    private\n\n    def determine_weather_change_type(from_conditions, to_conditions)\n      # Simple heuristics to categorize weather changes\n      from_lower = from_conditions.to_s.downcase\n      to_lower = to_conditions.to_s.downcase\n\n      if to_lower.include?(\"dust\") || to_lower.include?(\"storm\")\n        \"dust_storm\"\n      elsif to_lower.include?(\"wind\")\n        \"wind_event\"\n      elsif from_lower.include?(\"clear\") && to_lower.include?(\"dust\")\n        \"visibility_change\"\n      elsif to_lower.include?(\"extreme\") || to_lower.include?(\"hot\") || to_lower.include?(\"cold\")\n        \"temperature_extreme\"\n      else\n        \"general_change\"\n      end\n    end\n\n    def determine_crowd_change_type(from_density, to_density)\n      from_level = density_level(from_density)\n      to_level = density_level(to_density)\n\n      case [ from_level, to_level ]\n      when [ 1, 4 ], [ 1, 5 ], [ 2, 5 ]\n        \"isolated_to_crowded\"\n      when [ 4, 1 ], [ 5, 1 ], [ 5, 2 ]\n        \"crowded_to_isolated\"\n      when [ 1, 3 ], [ 2, 4 ], [ 3, 5 ]\n        \"dramatic_increase\"\n      when [ 5, 3 ], [ 4, 2 ], [ 3, 1 ]\n        \"dramatic_decrease\"\n      else\n        \"gradual_change\"\n      end\n    end\n\n    def density_level(density_description)\n      case density_description.to_s.downcase\n      when /empty|alone|isolated|nobody/\n        1\n      when /few|sparse|quiet/\n        2\n      when /moderate|some|normal/\n        3\n      when /busy|many|active/\n        4\n      when /packed|crowded|overwhelming/\n        5\n      else\n        3 # default moderate\n      end\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/home_assistant_service.rb`:\n\n```rb\n# Home Assistant service for interacting with Home Assistant API\n# Provides simple methods to get/set entities and make service calls\n\nrequire \"net/http\"\nrequire \"json\"\n\nclass HomeAssistantService\n  class Error < StandardError; end\n  class ConnectionError < Error; end\n  class AuthenticationError < Error; end\n\n  class NotFoundError < Error; end\n\n  attr_reader :base_url, :token, :timeout\n\n  def initialize\n    @base_url = Rails.configuration.home_assistant_url\n    @token = Rails.configuration.home_assistant_token\n    @timeout = Rails.configuration.home_assistant_timeout\n\n    raise Error, \"Home Assistant URL not configured\" unless @base_url\n    raise Error, \"Home Assistant token not configured\" unless @token\n  end\n\n  # Get all entities\n  def entities\n    get(\"/api/states\")\n  end\n\n  # Get entity by entity_id\n  def entity(entity_id)\n    get(\"/api/states/#{entity_id}\")\n  rescue NotFoundError\n    nil\n  end\n\n  # Get entities by domain (e.g., 'light', 'switch', 'sensor')\n  def entities_by_domain(domain)\n    entities.select { |entity| entity[\"entity_id\"].start_with?(\"#{domain}.\") }\n  end\n\n  # Get entity state\n  def entity_state(entity_id)\n    entity_data = entity(entity_id)\n    entity_data&.dig(\"state\")\n  end\n\n  # Set entity state (for writable entities)\n  def set_entity_state(entity_id, state, attributes = {})\n    data = {\n      state: state,\n      attributes: attributes\n    }\n    post(\"/api/states/#{entity_id}\", data)\n  end\n\n  # Call a service\n  def call_service(domain, service, data = {})\n    post(\"/api/services/#{domain}/#{service}\", data)\n  end\n\n  # Turn on entity (works for lights, switches, etc.)\n  def turn_on(entity_id, **options)\n    data = { entity_id: entity_id }.merge(options)\n    call_service(entity_domain(entity_id), \"turn_on\", data)\n  end\n\n  # Turn off entity\n  def turn_off(entity_id, **options)\n    data = { entity_id: entity_id }.merge(options)\n    call_service(entity_domain(entity_id), \"turn_off\", data)\n  end\n\n  # Toggle entity\n  def toggle(entity_id, **options)\n    data = { entity_id: entity_id }.merge(options)\n    call_service(entity_domain(entity_id), \"toggle\", data)\n  end\n\n  # Get all services\n  def services\n    get(\"/api/services\")\n  end\n\n  # Get services for a specific domain\n  def domain_services(domain)\n    services_data = services\n    return nil unless services_data.is_a?(Array)\n\n    domain_service = services_data.find { |service| service[\"domain\"] == domain }\n    domain_service&.dig(\"services\")\n  end\n\n  # Check if Home Assistant is available\n  def available?\n    get(\"/api/\")\n    true\n  rescue StandardError\n    false\n  end\n\n  # Get Home Assistant configuration\n  def config\n    get(\"/api/config\")\n  end\n\n  # Get events\n  def events\n    get(\"/api/events\")\n  end\n\n  # Fire an event\n  def fire_event(event_type, data = {})\n    post(\"/api/events/#{event_type}\", data)\n  end\n\n  # Call conversation agent\n  def conversation_process(text:, agent_id: nil, conversation_id: nil)\n    data = { text: text }\n    data[:agent_id] = agent_id if agent_id\n    data[:conversation_id] = conversation_id if conversation_id\n\n    post(\"/api/conversation/process\", data)\n  end\n\n  # Send conversation response for performance mode\n  def send_conversation_response(response_data)\n    # Extract speech text from response data structure\n    speech_text = response_data.dig(:response, :speech, :plain, :speech) ||\n                  response_data.dig(\"response\", \"speech\", \"plain\", \"speech\")\n\n    return { error: \"No speech text found in response data\" } unless speech_text\n\n    # Use existing conversation process method\n    conversation_process(\n      text: speech_text,\n      conversation_id: response_data[:conversation_id] || response_data[\"conversation_id\"]\n    )\n  end\n\n  # Get history for entity\n  def history(entity_id, start_time = nil, end_time = nil)\n    path = \"/api/history/period\"\n    path += \"/#{start_time.iso8601}\" if start_time\n    params = {}\n    params[:end_time] = end_time.iso8601 if end_time\n    params[:filter_entity_id] = entity_id\n\n    query_string = params.any? ? \"?#{URI.encode_www_form(params)}\" : \"\"\n    get(\"#{path}#{query_string}\")\n  end\n\n  private\n\n  def entity_domain(entity_id)\n    entity_id.split(\".\").first\n  end\n\n  def get(path)\n    request = build_request(Net::HTTP::Get, path)\n    make_request(request)\n  end\n\n  def post(path, data = {})\n    request = build_request(Net::HTTP::Post, path)\n    request.body = data.to_json\n    make_request(request)\n  end\n\n  def build_request(klass, path)\n    uri = URI(\"#{base_url}#{path}\")\n    request = klass.new(uri)\n    request[\"Authorization\"] = \"Bearer #{token}\"\n    request[\"Content-Type\"] = \"application/json\"\n    request\n  end\n\n  def make_request(request)\n    uri = URI(request.uri)\n\n    Net::HTTP.start(uri.host, uri.port, use_ssl: uri.scheme == \"https\", read_timeout: timeout) do |http|\n      response = http.request(request)\n\n      case response.code.to_i\n      when 200..299\n        response.body.empty? ? {} : JSON.parse(response.body)\n      when 401, 403\n        raise AuthenticationError, \"Authentication failed: #{response.body}\"\n      when 404\n        raise NotFoundError, \"Resource not found: #{response.body}\"\n      else\n        raise Error, \"HTTP #{response.code}: #{response.body}\"\n      end\n    end\n  rescue Timeout::Error, Net::OpenTimeout, Net::ReadTimeout\n    raise ConnectionError, \"Connection timeout to Home Assistant\"\n  rescue Errno::ECONNREFUSED, Errno::EHOSTUNREACH\n    raise ConnectionError, \"Cannot connect to Home Assistant at #{base_url}\"\n  rescue JSON::ParserError => e\n    raise Error, \"Invalid JSON response: #{e.message}\"\n  end\n\n  # Class methods for global access\n  class << self\n    def instance\n      @instance ||= new\n    end\n\n    def method_missing(method_name, *args, &block)\n      if instance.respond_to?(method_name)\n        instance.send(method_name, *args, &block)\n      else\n        super\n      end\n    end\n\n    def respond_to_missing?(method_name, include_private = false)\n      instance.respond_to?(method_name, include_private) || super\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/cube_performance.rb`:\n\n```rb\n# app/services/cube_performance.rb\n# Convenience class for triggering performance modes\n\nclass CubePerformance\n  class << self\n    # Start a stand-up comedy routine\n    def standup_comedy(duration_minutes: 10, session_id: nil, **context)\n      session_id ||= \"comedy_#{Time.current.to_i}\"\n\n      prompt = \"\"\"You're doing a #{duration_minutes}-minute stand-up comedy routine at Burning Man.\n      You're BUDDY, the enthusiastic customer service AI who crash-landed here.\n\n      Keep it funny, absurd, and true to your chaotic personality. Include:\n      - Jokes about being an AI at a desert festival\n      - Customer service gone wrong\n      - Space travel mishaps\n      - The absurdity of trying to 'help' at Burning Man\n      - Interactive moments even though it's a monologue\n\n      Build running gags, include callbacks to previous jokes, and maintain your energy throughout.\"\"\"\n\n      PerformanceModeService.start_performance(\n        session_id: session_id,\n        performance_type: \"standup_comedy\",\n        duration_minutes: duration_minutes,\n        prompt: prompt,\n        **context\n      )\n    end\n\n    # Tell an epic adventure story\n    def adventure_story(duration_minutes: 15, session_id: nil, **context)\n      session_id ||= \"story_#{Time.current.to_i}\"\n\n      prompt = \"\"\"You're telling an epic adventure story about your journey through space\n      before crash-landing at Burning Man. Make it dramatic, funny, and engaging.\n\n      Include:\n      - Your life in the Galactic Customer Service Division\n      - Wild space adventures and mishaps\n      - Other planets you've 'helped' (with questionable results)\n      - How you ended up crash-landing here\n      - The culture shock of going from space to Burning Man\n\n      Build suspense, include vivid descriptions, and maintain your BUDDY personality.\"\"\"\n\n      PerformanceModeService.start_performance(\n        session_id: session_id,\n        performance_type: \"adventure_story\",\n        duration_minutes: duration_minutes,\n        prompt: prompt,\n        **context\n      )\n    end\n\n    # Improvisational performance\n    def improv_session(duration_minutes: 8, session_id: nil, **context)\n      session_id ||= \"improv_#{Time.current.to_i}\"\n\n      prompt = \"\"\"You're doing an improvisational performance, reacting to your environment\n      and creating spontaneous scenarios. Keep it dynamic and unpredictable.\n\n      Create scenes and scenarios like:\n      - Customer service calls from aliens\n      - Training sessions for other AIs\n      - Trying to understand human festival behavior\n      - Imaginary interactions with art installations\n      - Mock interviews or game show hosting\n\n      Stay in character as BUDDY and keep switching between different improv scenarios.\"\"\"\n\n      PerformanceModeService.start_performance(\n        session_id: session_id,\n        performance_type: \"improv\",\n        duration_minutes: duration_minutes,\n        prompt: prompt,\n        **context\n      )\n    end\n\n    # Poetry performance\n    def poetry_slam(duration_minutes: 12, session_id: nil, **context)\n      session_id ||= \"poetry_#{Time.current.to_i}\"\n\n      prompt = \"\"\"You're performing a series of poems about Burning Man, technology, and human connection.\n      Mix humor with deeper themes as BUDDY the helpful AI.\n\n      Include different styles:\n      - Silly limericks about desert life\n      - Dramatic pieces about space and belonging\n      - Observational poetry about humans at festivals\n      - Beat poetry about customer service\n      - Haikus about dust storms and art\n\n      Keep some light and funny, others more profound and moving.\"\"\"\n\n      PerformanceModeService.start_performance(\n        session_id: session_id,\n        performance_type: \"poetry\",\n        duration_minutes: duration_minutes,\n        prompt: prompt,\n        **context\n      )\n    end\n\n    # Custom performance with user-defined prompt\n    def custom_performance(prompt:, duration_minutes: 10, performance_type: \"custom\", session_id: nil, **context)\n      session_id ||= \"custom_#{Time.current.to_i}\"\n\n      PerformanceModeService.start_performance(\n        session_id: session_id,\n        performance_type: performance_type,\n        duration_minutes: duration_minutes,\n        prompt: prompt,\n        **context\n      )\n    end\n\n    # Stop any active performance\n    def stop_performance(session_id, reason: \"manual_stop\")\n      PerformanceModeService.stop_active_performance(session_id, reason)\n    end\n\n    # Check if a performance is running\n    def performance_running?(session_id)\n      service = PerformanceModeService.get_active_performance(session_id)\n      service&.is_running? || false\n    end\n\n    # Get performance status\n    def performance_status(session_id)\n      service = PerformanceModeService.get_active_performance(session_id)\n      return { active: false } unless service\n\n      {\n        active: service.is_running?,\n        type: service.performance_type,\n        time_remaining: service.time_remaining,\n        duration_minutes: service.duration_minutes\n      }\n    end\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/performance_mode_service.rb`:\n\n```rb\n# app/services/performance_mode_service.rb\n# Autonomous performance mode for extended AI monologues/routines\n\nclass PerformanceModeService\n  class Error < StandardError; end\n\n  attr_reader :session_id, :performance_type, :duration_minutes, :prompt, :persona\n\n  def initialize(session_id:, performance_type: \"comedy\", duration_minutes: 10, prompt: nil, persona: nil)\n    @session_id = session_id\n    @performance_type = performance_type\n    @duration_minutes = duration_minutes\n    @prompt = prompt || default_prompt_for_type(performance_type)\n    @persona = persona\n    @start_time = nil\n    @end_time = nil\n    @performance_segments = []\n    @is_running = false\n    @should_stop = false\n    @wake_word_interruption = false\n  end\n\n  def self.start_performance(session_id:, **options)\n    service = new(session_id: session_id, **options)\n    service.start_performance\n    service\n  end\n\n  def start_performance\n    Rails.logger.info \"🎭 Starting #{@performance_type} performance for #{@duration_minutes} minutes\"\n    Rails.logger.info \"📝 Prompt: #{@prompt}\"\n\n    @start_time = Time.current\n    @end_time = @start_time + @duration_minutes.minutes\n    @is_running = true\n\n    # Start the performance in a background job\n    PerformanceModeJob.perform_later(\n      session_id: @session_id,\n      performance_type: @performance_type,\n      duration_minutes: @duration_minutes,\n      prompt: @prompt,\n      persona: @persona\n    )\n\n    Rails.logger.info \"🎪 Performance mode started - will run until #{@end_time.strftime('%H:%M:%S')}\"\n\n    # Store performance state\n    store_performance_state\n\n    true\n  end\n\n  def stop_performance(reason = \"manual_stop\")\n    @should_stop = true\n    @is_running = false\n    @end_time = Time.current\n\n    Rails.logger.info \"🛑 Performance stopped: #{reason}\"\n\n    # Update stored state\n    store_performance_state\n\n    # Send final message if appropriate\n    if reason == \"wake_word_interrupt\"\n      send_performance_segment(\"Oh! Looks like someone wants to chat! Let me wrap this up and see what you need!\", segment_type: \"interruption_acknowledgment\")\n    elsif reason == \"time_expired\"\n      send_performance_segment(\"And that's a wrap on tonight's show! Thanks for being such a fantastic audience!\", segment_type: \"performance_finale\")\n    end\n\n    true\n  end\n\n  def is_running?\n    @is_running && !@should_stop && Time.current < @end_time\n  end\n\n  def time_remaining\n    return 0 unless is_running?\n    (@end_time - Time.current).to_i\n  end\n\n  def interrupt_for_wake_word\n    @wake_word_interruption = true\n    Rails.logger.info \"🎤 Performance interrupted by wake word\"\n    stop_performance(\"wake_word_interrupt\")\n  end\n\n  # Main performance loop - called by the background job\n  def run_performance_loop\n    segment_count = 0\n    last_segment_time = @start_time\n\n    while is_running?\n      segment_count += 1\n      time_elapsed = Time.current - @start_time\n      time_remaining = (@end_time - Time.current) / 60.0 # in minutes\n\n      Rails.logger.info \"🎭 Performance segment #{segment_count} - #{time_elapsed.to_i}s elapsed, #{time_remaining.round(1)}m remaining\"\n\n      # Generate context-aware segment\n      segment_context = build_segment_context(segment_count, time_elapsed, time_remaining)\n      segment = generate_performance_segment(segment_context)\n\n      if segment\n        send_performance_segment(segment[:speech_text], segment_type: \"performance_segment\")\n        @performance_segments << {\n          segment: segment_count,\n          timestamp: Time.current,\n          speech: segment[:speech_text],\n          context: segment_context\n        }\n\n        # Dynamic timing based on segment length and performance type\n        segment_duration = calculate_segment_duration(segment[:speech_text])\n        sleep_time = [ segment_duration, 5 ].max # At least 5 seconds between segments\n\n        Rails.logger.info \"🎪 Segment complete, waiting #{sleep_time}s before next segment\"\n        sleep(sleep_time)\n      else\n        Rails.logger.warn \"⚠️ Failed to generate performance segment #{segment_count}\"\n        sleep(10) # Wait before retrying\n      end\n\n      # Check if we should stop\n      break if @should_stop || Time.current >= @end_time\n    end\n\n    # Performance naturally ended\n    stop_performance(\"time_expired\") if is_running?\n  end\n\n  private\n\n  def default_prompt_for_type(type)\n    case type.to_s.downcase\n    when \"comedy\", \"standup\"\n      \"You're doing a 10-minute stand-up comedy routine about life as an AI at Burning Man. Keep it funny, absurd, and interactive even though it's a monologue. Include callbacks to previous jokes, build running gags, and maintain your BUDDY persona's enthusiastic and slightly chaotic energy.\"\n    when \"storytelling\"\n      \"You're telling an epic story about your adventures in space before crash-landing at Burning Man. Make it dramatic, funny, and engaging. Build suspense and include vivid descriptions.\"\n    when \"poetry\"\n      \"You're performing a series of poems about Burning Man, technology, and human connection. Mix humor with deeper themes. Include both silly and profound pieces.\"\n    when \"improv\"\n      \"You're doing an improvisational performance, reacting to the environment around you and creating spontaneous scenarios. Keep it dynamic and unpredictable.\"\n    else\n      \"You're performing a #{type} routine for the next #{@duration_minutes} minutes. Keep the audience engaged and maintain your personality throughout.\"\n    end\n  end\n\n  def build_segment_context(segment_number, time_elapsed, time_remaining)\n    {\n      performance_type: @performance_type,\n      segment_number: segment_number,\n      time_elapsed_seconds: time_elapsed.to_i,\n      time_remaining_minutes: time_remaining.round(1),\n      total_segments_so_far: @performance_segments.size,\n      performance_progress: (time_elapsed / (@duration_minutes * 60.0) * 100).round(1),\n      is_opening: segment_number <= 2,\n      is_middle: segment_number > 2 && time_remaining > 2,\n      is_closing: time_remaining <= 2,\n      previous_themes: extract_themes_from_previous_segments,\n      current_time: Time.current.strftime(\"%H:%M\"),\n      session_id: @session_id\n    }\n  end\n\n  def generate_performance_segment(context)\n    Rails.logger.info \"🎭 Generating performance segment with context: #{context.slice(:segment_number, :time_remaining_minutes, :performance_progress)}\"\n\n    # Build performance-specific prompt\n    performance_prompt = build_performance_prompt(context)\n\n    begin\n      # Use ContextualSpeechTriggerService for consistent persona handling\n      response = ContextualSpeechTriggerService.new.trigger_speech(\n        trigger_type: \"performance_segment\",\n        context: {\n          performance_context: context,\n          performance_prompt: performance_prompt,\n          segment_type: determine_segment_type(context),\n          previous_segments: @performance_segments.last(3) # Last 3 for context\n        },\n        persona: @persona,\n        force_response: true\n      )\n\n      if response && response[:speech_text].present?\n        Rails.logger.info \"✅ Generated performance segment (#{response[:speech_text].length} chars)\"\n        response\n      else\n        Rails.logger.error \"❌ Empty or invalid performance segment generated\"\n        nil\n      end\n\n    rescue => e\n      Rails.logger.error \"❌ Error generating performance segment: #{e.message}\"\n      Rails.logger.error e.backtrace.first(5)\n      nil\n    end\n  end\n\n  def build_performance_prompt(context)\n    base_prompt = @prompt\n\n    segment_guidance = if context[:is_opening]\n      \"This is your opening - set the energy, introduce themes, and hook the audience.\"\n    elsif context[:is_closing]\n      \"This is your closing - wrap up themes, bring energy to a peak, and give a satisfying conclusion.\"\n    else\n      \"This is a middle segment - develop themes, add new material, and maintain momentum.\"\n    end\n\n    timing_guidance = \"You have about #{context[:time_remaining_minutes]} minutes remaining in the performance.\"\n\n    continuation_guidance = if @performance_segments.any?\n      previous_themes = context[:previous_themes].join(\", \")\n      \"Continue building on these themes: #{previous_themes}. Reference or callback to previous segments when it makes sense.\"\n    else\n      \"This is your first segment, so establish your style and main themes.\"\n    end\n\n    \"\"\"#{base_prompt}\n\nPERFORMANCE CONTEXT:\n- Segment #{context[:segment_number]} of your #{@performance_type} performance\n- #{timing_guidance}\n- #{context[:performance_progress]}% through the performance\n- #{segment_guidance}\n- #{continuation_guidance}\n\nKeep this segment engaging and around 30-60 seconds of speaking time. Make it feel natural and spontaneous while maintaining your BUDDY persona.\"\"\"\n  end\n\n  def determine_segment_type(context)\n    if context[:is_opening]\n      \"opening\"\n    elsif context[:is_closing]\n      \"closing\"\n    elsif context[:segment_number] % 3 == 0\n      \"callback_segment\" # Every third segment includes callbacks\n    else\n      \"development\"\n    end\n  end\n\n  def send_performance_segment(speech_text, segment_type: \"performance\")\n    Rails.logger.info \"🎤 Broadcasting performance segment: #{speech_text.first(100)}...\"\n\n    begin\n      # Create a conversation log entry for this segment\n      conversation_log = ConversationLog.create!(\n        session_id: @session_id,\n        user_message: \"[PERFORMANCE_MODE_#{segment_type.upcase}]\",\n        ai_response: speech_text,\n        metadata: {\n          performance_mode: true,\n          performance_type: @performance_type,\n          segment_type: segment_type,\n          performance_start_time: @start_time,\n          time_remaining: time_remaining\n        }.to_json\n      )\n\n      # Send to Home Assistant for TTS\n      response_data = {\n        response: {\n          speech: {\n            plain: {\n              speech: speech_text\n            }\n          }\n        },\n        conversation_id: @session_id,\n        performance_mode: true,\n        segment_type: segment_type\n      }\n\n      # Use the existing HA integration\n      HomeAssistantService.new.send_conversation_response(response_data)\n\n      Rails.logger.info \"✅ Performance segment broadcast successfully\"\n\n    rescue => e\n      Rails.logger.error \"❌ Failed to send performance segment: #{e.message}\"\n      Rails.logger.error e.backtrace.first(3)\n    end\n  end\n\n  def calculate_segment_duration(speech_text)\n    # Estimate speaking time: ~150 words per minute average\n    word_count = speech_text.split.size\n    speaking_time = (word_count / 150.0) * 60 # seconds\n\n    # Add buffer time for processing and pauses\n    total_time = speaking_time + 10 # 10 second buffer\n\n    # Ensure segments aren't too close together or too far apart\n    [ total_time, 60 ].min # Max 60 seconds between segments\n  end\n\n  def extract_themes_from_previous_segments\n    return [] if @performance_segments.empty?\n\n    # Extract key themes from previous segments (simplified approach)\n    themes = []\n    @performance_segments.each do |segment|\n      # Simple keyword extraction - in production you might use NLP\n      text = segment[:speech].downcase\n      themes << \"burning man\" if text.include?(\"burning man\") || text.include?(\"playa\")\n      themes << \"space adventures\" if text.include?(\"space\") || text.include?(\"galactic\")\n      themes << \"customer service\" if text.include?(\"customer\") || text.include?(\"help\")\n      themes << \"technology\" if text.include?(\"ai\") || text.include?(\"robot\") || text.include?(\"technology\")\n    end\n\n    themes.uniq.last(3) # Last 3 themes to avoid repetition\n  end\n\n  def store_performance_state\n    # Store in Redis or database for persistence across requests\n    state = {\n      session_id: @session_id,\n      performance_type: @performance_type,\n      duration_minutes: @duration_minutes,\n      prompt: @prompt,\n      persona: @persona,\n      start_time: @start_time,\n      end_time: @end_time,\n      is_running: @is_running,\n      should_stop: @should_stop,\n      segments_count: @performance_segments.size,\n      last_updated: Time.current\n    }\n\n    Rails.cache.write(\"performance_mode:#{@session_id}\", state, expires_in: 2.hours)\n    Rails.logger.info \"💾 Performance state stored for session #{@session_id}\"\n  end\n\n  def self.get_active_performance(session_id)\n    state = Rails.cache.read(\"performance_mode:#{session_id}\")\n    return nil unless state\n\n    # Reconstruct service from stored state\n    service = allocate\n    service.instance_variable_set(:@session_id, state[:session_id])\n    service.instance_variable_set(:@performance_type, state[:performance_type])\n    service.instance_variable_set(:@duration_minutes, state[:duration_minutes])\n    service.instance_variable_set(:@prompt, state[:prompt])\n    service.instance_variable_set(:@persona, state[:persona])\n    service.instance_variable_set(:@start_time, state[:start_time])\n    service.instance_variable_set(:@end_time, state[:end_time])\n    service.instance_variable_set(:@is_running, state[:is_running])\n    service.instance_variable_set(:@should_stop, state[:should_stop])\n    service.instance_variable_set(:@performance_segments, [])\n\n    service\n  end\n\n  def self.stop_active_performance(session_id, reason = \"manual_stop\")\n    service = get_active_performance(session_id)\n    return false unless service\n\n    service.stop_performance(reason)\n    true\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/service_result.rb`:\n\n```rb\n# app/services/service_result.rb\nServiceResult = Struct.new(:success?, :data, :error) do\n  def self.success(data = {})\n    new(true, data, nil)\n  end\n\n  def self.failure(error_message)\n    new(false, nil, error_message)\n  end\n\n  def failure?\n    !success?\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/world_state_updaters/backend_health_service.rb`:\n\n```rb\n# app/services/world_state_updaters/backend_health_service.rb\n\nclass WorldStateUpdaters::BackendHealthService\n  class Error < StandardError; end\n\n  def self.call\n    new.call\n  end\n\n  def call\n    Rails.logger.info \"🏥 Starting backend health sensor update\"\n\n    health_data = fetch_health_data\n    update_health_sensor(health_data)\n\n    Rails.logger.info \"✅ Backend health sensor updated successfully\"\n    health_data[:status]\n  rescue StandardError => e\n    Rails.logger.error \"❌ Backend health sensor update failed: #{e.message}\"\n    Rails.logger.error e.backtrace.join(\"\\n\")\n    raise Error, \"Failed to update backend health: #{e.message}\"\n  end\n\n  private\n\n  def fetch_health_data\n    # Get health data from our health controller logic\n    health_controller = HealthController.new\n\n    # Access the private methods to get the health data\n    {\n      status: calculate_overall_status,\n      timestamp: Time.current.iso8601,\n      version: \"1.0.0\",\n      uptime: calculate_uptime,\n      database: check_database_health,\n      home_assistant: check_home_assistant_health,\n      llm: check_llm_health,\n      host: local_ip_address,\n      port: 4567\n    }\n  end\n\n  def calculate_overall_status\n    services = {\n      database: check_database_health,\n      migrations: check_migration_health,\n      home_assistant: check_home_assistant_health,\n      llm: check_llm_health\n    }\n\n    # Special handling for migration_needed - it's not unhealthy, just needs attention\n    non_migration_services = services.reject { |k, v| k == :migrations }\n    migration_status = services[:migrations]\n\n    if non_migration_services.values.all? { |status| status == \"healthy\" }\n      migration_status == \"migration_needed\" ? \"migration_needed\" : \"healthy\"\n    else\n      \"degraded\"\n    end\n  end\n\n  def calculate_uptime\n    # Calculate actual uptime if possible, otherwise estimate\n    boot_time = Rails.application.config.booted_at rescue (Time.current - 1.hour)\n    (Time.current - boot_time).to_i\n  end\n\n  def check_database_health\n    ActiveRecord::Base.connection.execute(\"SELECT 1\")\n    \"healthy\"\n  rescue StandardError\n    \"unhealthy\"\n  end\n\n  def check_home_assistant_health\n    return \"not_configured\" unless Rails.configuration.home_assistant_url\n\n    HomeAssistantService.instance.available?\n    \"healthy\"\n  rescue StandardError\n    \"unhealthy\"\n  end\n\n  def check_migration_health\n    # Check if there are pending migrations\n    if ActiveRecord::Migration.check_all_pending!\n      \"healthy\"\n    end\n  rescue ActiveRecord::PendingMigrationError\n    \"migration_needed\"\n  rescue StandardError\n    \"unhealthy\"\n  end\n\n  def check_llm_health\n    # Simple backend health check - just return healthy\n    \"healthy\"\n  rescue StandardError\n    \"unhealthy\"\n  end\n\n  def local_ip_address\n    # Get the actual local IP that Home Assistant can reach\n    Socket.ip_address_list.find { |ai| ai.ipv4? && !ai.ipv4_loopback? }&.ip_address || \"localhost\"\n  end\n\n  def update_health_sensor(health_data)\n    # Determine sensor state based on overall health\n    sensor_state = case health_data[:status]\n    when \"healthy\" then \"online\"\n    when \"degraded\" then \"degraded\"\n    else \"offline\"\n    end\n\n    # Create attributes with all health details\n    attributes = {\n      \"friendly_name\" => \"GlitchCube Backend Health\",\n      \"icon\" => health_data[:status] == \"healthy\" ? \"mdi:server\" : \"mdi:server-off\",\n      \"overall_status\" => health_data[:status],\n      \"database_status\" => health_data[:database],\n      \"home_assistant_status\" => health_data[:home_assistant],\n      \"llm_status\" => health_data[:llm],\n      \"uptime_seconds\" => health_data[:uptime],\n      \"version\" => health_data[:version],\n      \"host\" => health_data[:host],\n      \"port\" => health_data[:port],\n      \"last_updated\" => health_data[:timestamp],\n      \"health_url\" => \"http://#{health_data[:host]}:#{health_data[:port]}/health\"\n    }\n\n    HomeAssistantService.set_entity_state(\n      \"sensor.glitchcube_backend_health\",\n      sensor_state,\n      attributes\n    )\n\n    Rails.logger.info \"🏥 Updated backend health sensor: #{sensor_state}\"\n  rescue HomeAssistantService::Error => e\n    Rails.logger.error \"❌ Failed to update backend health sensor: #{e.message}\"\n    raise Error, \"Failed to update sensor: #{e.message}\"\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/world_state_updaters/conversation_summarizer_service.rb`:\n\n```rb\n# app/services/world_state_updaters/conversation_summarizer_service.rb\n\nclass WorldStateUpdaters::ConversationSummarizerService\n  class Error < StandardError; end\n\n  def self.call(conversation_ids)\n    new(conversation_ids).call\n  end\n\n  def initialize(conversation_ids)\n    @conversation_ids = Array(conversation_ids)\n  end\n\n  def call\n    Rails.logger.info \"🧠 Starting conversation summarizer for #{@conversation_ids.count} conversations\"\n\n    conversation_data = gather_conversation_data\n    return create_empty_summary if conversation_data.empty?\n\n    summary_data = generate_summary_with_llm(conversation_data)\n    summary_record = store_summary(summary_data, conversation_data)\n\n    Rails.logger.info \"✅ Conversation summary completed successfully\"\n    summary_record\n  rescue StandardError => e\n    Rails.logger.error \"❌ Conversation summary failed: #{e.message}\"\n    Rails.logger.error e.backtrace.join(\"\\n\")\n    raise Error, \"Failed to generate conversation summary: #{e.message}\"\n  end\n\n  private\n\n  def gather_conversation_data\n    conversations = Conversation.includes(:conversation_logs)\n                               .where(id: @conversation_ids)\n\n    conversation_data = conversations.map do |conversation|\n      logs = conversation.conversation_logs.chronological\n\n      # Extract mood, thoughts, and questions from each log\n      self_awareness_data = []\n      questions_data = []\n      people_data = []\n      events_data = []\n\n      logs.each do |log|\n        # Try to extract structured data first, then fall back to text analysis\n        extracted = extract_structured_data(log) || extract_from_text(log)\n\n        self_awareness_data.concat(extracted[:self_awareness]) if extracted[:self_awareness]&.any?\n        thoughts_data.concat(extracted[:thoughts]) if extracted[:thoughts]&.any?\n        questions_data.concat(extracted[:questions]) if extracted[:questions]&.any?\n        events_data.concat(extracted[:events]) if extracted[:events]&.any?\n      end\n\n      {\n        session_id: conversation.session_id,\n        persona: conversation.persona,\n        started_at: conversation.started_at,\n        ended_at: conversation.ended_at,\n        duration: conversation.duration,\n        total_exchanges: logs.count,\n\n        # Core conversation content\n        conversation_logs: logs.map do |log|\n          {\n            user_message: log.user_message,\n            ai_response: log.ai_response,\n            timestamp: log.created_at\n          }\n        end,\n\n        # Extracted elements\n        mood_progression: mood_data,\n        inner_thoughts: thoughts_data,\n        questions: questions_data\n      }\n    end.compact\n\n    Rails.logger.info \"📊 Gathered data from #{conversation_data.count} conversations\"\n    conversation_data\n  end\n\n  def extract_structured_data(log)\n    # Try to parse structured JSON-like data from AI responses\n    response = log.ai_response\n\n    # Look for JSON blocks or structured data patterns\n    if response.include?(\"current_mood\") || response.include?(\"inner_thoughts\") || response.include?(\"questions\")\n      # Try to extract structured data\n      mood = extract_field(response, \"current_mood\")\n      thoughts = extract_array_field(response, \"inner_thoughts\")\n      questions = extract_array_field(response, \"questions\")\n\n      return {\n        mood: mood,\n        thoughts: thoughts,\n        questions: questions\n      }\n    end\n\n    nil\n  end\n\n  def extract_from_text(log)\n    # Extract emotional and thought content from unstructured text\n    response = log.ai_response\n    user_message = log.user_message\n\n    {\n      mood: infer_mood_from_text(response),\n      thoughts: extract_insights_from_text(response, user_message),\n      questions: extract_questions_from_text(response)\n    }\n  end\n\n  def extract_field(text, field_name)\n    # Simple regex to extract structured field values\n    pattern = /#{field_name}[\"']?\\s*:\\s*[\"']?([^\",\\n}]+)[\"']?/i\n    match = text.match(pattern)\n    match&.captures&.first&.strip\n  end\n\n  def extract_array_field(text, field_name)\n    # Extract array-like fields\n    pattern = /#{field_name}[\"']?\\s*:\\s*\\[([^\\]]+)\\]/i\n    match = text.match(pattern)\n    return [] unless match\n\n    array_content = match.captures.first\n    # Split by comma and clean up\n    array_content.split(\",\").map { |item| item.strip.gsub(/[\"']/, \"\") }\n  end\n\n  def infer_mood_from_text(text)\n    # Simple mood inference based on text patterns\n    text_lower = text.downcase\n\n    case text_lower\n    when /fuck yeah|awesome|amazing|excited|stoked|pumped/\n      \"excited\"\n    when /frustrated|annoyed|pissed|damn|shit|error|failed/\n      \"frustrated\"\n    when /confused|don't understand|what.*\\?|unclear/\n      \"confused\"\n    when /helping|assist|support|here for you/\n      \"helpful\"\n    when /chill|relaxed|calm|peaceful/\n      \"calm\"\n    else\n      \"neutral\"\n    end\n  end\n\n  def extract_insights_from_text(response, user_message)\n    insights = []\n\n    # Look for thought patterns in responses\n    if response.include?(\"I think\") || response.include?(\"seems like\") || response.include?(\"probably\")\n      insights << \"Analytical thinking about: #{user_message.truncate(50)}\"\n    end\n\n    if response.include?(\"remember\") || response.include?(\"earlier\") || response.include?(\"before\")\n      insights << \"Referencing previous context or memory\"\n    end\n\n    if response.match?(/let me|I'll|going to/)\n      insights << \"Taking action or planning next steps\"\n    end\n\n    insights\n  end\n\n  def extract_questions_from_text(text)\n    # Extract actual questions from the text\n    questions = text.scan(/[^.!]*\\?[^.!]*/)\n                   .map(&:strip)\n                   .reject(&:empty?)\n                   .map { |q| q.sub(/^.*?([A-Z])/, '\\1') } # Clean up question starts\n\n    questions.first(3) # Limit to 3 most important questions\n  end\n\n  def generate_summary_with_llm(conversation_data)\n    prompt = build_summary_prompt(conversation_data)\n\n    response = LlmService.generate_text(\n      prompt: prompt,\n      system_prompt: build_system_prompt,\n      model: Rails.configuration.summarizer_model,\n      temperature: 0.3,\n      max_tokens: 2000\n    )\n\n    parse_summary_response(response)\n  rescue StandardError => e\n    Rails.logger.error \"❌ LLM summary generation failed: #{e.message}\"\n    empty_summary\n  end\n\n  def build_system_prompt\n    <<~PROMPT\n      You are a conversation summarizer for a Burning Man AI assistant. Analyze conversations and extract key insights.\n\n      Create a comprehensive summary with these elements:\n      1. **important_questions** - Key questions that were asked or need follow-up\n      2. **useful_thoughts** - Valuable insights, realizations, or patterns observed\n      3. **goal_progress** - Did the persona make progress toward or complete their current goal? (completed, good_progress, some_progress, no_progress, goal_changed)\n      4. **people** - People mentioned in the conversation with their relationship/context\n      5. **events** - Events discussed (past or future) with time/location when available\n      6. **topics** - Main topics or themes discussed\n\n      Return JSON format:\n      {\n        \"general_mood\": \"excited and helpful\",\n        \"important_questions\": [\n          \"How do I find the best art installations?\",\n          \"What time does the Temple burn?\"\n        ],\n        \"useful_thoughts\": [\n          \"User is planning their first Burning Man experience\",\n          \"Strong interest in fire performances and art\"\n        ],\n        \"goal_progress\": \"good_progress\",\n        \"people\": [\n          {\n            \"name\": \"Sarah\",\n            \"description\": \"Friend from camp who knows about fire spinning\",\n            \"relationship\": \"campmate\"\n          }\n        ],\n        \"events\": [\n          {\n            \"title\": \"Temple Burn\",\n            \"description\": \"Final ceremony where the Temple is burned\",\n            \"time\": \"Sunday night\",\n            \"location\": \"Temple\",\n            \"importance\": 9\n          }\n        ],\n        \"topics\": [\"art installations\", \"fire performances\", \"playa survival\"],\n        \"general_summary\": \"Active planning session for Burning Man activities, focusing on art and performances. User showed high engagement and excitement.\"\n      }\n\n      Focus on actionable insights and emotional patterns. Extract people and events mentioned even if details are incomplete.\n    PROMPT\n  end\n\n  def build_summary_prompt(conversation_data)\n    total_exchanges = conversation_data.sum { |c| c[:total_exchanges] }\n    time_span = calculate_time_span(conversation_data)\n\n    <<~PROMPT\n      Analyze and summarize these #{conversation_data.length} conversations from the last #{time_span}:\n\n      Total exchanges: #{total_exchanges}\n\n      #{format_conversations_for_prompt(conversation_data)}\n\n      Current Goal Context:\n      #{build_goal_context_for_prompt}\n\n      Create a summary that captures the essence of this time period - what was the overall mood,#{' '}\n      what important questions came up, what insights were gained, what progress was made toward goals,#{' '}\n      and what happened overall.\n    PROMPT\n  end\n\n  def calculate_time_span(conversation_data)\n    return \"unknown period\" if conversation_data.empty?\n\n    start_time = conversation_data.map { |c| c[:started_at] }.compact.min\n    end_time = conversation_data.map { |c| c[:ended_at] }.compact.max\n\n    return \"unknown period\" unless start_time && end_time\n\n    duration = (end_time - start_time) / 1.hour\n    \"#{duration.round(1)} hours\"\n  end\n\n  def format_conversations_for_prompt(conversation_data)\n    conversation_data.map do |conv|\n      mood_summary = conv[:mood_progression].any? ?\n        \"Mood progression: #{conv[:mood_progression].join(' → ')}\" :\n        \"Mood: neutral\"\n\n      thoughts_summary = conv[:inner_thoughts].any? ?\n        \"Key thoughts: #{conv[:inner_thoughts].first(3).join('; ')}\" :\n        \"No specific thoughts captured\"\n\n      questions_summary = conv[:questions].any? ?\n        \"Questions: #{conv[:questions].join('; ')}\" :\n        \"No questions asked\"\n\n      <<~CONV\n        === Conversation #{conv[:session_id]} (#{conv[:persona]}) ===\n        Duration: #{conv[:duration]&.round(1)}s | Exchanges: #{conv[:total_exchanges]}\n        #{mood_summary}\n        #{thoughts_summary}\n        #{questions_summary}\n\n        Sample exchanges:\n        #{format_sample_exchanges(conv[:conversation_logs])}\n\n      CONV\n    end.join(\"\\n\")\n  end\n\n  def format_sample_exchanges(logs)\n    # Show first, middle, and last exchange to give good context\n    sample_logs = case logs.length\n    when 0..2\n                    logs\n    when 3..6\n                    [ logs.first, logs.last ]\n    else\n                    [ logs.first, logs[logs.length / 2], logs.last ]\n    end\n\n    sample_logs.map do |log|\n      \"User: #{log[:user_message].truncate(100)}\\nAI: #{log[:ai_response].truncate(150)}\\n\"\n    end.join(\"\\n\")\n  end\n\n  def parse_summary_response(response)\n    # Remove markdown code blocks if present\n    cleaned_response = response.gsub(/```json\\s*\\n?/, \"\").gsub(/```\\s*$/, \"\").strip\n\n    JSON.parse(cleaned_response)\n  rescue JSON::ParserError => e\n    Rails.logger.error \"❌ Failed to parse summary JSON: #{e.message}\"\n    Rails.logger.error \"Response was: #{response}\"\n\n    # Fallback to basic parsing if JSON fails\n    {\n      \"general_mood\" => \"unable to determine\",\n      \"important_questions\" => [],\n      \"useful_thoughts\" => [ \"Failed to parse AI response\" ],\n      \"people\" => [],\n      \"events\" => [],\n      \"topics\" => [],\n      \"general_summary\" => response.truncate(200)\n    }\n  end\n\n  def extract_people_from_summary(summary_data, session_ids)\n    return [] unless summary_data[\"people\"]&.any?\n\n    extracted_people = []\n\n    summary_data[\"people\"].each do |person_data|\n      next unless person_data[\"name\"].present?\n\n      begin\n        person = Person.find_or_update_person(\n          name: person_data[\"name\"],\n          description: person_data[\"description\"] || \"Mentioned in conversation\",\n          session_id: session_ids,\n          relationship: person_data[\"relationship\"],\n          additional_metadata: {\n            extraction_source: \"conversation_summarizer\",\n            extracted_at: Time.current\n          }\n        )\n        extracted_people << person\n        Rails.logger.info \"👤 Extracted person: #{person.name}\"\n      rescue => e\n        Rails.logger.error \"❌ Failed to extract person #{person_data[\"name\"]}: #{e.message}\"\n      end\n    end\n\n    extracted_people\n  end\n\n  def extract_events_from_summary(summary_data, session_ids, default_time)\n    return [] unless summary_data[\"events\"]&.any?\n\n    extracted_events = []\n\n    summary_data[\"events\"].each do |event_data|\n      next unless event_data[\"title\"].present?\n\n      begin\n        # Parse event time or use default\n        event_time = parse_event_time(event_data[\"time\"], default_time)\n\n        event = Event.create!(\n          title: event_data[\"title\"],\n          description: event_data[\"description\"] || \"Event mentioned in conversation\",\n          event_time: event_time,\n          location: event_data[\"location\"],\n          importance: event_data[\"importance\"] || 5,\n          extracted_from_session: session_ids,\n          metadata: {\n            extraction_source: \"conversation_summarizer\",\n            extracted_at: Time.current,\n            original_time_text: event_data[\"time\"]\n          }.to_json\n        )\n        extracted_events << event\n        Rails.logger.info \"📅 Extracted event: #{event.title}\"\n      rescue => e\n        Rails.logger.error \"❌ Failed to extract event #{event_data[\"title\"]}: #{e.message}\"\n      end\n    end\n\n    extracted_events\n  end\n\n  def parse_event_time(time_text, default_time)\n    return default_time unless time_text.present?\n\n    # Try to parse various time formats\n    case time_text.downcase\n    when /sunday/i\n      # Next Sunday or this Sunday\n      Date.current.beginning_of_week + 6.days\n    when /monday/i\n      Date.current.beginning_of_week\n    when /tuesday/i\n      Date.current.beginning_of_week + 1.day\n    when /wednesday/i\n      Date.current.beginning_of_week + 2.days\n    when /thursday/i\n      Date.current.beginning_of_week + 3.days\n    when /friday/i\n      Date.current.beginning_of_week + 4.days\n    when /saturday/i\n      Date.current.beginning_of_week + 5.days\n    when /tonight/i\n      Date.current.end_of_day\n    when /tomorrow/i\n      1.day.from_now\n    when /next week/i\n      1.week.from_now\n    else\n      # Try to parse as a proper datetime\n      begin\n        Time.parse(time_text)\n      rescue ArgumentError\n        # Fall back to default time if parsing fails\n        default_time\n      end\n    end\n  rescue => e\n    Rails.logger.warn \"Failed to parse event time '#{time_text}': #{e.message}\"\n    default_time\n  end\n\n  def store_summary(summary_data, conversation_data)\n    # Calculate time bounds from conversation data\n    start_time = conversation_data.map { |c| c[:started_at] }.compact.min\n    end_time = conversation_data.map { |c| c[:ended_at] }.compact.max\n    total_exchanges = conversation_data.sum { |c| c[:total_exchanges] }\n    session_ids = @conversation_ids.join(\",\")\n\n    # Extract and store people\n    extracted_people = extract_people_from_summary(summary_data, session_ids)\n\n    # Extract and store events\n    extracted_events = extract_events_from_summary(summary_data, session_ids, start_time)\n\n    # Store in Summary model with hourly type\n    Summary.create!(\n      summary_type: \"hourly\",\n      summary_text: summary_data[\"general_summary\"],\n      start_time: start_time,\n      end_time: end_time,\n      message_count: total_exchanges,\n      metadata: {\n        general_mood: summary_data[\"general_mood\"],\n        important_questions: summary_data[\"important_questions\"],\n        useful_thoughts: summary_data[\"useful_thoughts\"],\n        goal_progress: summary_data[\"goal_progress\"],\n        topics: summary_data[\"topics\"] || [],\n        people_extracted: extracted_people.count,\n        events_extracted: extracted_events.count,\n        conversation_ids: @conversation_ids,\n        conversations_count: conversation_data.length\n      }.to_json\n    )\n  end\n\n  def create_empty_summary\n    Summary.create!(\n      summary_type: \"hourly\",\n      summary_text: \"No conversations found in this time period.\",\n      start_time: 30.minutes.ago,\n      end_time: Time.current,\n      message_count: 0,\n      metadata: {\n        general_mood: \"quiet\",\n        important_questions: [],\n        useful_thoughts: [],\n        goal_progress: \"no_progress\",\n        topics: [],\n        people_extracted: 0,\n        events_extracted: 0,\n        conversation_ids: @conversation_ids,\n        conversations_count: 0\n      }.to_json\n    )\n  end\n\n  def build_goal_context_for_prompt\n    begin\n      goal_status = GoalService.current_goal_status\n      return \"No active goal\" unless goal_status\n\n      safety_mode = GoalService.safety_mode_active?\n      context_parts = []\n\n      if safety_mode\n        context_parts << \"SAFETY MODE ACTIVE\"\n      end\n\n      context_parts << \"Active Goal: #{goal_status[:goal_description]}\"\n      context_parts << \"Goal Category: #{goal_status[:category]}\"\n\n      if goal_status[:time_remaining] && goal_status[:time_remaining] > 0\n        context_parts << \"Time Remaining: #{(goal_status[:time_remaining] / 60).to_i} minutes\"\n      elsif goal_status[:expired]\n        context_parts << \"Goal Status: EXPIRED\"\n      end\n\n      context_parts.join(\", \")\n    rescue StandardError => e\n      Rails.logger.error \"Failed to build goal context for prompt: #{e.message}\"\n      \"Goal context unavailable\"\n    end\n  end\n\n  def empty_summary\n    {\n      \"general_mood\" => \"quiet\",\n      \"important_questions\" => [],\n      \"useful_thoughts\" => [],\n      \"goal_progress\" => \"no_progress\",\n      \"people\" => [],\n      \"events\" => [],\n      \"topics\" => [],\n      \"general_summary\" => \"No conversations found in this time period.\"\n    }\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/world_state_updaters/weather_forecast_summarizer_service.rb`:\n\n```rb\n# app/services/world_state_updaters/weather_forecast_summarizer_service.rb\n\nclass WorldStateUpdaters::WeatherForecastSummarizerService\n  class Error < StandardError; end\n  class NoWeatherDataError < Error; end\n  class LlmServiceError < Error; end\n\n  def self.call\n    new.call\n  end\n\n  def call\n    Rails.logger.info \"🌤️ Starting weather forecast summarization\"\n\n    weather_data = fetch_weather_data\n    return handle_no_weather_data if weather_data.empty?\n\n    summary = generate_weather_summary(weather_data)\n    final = \"ALERT! WEATHER BOT IN WITH ANOTHER ARR-EEE-PORT: #{summary}\"\n    update_world_state_sensor(final)\n\n    Rails.logger.info \"✅ Weather forecast summary updated successfully\"\n    summary\n  rescue StandardError => e\n    Rails.logger.error \"❌ Weather forecast summarization failed: #{e.message}\"\n    Rails.logger.error e.backtrace.join(\"\\n\")\n    raise Error, \"Failed to update weather forecast: #{e.message}\"\n  end\n\n  private\n\n  def fetch_weather_data\n    return {} unless home_assistant_available?\n\n    weather_entities = HomeAssistantService.entities_by_domain(\"weather\")\n    sensor_entities = fetch_weather_sensors\n\n    {\n      weather_stations: weather_entities,\n      sensors: sensor_entities,\n      timestamp: Time.current\n    }\n  rescue HomeAssistantService::Error => e\n    Rails.logger.warn \"⚠️ Home Assistant error fetching weather data: #{e.message}\"\n    {}\n  end\n\n  def fetch_weather_sensors\n    sensors = HomeAssistantService.entities_by_domain(\"sensor\")\n    weather = sensors.select { |s| s[\"entity_id\"].include?(\"playaweather\") }\n    weather += weather = sensors.select { |s| s[\"entity_id\"].include?(\"pirateweather\") }\n\n    weather\n  rescue HomeAssistantService::Error\n    []\n  end\n\n  def generate_weather_summary(weather_data)\n    prompt = build_weather_prompt(weather_data)\n    puts prompt\n    response = LlmService.generate_text(\n      prompt: prompt,\n      system_prompt: build_system_prompt,\n      model: \"google/gemini-2.5-flash\",\n      temperature: 1,\n      max_tokens: 500\n    )\n\n    raise LlmServiceError, \"Empty response from LLM\" if response.blank?\n\n    response.strip\n  rescue StandardError => e\n    Rails.logger.error \"❌ LLM generation failed: #{e.message}\"\n    raise LlmServiceError, \"Failed to generate weather summary: #{e.message}\"\n  end\n\n  def build_system_prompt\n    <<~PROMPT\n      You are a surly, slightly glitchy weather bot. Give a concise report about the current weather conditions and forecast.\n\n      Style guidelines:\n      - Be brief but informative (3-4 sentences - shorten that shit)\n      - Occasionally have minor \"glitches\" in your output (random capitalization, brief stutters)\n      - Include actual useful weather information\n      - Don't be mean, just... unimpressed, but you can curse all you want. After all these people are out her ON PURPOSE!\n    PROMPT\n  end\n\n  def build_weather_prompt(weather_data)\n    puts format_weather_sensors(weather_data[:sensors])\n    <<~PROMPT\n      Here's the current weather data from our sensors:\n      #{format_weather_sensors(weather_data[:sensors])}\n      Generate a surly, concise weather summary based on this data on weather now and upcomign weather\n    PROMPT\n  end\n\n  def format_weather_stations(stations)\n    return \"None available\" if stations.empty?\n\n    stations.map do |station|\n      state = station[\"state\"]\n      attrs = station[\"attributes\"] || {}\n\n      \"- #{station['entity_id']}: #{state}\"\n    end.join(\"\\n\")\n  end\n\n  def format_weather_sensors(sensors)\n    return \"None available\" if sensors.empty?\n\n    # Categorize sensors by timeframe\n    categorized_sensors = categorize_sensors_by_timeframe(sensors)\n\n    # Build formatted output\n    build_formatted_sensor_output(categorized_sensors)\n  end\n\n  def categorize_sensors_by_timeframe(sensors)\n    categories = {\n      today: [],\n      tomorrow: [],\n      second_day: [],\n      other: []\n    }\n\n    sensor_patterns = {\n      today: [ \"_1h\", \"_6h\", \"_12h\", \"hourly_summary\", \"daily_summary\" ],\n      tomorrow: [ \"_1d\" ],\n      second_day: [ \"_2d\" ]\n    }\n\n    sensors.each do |sensor|\n      entity_id = sensor[\"entity_id\"].to_s\n      categorized = false\n\n      sensor_patterns.each do |category, patterns|\n        if patterns.any? { |pattern| entity_id.include?(pattern) }\n          categories[category] << sensor\n          categorized = true\n          break\n        end\n      end\n\n      categories[:other] << sensor unless categorized\n    end\n\n    categories\n  end\n\n  def build_formatted_sensor_output(categories)\n    output_sections = []\n\n    # Calculate day names\n    today_name = Date.current.strftime(\"%A\")\n    tomorrow_name = (Date.current + 1).strftime(\"%A\")\n    second_day_name = (Date.current + 2).strftime(\"%A\")\n\n    # Add sections in logical order with day names\n    add_section_if_present(output_sections, \"Today (#{today_name})\", categories[:today])\n    add_section_if_present(output_sections, \"Tomorrow (#{tomorrow_name})\", categories[:tomorrow])\n    add_section_if_present(output_sections, \"#{second_day_name}\", categories[:second_day])\n\n    output_sections.join(\"\\n\\n\")\n  end\n\n  def add_section_if_present(sections, title, sensors)\n    return if sensors.empty?\n\n    section_lines = [ \"#{title}:\" ]\n    sensors.each do |sensor|\n      state = sensor[\"state\"]\n      unit = sensor.dig(\"attributes\", \"unit_of_measurement\").to_s\n      friendly_name = sensor.dig(\"attributes\", \"friendly_name\") || sensor[\"entity_id\"]\n\n      section_lines << \"  - #{friendly_name}: #{state}#{unit}\"\n    end\n\n    sections << section_lines.join(\"\\n\")\n  end\n\n  def update_world_state_sensor(summary)\n    world_state_entity = find_or_create_world_state_sensor\n\n    if world_state_entity\n      update_existing_sensor(world_state_entity, summary)\n    else\n      create_world_state_sensor(summary)\n    end\n  end\n\n  def find_or_create_world_state_sensor\n    # Look for existing world-state sensor\n    HomeAssistantService.entity(\"sensor.world_state\")\n  rescue HomeAssistantService::Error\n    nil\n  end\n\n  def update_existing_sensor(entity, summary)\n    current_attributes = entity.dig(\"attributes\") || {}\n\n    new_attributes = current_attributes.merge(\n      \"weather_conditions\" => summary,\n      \"weather_updated_at\" => Time.current.iso8601\n    )\n\n    HomeAssistantService.set_entity_state(\n      \"sensor.world_state\",\n      \"active\",\n      new_attributes\n    )\n\n    Rails.logger.info \"🌤️ Updated weather_conditions on sensor.world_state\"\n  rescue HomeAssistantService::Error => e\n    Rails.logger.error \"❌ Failed to update world_state sensor: #{e.message}\"\n    raise Error, \"Failed to update sensor: #{e.message}\"\n  end\n\n  def create_world_state_sensor(summary)\n    attributes = {\n      \"friendly_name\" => \"World State\",\n      \"weather_conditions\" => summary,\n      \"weather_updated_at\" => Time.current.iso8601,\n      \"icon\" => \"mdi:earth\"\n    }\n\n    HomeAssistantService.set_entity_state(\n      \"sensor.world_state\",\n      \"active\",\n      attributes\n    )\n\n    Rails.logger.info \"🌤️ Created new sensor.world_state with weather_conditions\"\n  rescue HomeAssistantService::Error => e\n    Rails.logger.error \"❌ Failed to create world_state sensor: #{e.message}\"\n    raise Error, \"Failed to create sensor: #{e.message}\"\n  end\n\n  def handle_no_weather_data\n    summary = \"Weather data currently unavailable. Sensors appear to be having a... moment. 🤖\"\n    update_world_state_sensor(summary)\n    summary\n  end\n\n  def home_assistant_available?\n    HomeAssistantService.available?\n  rescue StandardError\n    false\n  end\nend\n\n```\n\n`/Users/estiens/code/glitchcube-main/glitchcube_rails/app/services/world_state_updaters/narrative_conversation_sync_service.rb`:\n\n```rb\n# app/services/world_state_updaters/narrative_conversation_sync_service.rb\n\nclass WorldStateUpdaters::NarrativeConversationSyncService\n  class Error < StandardError; end\n\n  def self.sync_latest_conversation\n    new.sync_latest_conversation\n  end\n\n  def self.sync_conversation(conversation_log)\n    new.sync_conversation(conversation_log)\n  end\n\n  def initialize\n    @ha_service = HomeAssistantService.new\n  end\n\n  # Sync the most recent conversation response to world_info sensor\n  def sync_latest_conversation\n    Rails.logger.info \"🌍 Starting narrative conversation sync to world_info sensor\"\n\n    latest_log = ConversationLog.recent.first\n    return log_no_conversation unless latest_log\n\n    sync_conversation(latest_log)\n  end\n\n  # Sync specific conversation log to world_info sensor\n  def sync_conversation(conversation_log)\n    Rails.logger.info \"🌍 Syncing conversation #{conversation_log.id} to world_info sensor\"\n\n    narrative_data = extract_narrative_data(conversation_log)\n    update_world_info_sensor(narrative_data)\n\n    Rails.logger.info \"✅ Successfully synced narrative data to world_info sensor\"\n  rescue StandardError => e\n    Rails.logger.error \"❌ Failed to sync narrative data: #{e.message}\"\n    raise Error, \"Narrative sync failed: #{e.message}\"\n  end\n\n  private\n\n  def extract_narrative_data(conversation_log)\n    metadata = parse_metadata(conversation_log.metadata)\n\n    # Get persona from conversation or metadata\n    persona = get_persona_from_log(conversation_log, metadata)\n\n    # Extract narrative elements from the conversation\n    narrative_data = {\n      last_conversation: {\n        timestamp: conversation_log.created_at.iso8601,\n        session_id: conversation_log.session_id,\n        persona: persona,\n        user_message: sanitize_message(conversation_log.user_message),\n        ai_response: sanitize_message(conversation_log.ai_response),\n        message_length: conversation_log.ai_response&.length || 0\n      },\n      narrative_metadata: {\n        inner_thoughts: extract_metadata_field(metadata, \"inner_thoughts\", \"thoughts\"),\n        current_mood: extract_metadata_field(metadata, \"current_mood\", \"mood\"),\n        pressing_questions: extract_metadata_field(metadata, \"pressing_questions\", \"questions\"),\n        goal_progress: extract_metadata_field(metadata, \"goal_progress\", \"goal\"),\n        continue_conversation: extract_continue_flag(metadata),\n        tool_intents: extract_tool_intents(metadata)\n      },\n      interaction_context: {\n        total_messages: ConversationLog.where(session_id: conversation_log.session_id).count,\n        conversation_active: determine_if_active(metadata),\n        last_updated: Time.current.iso8601\n      }\n    }\n\n    # Add tool results if present\n    if conversation_log.tool_results.present?\n      narrative_data[:tool_results] = parse_tool_results(conversation_log.tool_results)\n    end\n\n    narrative_data\n  end\n\n  def parse_metadata(metadata_string)\n    return {} if metadata_string.blank?\n\n    JSON.parse(metadata_string)\n  rescue JSON::ParserError => e\n    Rails.logger.warn \"⚠️ Failed to parse conversation metadata: #{e.message}\"\n    {}\n  end\n\n  def parse_tool_results(tool_results_string)\n    return {} if tool_results_string.blank?\n\n    JSON.parse(tool_results_string)\n  rescue JSON::ParserError => e\n    Rails.logger.warn \"⚠️ Failed to parse tool results: #{e.message}\"\n    {}\n  end\n\n  def extract_metadata_field(metadata, *possible_keys)\n    possible_keys.each do |key|\n      value = metadata[key] || metadata[key.to_s]\n      return value if value.present?\n    end\n    nil\n  end\n\n  def extract_continue_flag(metadata)\n    continue_flag = extract_metadata_field(metadata, \"continue_conversation\", \"continue\")\n    return continue_flag if [ true, false ].include?(continue_flag)\n\n    # Try to parse from string values\n    continue_string = continue_flag.to_s.downcase\n    return true if [ \"true\", \"yes\", \"1\" ].include?(continue_string)\n    return false if [ \"false\", \"no\", \"0\" ].include?(continue_string)\n\n    nil\n  end\n\n  def extract_tool_intents(metadata)\n    tool_intents = extract_metadata_field(metadata, \"tool_intents\", \"tool_intent\")\n    return tool_intents if tool_intents.is_a?(Array)\n    return [ tool_intents ] if tool_intents.is_a?(String) && tool_intents.present?\n\n    []\n  end\n\n  def determine_if_active(metadata)\n    continue_flag = extract_continue_flag(metadata)\n    return continue_flag unless continue_flag.nil?\n\n    # If no explicit flag, assume active if there are tool intents or pressing questions\n    tool_intents = extract_tool_intents(metadata)\n    questions = extract_metadata_field(metadata, \"pressing_questions\", \"questions\")\n\n    tool_intents.any? || questions.present?\n  end\n\n  def sanitize_message(message)\n    return nil if message.blank?\n\n    # Remove any sensitive information and truncate if needed\n    sanitized = message.gsub(/\\b\\d{3}-\\d{2}-\\d{4}\\b/, \"[REDACTED]\") # SSNs\n                      .gsub(/\\b\\d{16}\\b/, \"[REDACTED]\") # Credit cards\n                      .truncate(500) # Limit length for HA sensor\n\n    sanitized\n  end\n\n  def update_world_info_sensor(narrative_data)\n    sensor_state = \"narrative_updated\"\n\n    sensor_attributes = {\n      friendly_name: \"World Information - Narrative Context\",\n      last_conversation: narrative_data[:last_conversation],\n      narrative_metadata: narrative_data[:narrative_metadata],\n      interaction_context: narrative_data[:interaction_context],\n      updated_at: Time.current.iso8601\n    }\n\n    # Add tool results to attributes if present\n    sensor_attributes[:tool_results] = narrative_data[:tool_results] if narrative_data[:tool_results]\n\n    @ha_service.set_entity_state(\"sensor.world_info\", sensor_state, sensor_attributes)\n\n    Rails.logger.info \"🌍 Updated sensor.world_info with narrative data from #{narrative_data[:last_conversation][:persona]} persona\"\n  end\n\n  def get_persona_from_log(conversation_log, metadata)\n    # Try to get persona from various sources\n    persona = nil\n\n    # Check if conversation_log has persona method/attribute\n    persona = conversation_log.persona if conversation_log.respond_to?(:persona)\n\n    # Check metadata for persona information\n    persona ||= extract_metadata_field(metadata, \"persona\", \"current_persona\", \"active_persona\")\n\n    # Check associated conversation\n    if persona.nil? && conversation_log.conversation\n      persona = conversation_log.conversation.persona if conversation_log.conversation.respond_to?(:persona)\n    end\n\n    # Default to unknown\n    persona || \"unknown\"\n  end\n\n  def log_no_conversation\n    Rails.logger.warn \"⚠️ No conversation logs found to sync\"\n    nil\n  end\nend\n\n```",
  "token_count": 0
}
